{
  "title": "Action selection",
  "html": "<!DOCTYPE html>\n<html class=\"client-nojs\" dir=\"ltr\" lang=\"en\">\n<head>\n<meta charset=\"utf-8\"/>\n<title>Action selection - Wikipedia</title>\n<script>document.documentElement.className = document.documentElement.className.replace( /(^|\\s)client-nojs(\\s|$)/, \"$1client-js$2\" );</script>\n<script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({\"wgCanonicalNamespace\":\"\",\"wgCanonicalSpecialPageName\":false,\"wgNamespaceNumber\":0,\"wgPageName\":\"Action_selection\",\"wgTitle\":\"Action selection\",\"wgCurRevisionId\":843537296,\"wgRevisionId\":843537296,\"wgArticleId\":5033373,\"wgIsArticle\":true,\"wgIsRedirect\":false,\"wgAction\":\"view\",\"wgUserName\":null,\"wgUserGroups\":[\"*\"],\"wgCategories\":[\"Artificial intelligence\",\"Motor control\",\"Motor cognition\"],\"wgBreakFrames\":false,\"wgPageContentLanguage\":\"en\",\"wgPageContentModel\":\"wikitext\",\"wgSeparatorTransformTable\":[\"\",\"\"],\"wgDigitTransformTable\":[\"\",\"\"],\"wgDefaultDateFormat\":\"dmy\",\"wgMonthNames\":[\"\",\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"],\"wgMonthNamesShort\":[\"\",\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"],\"wgRelevantPageName\":\"Action_selection\",\"wgRelevantArticleId\":5033373,\"wgRequestId\":\"XHMS-ApAAEQAACVANYAAAACQ\",\"wgCSPNonce\":false,\"wgIsProbablyEditable\":true,\"wgRelevantPageIsProbablyEditable\":true,\"wgRestrictionEdit\":[],\"wgRestrictionMove\":[],\"wgFlaggedRevsParams\":{\"tags\":{}},\"wgStableRevisionId\":null,\"wgCategoryTreePageCategoryOptions\":\"{\\\"mode\\\":0,\\\"hideprefix\\\":20,\\\"showcount\\\":true,\\\"namespaces\\\":false}\",\"wgWikiEditorEnabledModules\":[],\"wgBetaFeaturesFeatures\":[],\"wgMediaViewerOnClick\":true,\"wgMediaViewerEnabledByDefault\":true,\"wgPopupsShouldSendModuleToUser\":true,\"wgPopupsConflictsWithNavPopupGadget\":false,\"wgVisualEditor\":{\"pageLanguageCode\":\"en\",\"pageLanguageDir\":\"ltr\",\"pageVariantFallbacks\":\"en\",\"usePageImages\":true,\"usePageDescriptions\":true},\"wgMFIsPageContentModelEditable\":true,\"wgMFEnableFontChanger\":true,\"wgMFDisplayWikibaseDescriptions\":{\"search\":true,\"nearby\":true,\"watchlist\":true,\"tagline\":false},\"wgRelatedArticles\":null,\"wgRelatedArticlesUseCirrusSearch\":true,\"wgRelatedArticlesOnlyUseCirrusSearch\":false,\"wgWMESchemaEditAttemptStepOversample\":false,\"wgPoweredByHHVM\":true,\"wgULSCurrentAutonym\":\"English\",\"wgNoticeProject\":\"wikipedia\",\"wgCentralNoticeCookiesToDelete\":[],\"wgCentralNoticeCategoriesUsingLegacy\":[\"Fundraising\",\"fundraising\"],\"wgWikibaseItemId\":\"Q4677422\",\"wgScoreNoteLanguages\":{\"arabic\":\"العربية\",\"catalan\":\"català\",\"deutsch\":\"Deutsch\",\"english\":\"English\",\"espanol\":\"español\",\"italiano\":\"italiano\",\"nederlands\":\"Nederlands\",\"norsk\":\"norsk\",\"portugues\":\"português\",\"suomi\":\"suomi\",\"svenska\":\"svenska\",\"vlaams\":\"West-Vlams\"},\"wgScoreDefaultNoteLanguage\":\"nederlands\",\"wgCentralAuthMobileDomain\":false,\"wgCodeMirrorEnabled\":true,\"wgVisualEditorToolbarScrollOffset\":0,\"wgVisualEditorUnsupportedEditParams\":[\"undo\",\"undoafter\",\"veswitched\"],\"wgEditSubmitButtonLabelPublish\":true,\"oresWikiId\":\"enwiki\",\"oresBaseUrl\":\"http://ores.discovery.wmnet:8081/\",\"oresApiVersion\":3});mw.loader.state({\"ext.gadget.charinsert-styles\":\"ready\",\"ext.globalCssJs.user.styles\":\"ready\",\"ext.globalCssJs.site.styles\":\"ready\",\"site.styles\":\"ready\",\"noscript\":\"ready\",\"user.styles\":\"ready\",\"ext.globalCssJs.user\":\"ready\",\"ext.globalCssJs.site\":\"ready\",\"user\":\"ready\",\"user.options\":\"ready\",\"user.tokens\":\"loading\",\"ext.cite.styles\":\"ready\",\"mediawiki.legacy.shared\":\"ready\",\"mediawiki.legacy.commonPrint\":\"ready\",\"mediawiki.toc.styles\":\"ready\",\"wikibase.client.init\":\"ready\",\"ext.visualEditor.desktopArticleTarget.noscript\":\"ready\",\"ext.uls.interlanguage\":\"ready\",\"ext.wikimediaBadges\":\"ready\",\"ext.3d.styles\":\"ready\",\"mediawiki.skinning.interface\":\"ready\",\"skins.vector.styles\":\"ready\"});mw.loader.implement(\"user.tokens@0tffind\",function($,jQuery,require,module){/*@nomin*/mw.user.tokens.set({\"editToken\":\"+\\\\\",\"patrolToken\":\"+\\\\\",\"watchToken\":\"+\\\\\",\"csrfToken\":\"+\\\\\"});\n});RLPAGEMODULES=[\"ext.cite.ux-enhancements\",\"site\",\"mediawiki.page.startup\",\"mediawiki.page.ready\",\"mediawiki.toc\",\"mediawiki.searchSuggest\",\"ext.gadget.teahouse\",\"ext.gadget.ReferenceTooltips\",\"ext.gadget.watchlist-notice\",\"ext.gadget.DRN-wizard\",\"ext.gadget.charinsert\",\"ext.gadget.refToolbar\",\"ext.gadget.extra-toolbar-buttons\",\"ext.gadget.switcher\",\"ext.centralauth.centralautologin\",\"mmv.head\",\"mmv.bootstrap.autostart\",\"ext.popups\",\"ext.visualEditor.desktopArticleTarget.init\",\"ext.visualEditor.targetLoader\",\"ext.eventLogging\",\"ext.wikimediaEvents\",\"ext.navigationTiming\",\"ext.uls.eventlogger\",\"ext.uls.init\",\"ext.uls.compactlinks\",\"ext.uls.interface\",\"ext.quicksurveys.init\",\"ext.centralNotice.geoIP\",\"ext.centralNotice.startUp\",\"skins.vector.js\"];mw.loader.load(RLPAGEMODULES);});</script>\n<link href=\"/w/load.php?debug=false&amp;lang=en&amp;modules=ext.3d.styles%7Cext.cite.styles%7Cext.uls.interlanguage%7Cext.visualEditor.desktopArticleTarget.noscript%7Cext.wikimediaBadges%7Cmediawiki.legacy.commonPrint%2Cshared%7Cmediawiki.skinning.interface%7Cmediawiki.toc.styles%7Cskins.vector.styles%7Cwikibase.client.init&amp;only=styles&amp;skin=vector\" rel=\"stylesheet\"/>\n<script async=\"\" src=\"/w/load.php?debug=false&amp;lang=en&amp;modules=startup&amp;only=scripts&amp;skin=vector\"></script>\n<meta content=\"\" name=\"ResourceLoaderDynamicStyles\"/>\n<link href=\"/w/load.php?debug=false&amp;lang=en&amp;modules=ext.gadget.charinsert-styles&amp;only=styles&amp;skin=vector\" rel=\"stylesheet\"/>\n<link href=\"/w/load.php?debug=false&amp;lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=vector\" rel=\"stylesheet\"/>\n<meta content=\"MediaWiki 1.33.0-wmf.18\" name=\"generator\"/>\n<meta content=\"origin\" name=\"referrer\"/>\n<meta content=\"origin-when-crossorigin\" name=\"referrer\"/>\n<meta content=\"origin-when-cross-origin\" name=\"referrer\"/>\n<link href=\"android-app://org.wikipedia/http/en.m.wikipedia.org/wiki/Action_selection\" rel=\"alternate\"/>\n<link href=\"/w/index.php?title=Action_selection&amp;action=edit\" rel=\"alternate\" title=\"Edit this page\" type=\"application/x-wiki\"/>\n<link href=\"/w/index.php?title=Action_selection&amp;action=edit\" rel=\"edit\" title=\"Edit this page\"/>\n<link href=\"/static/apple-touch/wikipedia.png\" rel=\"apple-touch-icon\"/>\n<link href=\"/static/favicon/wikipedia.ico\" rel=\"shortcut icon\"/>\n<link href=\"/w/opensearch_desc.php\" rel=\"search\" title=\"Wikipedia (en)\" type=\"application/opensearchdescription+xml\"/>\n<link href=\"//en.wikipedia.org/w/api.php?action=rsd\" rel=\"EditURI\" type=\"application/rsd+xml\"/>\n<link href=\"//creativecommons.org/licenses/by-sa/3.0/\" rel=\"license\"/>\n<link href=\"https://en.wikipedia.org/wiki/Action_selection\" rel=\"canonical\"/>\n<link href=\"//login.wikimedia.org\" rel=\"dns-prefetch\"/>\n<link href=\"//meta.wikimedia.org\" rel=\"dns-prefetch\"/>\n<!--[if lt IE 9]><script src=\"/w/load.php?debug=false&amp;lang=en&amp;modules=html5shiv&amp;only=scripts&amp;skin=vector&amp;sync=1\"></script><![endif]-->\n</head>\n<body class=\"mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject mw-editable page-Action_selection rootpage-Action_selection skin-vector action-view\"> <div class=\"noprint\" id=\"mw-page-base\"></div>\n<div class=\"noprint\" id=\"mw-head-base\"></div>\n<div class=\"mw-body\" id=\"content\" role=\"main\">\n<a id=\"top\"></a>\n<div class=\"mw-body-content\" id=\"siteNotice\"><!-- CentralNotice --></div><div class=\"mw-indicators mw-body-content\">\n</div>\n<h1 class=\"firstHeading\" id=\"firstHeading\" lang=\"en\">Action selection</h1> <div class=\"mw-body-content\" id=\"bodyContent\">\n<div class=\"noprint\" id=\"siteSub\">From Wikipedia, the free encyclopedia</div> <div id=\"contentSub\"></div>\n<div id=\"jump-to-nav\"></div> <a class=\"mw-jump-link\" href=\"#mw-head\">Jump to navigation</a>\n<a class=\"mw-jump-link\" href=\"#p-search\">Jump to search</a>\n<div class=\"mw-content-ltr\" dir=\"ltr\" id=\"mw-content-text\" lang=\"en\"><div class=\"mw-parser-output\"><p><b>Action selection</b> is a way of characterizing the most basic problem of intelligent systems: what to do next. In <a href=\"/wiki/Artificial_intelligence\" title=\"Artificial intelligence\">artificial intelligence</a> and computational <a href=\"/wiki/Cognitive_science\" title=\"Cognitive science\">cognitive science</a>, \"the action selection problem\" is typically associated with <a class=\"mw-redirect\" href=\"/wiki/Intelligent_agents\" title=\"Intelligent agents\">intelligent agents</a> and <a href=\"/wiki/Animat\" title=\"Animat\">animats</a>—artificial systems that exhibit complex behaviour in an <a class=\"mw-redirect\" href=\"/wiki/Agent_environment\" title=\"Agent environment\">agent environment</a>. The term is also sometimes used in <a href=\"/wiki/Ethology\" title=\"Ethology\">ethology</a> or animal behavior.\n</p><p>One problem for understanding action selection is determining the level of abstraction used for specifying an \"act\". At the most basic level of abstraction, an atomic act could be anything from <i>contracting a muscle cell</i> to <i>provoking a war</i>. Typically for any one action-selection mechanism, the set of possible actions is predefined and fixed.\n</p><p>Most researchers working in this field place high demands on their agents: \n</p>\n<ul><li>The acting <a href=\"/wiki/Intelligent_agent\" title=\"Intelligent agent\">agent</a> typically must select its action in <a class=\"mw-redirect\" href=\"/wiki/Agent_environment\" title=\"Agent environment\">dynamic</a> and <a class=\"mw-redirect\" href=\"/wiki/Agent_environment\" title=\"Agent environment\">unpredictable</a> environments.</li>\n<li>The agents typically act in <a href=\"/wiki/Real-time_computing\" title=\"Real-time computing\">real time</a>; therefore they must make decisions in a timely fashion.</li>\n<li>The agents are normally created to perform several different tasks. These tasks may conflict for resource allocation (e.g. can the agent put out a fire and deliver a cup of coffee at the same time?)</li>\n<li>The environment the agents operate in may include <a class=\"mw-redirect\" href=\"/wiki/Humans\" title=\"Humans\">humans</a>, who may make things more difficult for the agent (either intentionally or by attempting to assist.)</li>\n<li>The agents themselves are often intended to <a class=\"mw-redirect\" href=\"/wiki/Computer_model\" title=\"Computer model\">model</a> animals or humans, and animal/human <a class=\"mw-redirect\" href=\"/wiki/Behaviour\" title=\"Behaviour\">behaviour</a> is quite complicated.</li></ul>\n<p>For these reasons action selection is not trivial and attracts a good deal of research.\n</p>\n<div class=\"toc\" id=\"toc\"><input class=\"toctogglecheckbox\" id=\"toctogglecheckbox\" role=\"button\" style=\"display:none\" type=\"checkbox\"/><div class=\"toctitle\" dir=\"ltr\" lang=\"en\"><h2>Contents</h2><span class=\"toctogglespan\"><label class=\"toctogglelabel\" for=\"toctogglecheckbox\"></label></span></div>\n<ul>\n<li class=\"toclevel-1 tocsection-1\"><a href=\"#Characteristics_of_the_action_selection_problem\"><span class=\"tocnumber\">1</span> <span class=\"toctext\">Characteristics of the action selection problem</span></a></li>\n<li class=\"toclevel-1 tocsection-2\"><a href=\"#AI_mechanisms\"><span class=\"tocnumber\">2</span> <span class=\"toctext\">AI mechanisms</span></a>\n<ul>\n<li class=\"toclevel-2 tocsection-3\"><a href=\"#Symbolic_approaches\"><span class=\"tocnumber\">2.1</span> <span class=\"toctext\">Symbolic approaches</span></a></li>\n<li class=\"toclevel-2 tocsection-4\"><a href=\"#Distributed_approaches\"><span class=\"tocnumber\">2.2</span> <span class=\"toctext\">Distributed approaches</span></a></li>\n<li class=\"toclevel-2 tocsection-5\"><a href=\"#Dynamic_planning_approaches\"><span class=\"tocnumber\">2.3</span> <span class=\"toctext\">Dynamic planning approaches</span></a></li>\n<li class=\"toclevel-2 tocsection-6\"><a href=\"#Others\"><span class=\"tocnumber\">2.4</span> <span class=\"toctext\">Others</span></a></li>\n</ul>\n</li>\n<li class=\"toclevel-1 tocsection-7\"><a href=\"#Theories_of_action_selection_in_nature\"><span class=\"tocnumber\">3</span> <span class=\"toctext\">Theories of action selection in nature</span></a>\n<ul>\n<li class=\"toclevel-2 tocsection-8\"><a href=\"#AI_models_of_neural_action_selection\"><span class=\"tocnumber\">3.1</span> <span class=\"toctext\">AI models of neural action selection</span></a></li>\n</ul>\n</li>\n<li class=\"toclevel-1 tocsection-9\"><a href=\"#See_also\"><span class=\"tocnumber\">4</span> <span class=\"toctext\">See also</span></a></li>\n<li class=\"toclevel-1 tocsection-10\"><a href=\"#References\"><span class=\"tocnumber\">5</span> <span class=\"toctext\">References</span></a></li>\n<li class=\"toclevel-1 tocsection-11\"><a href=\"#Further_reading\"><span class=\"tocnumber\">6</span> <span class=\"toctext\">Further reading</span></a></li>\n<li class=\"toclevel-1 tocsection-12\"><a href=\"#External_links\"><span class=\"tocnumber\">7</span> <span class=\"toctext\">External links</span></a></li>\n</ul>\n</div>\n<h2><span class=\"mw-headline\" id=\"Characteristics_of_the_action_selection_problem\">Characteristics of the action selection problem</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Action_selection&amp;action=edit&amp;section=1\" title=\"Edit section: Characteristics of the action selection problem\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>The main problem for action selection is <a href=\"/wiki/Complexity\" title=\"Complexity\">complexity</a>. Since all <a href=\"/wiki/Computation\" title=\"Computation\">computation</a> takes both time and space (in memory), agents cannot possibly consider every option available to them at every instant in time. Consequently, they must be <a href=\"/wiki/Bias\" title=\"Bias\">biased</a>, and constrain their search in some way. For AI, the question of action selection is <i>what is the best way to constrain this search</i>? For biology and ethology, the question is <i>how do various types of animals constrain their search? Do all animals use the same approaches? Why do they use the ones they do?</i>\n</p><p>One fundamental question about action selection is whether it is really a problem at all for an agent, or whether it is just a description of an <a href=\"/wiki/Emergence\" title=\"Emergence\">emergent</a> property of an intelligent agent's behavior. However, if we consider how we are going to build an intelligent agent, then it becomes apparent there must be <i>some</i> mechanism for action selection. This mechanism may be highly distributed (as in the case of distributed organisms such as <a class=\"mw-redirect\" href=\"/wiki/Social_insect\" title=\"Social insect\">social insect</a> colonies or <a href=\"/wiki/Slime_mold\" title=\"Slime mold\">slime mold</a>) or it may be a special-purpose module.\n</p><p>The action selection mechanism (ASM) determines not only the agent’s actions in terms of impact on the world, but also directs its perceptual <a href=\"/wiki/Attention\" title=\"Attention\">attention</a>, and updates its <a href=\"/wiki/Memory\" title=\"Memory\">memory</a>. These <a class=\"mw-redirect\" href=\"/wiki/Egocentric\" title=\"Egocentric\">egocentric</a> sorts of actions may in turn result in modifying the agents basic behavioural capacities, particularly in that updating memory implies some form of <a href=\"/wiki/Machine_learning\" title=\"Machine learning\">machine learning</a> is possible. Ideally, action selection itself should also be able to learn and adapt, but there are many problems of <a href=\"/wiki/Combinatorics\" title=\"Combinatorics\">combinatorial complexity</a> and computational <a class=\"mw-redirect\" href=\"/wiki/Tractable_problem\" title=\"Tractable problem\">tractability</a> that may require restricting the search space for learning.\n</p><p>In AI, an ASM is also sometimes either referred to as an <a href=\"/wiki/Agent_architecture\" title=\"Agent architecture\">agent architecture</a> or thought of as a substantial part of one.\n</p>\n<h2><span class=\"mw-headline\" id=\"AI_mechanisms\">AI mechanisms</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Action_selection&amp;action=edit&amp;section=2\" title=\"Edit section: AI mechanisms\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>Generally, artificial action selection mechanisms can be divided into several categories: <a href=\"/wiki/Automated_planning_and_scheduling\" title=\"Automated planning and scheduling\">symbol-based systems</a> sometimes known as classical planning, <a class=\"mw-redirect\" href=\"/wiki/Distributed_systems\" title=\"Distributed systems\">distributed solutions</a>, and reactive or <a href=\"/wiki/Reactive_planning\" title=\"Reactive planning\">dynamic planning</a>. Some approaches do not fall neatly into any one of these categories. Others are really more about providing <a class=\"mw-redirect\" href=\"/wiki/Scientific_model\" title=\"Scientific model\">scientific models</a> than practical AI control; these last are described further in the next section.\n</p>\n<h3><span class=\"mw-headline\" id=\"Symbolic_approaches\">Symbolic approaches</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Action_selection&amp;action=edit&amp;section=3\" title=\"Edit section: Symbolic approaches\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<div class=\"hatnote navigation-not-searchable\" role=\"note\">Main article: <a href=\"/wiki/Automated_planning_and_scheduling\" title=\"Automated planning and scheduling\">Automated planning and scheduling</a></div>\n<p>Early in the <a href=\"/wiki/History_of_artificial_intelligence\" title=\"History of artificial intelligence\">history of artificial intelligence</a>, it was assumed that the best way for an agent to choose what to do next would be to compute a <a class=\"mw-redirect\" href=\"/wiki/Logical_argument\" title=\"Logical argument\">probably optimal</a> plan, and then execute that plan. This led to the <a href=\"/wiki/Physical_symbol_system\" title=\"Physical symbol system\">physical symbol system</a> hypothesis, that a physical agent that can manipulate symbols is <a class=\"mw-redirect\" href=\"/wiki/Sufficient\" title=\"Sufficient\">necessary and sufficient</a> for intelligence. Many <a class=\"mw-redirect\" href=\"/wiki/Software_agents\" title=\"Software agents\">software agents</a> still use this approach for action selection. It normally requires describing all sensor readings, the world, all of ones actions and all of one's goals in some form of <a class=\"mw-redirect\" href=\"/wiki/Predicate_logic\" title=\"Predicate logic\">predicate logic</a>. Critics of this approach complain that it is too slow for real-time planning and that, despite the proofs, it is still unlikely to produce optimal plans because reducing descriptions of reality to logic is a process prone to errors.\n</p><p><a href=\"/wiki/Satisficing\" title=\"Satisficing\">Satisficing</a> is a decision-making strategy which attempts to meet criteria for adequacy, rather than identify an optimal solution. A satisficing strategy may often, in fact, be (near) optimal if the costs of the decision-making process itself, such as the cost of obtaining complete information, are considered in the outcome calculus.\n</p><p><b>Goal driven architectures</b> – In these <a href=\"/wiki/Symbol\" title=\"Symbol\">symbolic</a> architectures, the agent's behaviour is typically described by a set of goals. Each goal can be achieved by a process or an activity, which is described by a prescripted plan. The agent must just decide which process to carry on to accomplish a given goal. The plan can expand to subgoals, which makes the process slightly recursive. Technically, more or less, the plans exploits condition-rules. These architectures are <a href=\"/wiki/Reactive_planning\" title=\"Reactive planning\">reactive</a> or hybrid. Classical examples of goal driven architectures are implementable refinements of <a class=\"mw-redirect\" href=\"/wiki/BDI_software_agent\" title=\"BDI software agent\">belief-desire-intention</a> architecture like <a class=\"external text\" href=\"http://www.marcush.net/IRS/irs_downloads.html\" rel=\"nofollow\">JAM</a> or <a class=\"external text\" href=\"http://urtax.ms.mff.cuni.cz/ive/public/about.php\" rel=\"nofollow\">IVE</a>.  \n</p>\n<h3><span class=\"mw-headline\" id=\"Distributed_approaches\">Distributed approaches</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Action_selection&amp;action=edit&amp;section=4\" title=\"Edit section: Distributed approaches\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>In contrast to the symbolic approach, distributed systems of action selection actually have no one \"box\" in the agent which decides the next action. At least in their idealized form, distributed systems have many <a class=\"mw-redirect\" href=\"/wiki/Module_(programming)\" title=\"Module (programming)\">modules</a> running in parallel and determining the best action based on local expertise. In these idealized systems, overall coherence is expected to emerge somehow, possibly through careful design of the interacting components. This approach is often inspired by <a class=\"mw-redirect\" href=\"/wiki/Artificial_neural_networks\" title=\"Artificial neural networks\">artificial neural networks</a> research. In practice, there is almost always <i>some</i> centralised system determining which module is \"the most active\" or has the most salience. There is evidence real biological brains also have such <a class=\"mw-redirect\" href=\"/wiki/Executive_system\" title=\"Executive system\">executive decision systems</a> which evaluate which of the competing systems deserves the most <a href=\"/wiki/Attention\" title=\"Attention\">attention</a>, or more properly, has its desired actions <a class=\"mw-redirect\" href=\"/wiki/Disinhibited\" title=\"Disinhibited\">disinhibited</a>.\n</p>\n<ul><li><a class=\"new\" href=\"/w/index.php?title=ASMO_(cognitive_architecture)&amp;action=edit&amp;redlink=1\" title=\"ASMO (cognitive architecture) (page does not exist)\">ASMO</a> is an attention-based architecture developed by Rony Novianto. It orchestrates a diversity of modular distributed processes that can use their own representations and techniques to perceive the environment, process information, plan actions and propose actions to perform.</li>\n<li>Various types of <a href=\"/wiki/Winner-take-all_in_action_selection\" title=\"Winner-take-all in action selection\">winner-take-all</a> architectures, in which the single selected action takes full control of the motor system</li>\n<li><b>Spreading activation</b> including <a class=\"new\" href=\"/w/index.php?title=Maes_Nets_(ANA)&amp;action=edit&amp;redlink=1\" title=\"Maes Nets (ANA) (page does not exist)\">Maes Nets (ANA)</a></li>\n<li><b>Extended Rosenblatt &amp; Payton</b> is a spreading activation architecture developed by Toby Tyrrell in 1993. The agent's behaviour is stored in the form of a hierarchical <a class=\"mw-redirect\" href=\"/wiki/Connectionist\" title=\"Connectionist\">connectionism</a> network, which Tyrrell named free-flow hierarchy. Recently exploited for example by <a class=\"external text\" href=\"http://vrlab.epfl.ch/Publications/pdf/Sevin_Thalmann_CGI_05.pdf\" rel=\"nofollow\">de Sevin &amp; Thalmann</a> (2005) or <a class=\"external text\" href=\"http://cyber.felk.cvut.cz/gerstner/eth/download/dpdk2.pdf\" rel=\"nofollow\">Kadleček</a> (2001).</li>\n<li><b><a class=\"mw-redirect\" href=\"/wiki/Behavior_based_AI\" title=\"Behavior based AI\">Behavior based AI</a></b>, was a response to the slow speed of robots using symbolic action selection techniques. In this form, separate modules respond to different stimuli and generate their own responses. In the original form, the <a href=\"/wiki/Subsumption_architecture\" title=\"Subsumption architecture\">subsumption architecture</a>, these consisted of different layers which could monitor and suppress each other's inputs and outputs.</li>\n<li><b><a class=\"mw-redirect\" href=\"/wiki/Creatures_(artificial_life_program)\" title=\"Creatures (artificial life program)\">Creatures</a></b> are virtual pets from a computer game driven by three-layered <a href=\"/wiki/Artificial_neural_network\" title=\"Artificial neural network\">neural network</a>, which is adaptive. Their mechanism is reactive since the network at every time step determines the task that has to be performed by the pet. The network is described well in the paper of <a class=\"external text\" href=\"http://www.cp.eng.chula.ac.th/~vishnu/gameResearch/AI/creatures.pdf\" rel=\"nofollow\">Grand et al.</a> (1997) and in <a class=\"external text\" href=\"http://www.double.co.nz/creatures/\" rel=\"nofollow\">The Creatures Developer Resources</a>. See also the <a class=\"external text\" href=\"http://creatureswiki.net/\" rel=\"nofollow\">Creatures Wiki</a>.</li></ul>\n<h3><span class=\"mw-headline\" id=\"Dynamic_planning_approaches\">Dynamic planning approaches</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Action_selection&amp;action=edit&amp;section=5\" title=\"Edit section: Dynamic planning approaches\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>Because purely distributed systems are difficult to construct, many researchers have turned to using explicit hard-coded plans to determine the priorities of their system.\n</p><p>Dynamic or <a href=\"/wiki/Reactive_planning\" title=\"Reactive planning\">reactive planning</a> methods compute just one next action in every instant based on the current context and pre-scripted plans. In contrast to classical planning methods, reactive or dynamic approaches do not suffer <a href=\"/wiki/Combinatorial_explosion\" title=\"Combinatorial explosion\">combinatorial explosion</a>. On the other hand, they are sometimes seen as too rigid to be considered <a href=\"/wiki/Artificial_general_intelligence\" title=\"Artificial general intelligence\">strong AI</a>, since the plans are coded in advance. At the same time, natural intelligence can be rigid in some contexts although it is fluid and able to adapt in others.\n</p><p>Example dynamic planning mechanisms include:\n</p>\n<ul><li><b><a class=\"mw-redirect\" href=\"/wiki/Finite_state_machine\" title=\"Finite state machine\">Finite-state machines</a></b> These are <a href=\"/wiki/Reactive_planning\" title=\"Reactive planning\">reactive</a> architectures used mostly for computer game agents, in particular for first-person shooters <a class=\"mw-redirect\" href=\"/wiki/Computer_game_bot\" title=\"Computer game bot\">bots</a>, or for virtual movie actors. Typically, the state-machines are hierarchical. For concrete game examples, see <a class=\"external text\" href=\"http://www.gamasutra.com/gdc2005/features/20050311/isla_pfv.htm\" rel=\"nofollow\">Halo 2 bots paper</a> by Damian Isla (2005) or <a class=\"external text\" href=\"http://www.kbs.twi.tudelft.nl/Publications/MSc/2001-VanWaveren-MSc.html\" rel=\"nofollow\">the Master's Thesis about Quake III bots</a> by Jan Paul van Waveren (2001). For a movie example, see <a class=\"mw-redirect\" href=\"/wiki/Softimage\" title=\"Softimage\">Softimage</a>.</li>\n<li>Other <b>structured reactive plans</b> tend to look a little more like conventional plans, often with ways to represent <a class=\"mw-redirect\" href=\"/wiki/Hierarchical\" title=\"Hierarchical\">hierarchical</a> and <a class=\"mw-redirect\" href=\"/wiki/Sequential\" title=\"Sequential\">sequential</a> structure. Some, such as PRS's 'acts', have support for <a class=\"mw-redirect\" href=\"/wiki/Partial_plan\" title=\"Partial plan\">partial plans</a>.<sup class=\"reference\" id=\"cite_ref-1\"><a href=\"#cite_note-1\">[1]</a></sup> Many agent architectures from the mid-1990s included such plans as a \"middle layer\" that provided organization for low-level <a class=\"mw-redirect\" href=\"/wiki/Behavior_based_AI\" title=\"Behavior based AI\">behavior modules</a> while being directed by a higher level real-time planner. Despite this supposed <a href=\"/wiki/Interoperability\" title=\"Interoperability\">interoperability</a> with automated planners, most structured reactive plans are hand coded (Bryson 2001, ch. 3). Examples of structured reactive plans include <a class=\"new\" href=\"/w/index.php?title=James_Firby&amp;action=edit&amp;redlink=1\" title=\"James Firby (page does not exist)\">James Firby</a>'s <a class=\"external text\" href=\"http://people.cs.uchicago.edu/~firby/raps/\" rel=\"nofollow\">RAP</a> System and the <a class=\"mw-redirect\" href=\"/wiki/Nils_Nilsson_(researcher)\" title=\"Nils Nilsson (researcher)\">Nils Nilsson</a>'s <a class=\"external text\" href=\"http://ai.stanford.edu/users/nilsson/trweb/tr.html\" rel=\"nofollow\">Teleo-reactive plans</a>. PRS, RAPs &amp; TRP are no longer developed or supported. One still-active (as of 2006) descendent of this approach is the Parallel-rooted Ordered Slip-stack Hierarchical (or <a class=\"external text\" href=\"http://www.cs.bath.ac.uk/~jjb/web/posh.html\" rel=\"nofollow\">POSH</a>) action selection system, which is a part of Joanna Bryson's Behaviour Oriented Design.</li></ul>\n<p>Sometimes to attempt to address the perceived inflexibility of dynamic planning, hybrid techniques are used. In these, a more conventional AI planning system searches for new plans when the agent has spare time, and updates the dynamic plan library when it finds good solutions. The important aspect of any such system is that when the agent needs to select an action, some solution exists that can be used immediately (see further <a href=\"/wiki/Anytime_algorithm\" title=\"Anytime algorithm\">anytime algorithm</a>).\n</p>\n<h3><span class=\"mw-headline\" id=\"Others\">Others</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Action_selection&amp;action=edit&amp;section=6\" title=\"Edit section: Others\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<ul><li><a class=\"external text\" href=\"http://CogniTeam.com\" rel=\"nofollow\">CogniTAO</a> is a decision making engine it based on <a href=\"/wiki/Belief%E2%80%93desire%E2%80%93intention_software_model\" title=\"Belief–desire–intention software model\">BDI</a> (belief-desire-intention), it includes built in teamwork capabilities.</li>\n<li><a href=\"/wiki/Soar_(cognitive_architecture)\" title=\"Soar (cognitive architecture)\">Soar</a> is a <a href=\"/wiki/Symbol\" title=\"Symbol\">symbolic</a> <a href=\"/wiki/Cognitive_architecture\" title=\"Cognitive architecture\">cognitive architecture</a>. It is based on condition-action rules known as <a href=\"/wiki/Production_system_(computer_science)\" title=\"Production system (computer science)\">productions</a>. Programmers can use the Soar development toolkit for building both reactive and planning agents, or any compromise between these two extremes.</li>\n<li><b><a class=\"external text\" href=\"http://www.ai-center.com/projects/excalibur/index.html\" rel=\"nofollow\">Excalibur</a></b> was a research project led by Alexander Nareyek featuring any-time planning agents for computer games. The architecture is based on structural <a href=\"/wiki/Constraint_satisfaction\" title=\"Constraint satisfaction\">constraint satisfaction</a>, which is an advanced <a href=\"/wiki/Artificial_intelligence\" title=\"Artificial intelligence\">artificial intelligence</a> technique.</li>\n<li><a href=\"/wiki/ACT-R\" title=\"ACT-R\">ACT-R</a> is similar to Soar. It includes a <a href=\"/wiki/Bayesian_inference\" title=\"Bayesian inference\">Bayesian</a> learning system to help prioritize the productions.</li>\n<li>ABL/Hap</li>\n<li><b><a href=\"/wiki/Fuzzy_control_system\" title=\"Fuzzy control system\">Fuzzy architectures</a></b> The <a href=\"/wiki/Fuzzy_logic\" title=\"Fuzzy logic\">Fuzzy approach</a> in action selection produces more smooth behaviour than can be produced by architectures exploiting boolean condition-action rules (like Soar or POSH). These architectures are mostly <a href=\"/wiki/Reactive_planning\" title=\"Reactive planning\">reactive</a> and <a href=\"/wiki/Symbol\" title=\"Symbol\">symbolic</a>.</li></ul>\n<h2><span class=\"mw-headline\" id=\"Theories_of_action_selection_in_nature\">Theories of action selection in nature</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Action_selection&amp;action=edit&amp;section=7\" title=\"Edit section: Theories of action selection in nature\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>Many dynamic models of artificial action selection were originally inspired by research in <a href=\"/wiki/Ethology\" title=\"Ethology\">ethology</a>. In particular, <a href=\"/wiki/Konrad_Lorenz\" title=\"Konrad Lorenz\">Konrad Lorenz</a> and <a href=\"/wiki/Nikolaas_Tinbergen\" title=\"Nikolaas Tinbergen\">Nikolaas Tinbergen</a> provided the idea of an <a class=\"mw-redirect\" href=\"/wiki/Innate_releasing_mechanism\" title=\"Innate releasing mechanism\">innate releasing mechanism</a> to explain instinctive behaviors (<a href=\"/wiki/Fixed_action_pattern\" title=\"Fixed action pattern\">fixed action patterns</a>). Influenced by the ideas of <a href=\"/wiki/William_McDougall_(psychologist)\" title=\"William McDougall (psychologist)\">William McDougall</a>, Lorenz developed this into a \"<a class=\"new\" href=\"/w/index.php?title=Psychohydraulic&amp;action=edit&amp;redlink=1\" title=\"Psychohydraulic (page does not exist)\">psychohydraulic</a>\" model of the <a href=\"/wiki/Motivation\" title=\"Motivation\">motivation</a> of behavior. In ethology, these ideas were influential in the 1960s, but they are now regarded as outdated because of their use of an <a href=\"/wiki/Energy_flow_(ecology)\" title=\"Energy flow (ecology)\">energy flow</a> metaphor; the <a href=\"/wiki/Nervous_system\" title=\"Nervous system\">nervous system</a> and the control of behavior are now normally treated as involving information transmission rather than energy flow. Dynamic plans and neural networks are more similar to information transmission, while spreading activation is more similar to the diffuse control of emotional / hormonal systems.\n</p><p><a href=\"/wiki/Stan_Franklin\" title=\"Stan Franklin\">Stan Franklin</a> has proposed that <b>action selection</b> is the right perspective to take in understanding the role and evolution of <a href=\"/wiki/Mind\" title=\"Mind\">mind</a>.  See his page on <a class=\"external text\" href=\"http://www.msci.memphis.edu/~franklin/paradigm.html\" rel=\"nofollow\">the action selection paradigm</a>.\n</p>\n<h3><span class=\"mw-headline\" id=\"AI_models_of_neural_action_selection\">AI models of neural action selection</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Action_selection&amp;action=edit&amp;section=8\" title=\"Edit section: AI models of neural action selection\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>Some researchers create elaborate models of neural action selection. See for example:\n</p>\n<ul><li>The <a class=\"external text\" href=\"http://ccnlab.colorado.edu/mambo/\" rel=\"nofollow\">Computational Cognitive Neuroscience Lab</a> (CU Boulder).</li>\n<li>The <a class=\"external text\" href=\"http://www.abrg.group.shef.ac.uk/\" rel=\"nofollow\">Adaptive Behaviour Research Group</a> (Sheffield).</li></ul>\n<h2><span class=\"mw-headline\" id=\"See_also\">See also</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Action_selection&amp;action=edit&amp;section=9\" title=\"Edit section: See also\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<div aria-label=\"Portals\" class=\"noprint portal plainlist tright\" role=\"navigation\" style=\"margin:0.5em 0 0.5em 1em;border:solid #aaa 1px\">\n<ul style=\"display:table;box-sizing:border-box;padding:0.1em;max-width:175px;background:#f9f9f9;font-size:85%;line-height:110%;font-style:italic;font-weight:bold\">\n<li style=\"display:table-row\"><span style=\"display:table-cell;padding:0.2em;vertical-align:middle;text-align:center\"><a class=\"image\" href=\"/wiki/File:Animation2.gif\"><img alt=\"icon\" class=\"noviewer\" data-file-height=\"78\" data-file-width=\"48\" decoding=\"async\" height=\"28\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/c/c0/Animation2.gif/17px-Animation2.gif\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/c/c0/Animation2.gif/26px-Animation2.gif 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/c/c0/Animation2.gif/34px-Animation2.gif 2x\" width=\"17\"/></a></span><span style=\"display:table-cell;padding:0.2em 0.2em 0.2em 0.3em;vertical-align:middle\"><a href=\"/wiki/Portal:Artificial_intelligence\" title=\"Portal:Artificial intelligence\">Artificial intelligence portal</a></span></li></ul></div>\n<ul><li><a href=\"/wiki/Action_description_language\" title=\"Action description language\">Action description language</a></li>\n<li><a href=\"/wiki/Utility_system\" title=\"Utility system\">Utility system</a></li>\n<li><a href=\"/wiki/Expert_system\" title=\"Expert system\">Expert system</a></li>\n<li><a class=\"mw-redirect\" href=\"/wiki/Game_artificial_intelligence\" title=\"Game artificial intelligence\">Game artificial intelligence</a></li>\n<li><a href=\"/wiki/Inference_engine\" title=\"Inference engine\">Inference engine</a></li>\n<li><a href=\"/wiki/Intelligent_agent\" title=\"Intelligent agent\">Intelligent agent</a></li>\n<li><a href=\"/wiki/OPS5\" title=\"OPS5\">OPS5</a></li>\n<li><a href=\"/wiki/Production_system_(computer_science)\" title=\"Production system (computer science)\">Production system</a></li>\n<li><a href=\"/wiki/Rete_algorithm\" title=\"Rete algorithm\">Rete algorithm</a></li>\n<li><a href=\"/wiki/Reinforcement_learning\" title=\"Reinforcement learning\">Reinforcement learning</a></li>\n<li><a class=\"mw-redirect\" href=\"/wiki/Robot_intelligence\" title=\"Robot intelligence\">Robot intelligence</a></li></ul>\n<h2><span class=\"mw-headline\" id=\"References\">References</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Action_selection&amp;action=edit&amp;section=10\" title=\"Edit section: References\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<div class=\"reflist\" style=\"list-style-type: decimal;\">\n<div class=\"mw-references-wrap\"><ol class=\"references\">\n<li id=\"cite_note-1\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-1\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation web\">Karen L. Myers. <a class=\"external text\" href=\"http://www.ai.sri.com/~prs/\" rel=\"nofollow\">\"PRS-CL: A Procedural Reasoning System\"</a>. <i><a href=\"/wiki/Artificial_Intelligence_Center\" title=\"Artificial Intelligence Center\">Artificial Intelligence Center</a></i>. <a href=\"/wiki/SRI_International\" title=\"SRI International\">SRI International</a><span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2013-06-13</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Artificial+Intelligence+Center&amp;rft.atitle=PRS-CL%3A+A+Procedural+Reasoning+System&amp;rft.au=Karen+L.+Myers&amp;rft_id=http%3A%2F%2Fwww.ai.sri.com%2F~prs%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AAction+selection\"></span><style data-mw-deduplicate=\"TemplateStyles:r879151008\">.mw-parser-output cite.citation{font-style:inherit}.mw-parser-output .citation q{quotes:\"\\\"\"\"\\\"\"\"'\"\"'\"}.mw-parser-output .citation .cs1-lock-free a{background:url(\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png\")no-repeat;background-position:right .1em center}.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:url(\"//upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Lock-gray-alt-2.svg/9px-Lock-gray-alt-2.svg.png\")no-repeat;background-position:right .1em center}.mw-parser-output .citation .cs1-lock-subscription a{background:url(\"//upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Lock-red-alt-2.svg/9px-Lock-red-alt-2.svg.png\")no-repeat;background-position:right .1em center}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration{color:#555}.mw-parser-output .cs1-subscription span,.mw-parser-output .cs1-registration span{border-bottom:1px dotted;cursor:help}.mw-parser-output .cs1-ws-icon a{background:url(\"//upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Wikisource-logo.svg/12px-Wikisource-logo.svg.png\")no-repeat;background-position:right .1em center}.mw-parser-output code.cs1-code{color:inherit;background:inherit;border:inherit;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;font-size:100%}.mw-parser-output .cs1-visible-error{font-size:100%}.mw-parser-output .cs1-maint{display:none;color:#33aa33;margin-left:0.3em}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration,.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left,.mw-parser-output .cs1-kern-wl-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right,.mw-parser-output .cs1-kern-wl-right{padding-right:0.2em}</style></span>\n</li>\n</ol></div></div>\n<h2><span class=\"mw-headline\" id=\"Further_reading\">Further reading</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Action_selection&amp;action=edit&amp;section=11\" title=\"Edit section: Further reading\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<ul><li>Bratman, M.: Intention, plans, and practical reason. Cambridge, Mass: Harvard University Press (1987)</li>\n<li>Brom, C., Lukavský, J., Šerý, O., Poch, T., Šafrata, P.: <a class=\"external text\" href=\"http://urtax.ms.mff.cuni.cz/ive\" rel=\"nofollow\">Affordances and level-of-detail AI for virtual humans</a>. In: Proceedings of Game Set and Match 2, Delft (2006)</li>\n<li>Bryson, J.: <a class=\"external text\" href=\"ftp://publications.ai.mit.edu/ai-publications/2002/AITR-2002-003.pdf\" rel=\"nofollow\">Intelligence by Design: Principles of Modularity and Coordination for Engineering Complex Adaptive Agents</a>. PhD thesis, <a class=\"external text\" href=\"http://publications.csail.mit.edu/ai/\" rel=\"nofollow\">Massachusetts Institute of Technology</a> (2001)</li>\n<li>Champandard, A. J.: AI Game Development: Synthetic Creatures with learning and Reactive Behaviors. New Riders, USA (2003)</li>\n<li>Grand, S., Cliff, D., Malhotra, A.: Creatures: Artificial life autonomous software-agents for home entertainment. In: Johnson, W. L. (eds.): Proceedings of the First International Conference on Autonomous Agents. ACM press (1997) 22-29</li>\n<li>Huber, M. J.: <a class=\"external text\" href=\"http://www.marcush.net/IRS/irs_downloads.html\" rel=\"nofollow\">JAM: A BDI-theoretic mobile agent architecture</a>. In: Proceedings of the Third International Conference on Autonomous Agents (Agents'99). Seattle (1999) 236-243</li>\n<li>Isla, D.: <a class=\"external text\" href=\"http://www.gamasutra.com/gdc2005/features/20050311/isla_pfv.htm\" rel=\"nofollow\">Handling complexity in Halo 2</a>. In: Gamastura online, 03/11 (2005)</li>\n<li>Maes, P.: The agent network architecture (ANA). In: SIGART Bulletin, 2 (4), pages 115–120 (1991)</li>\n<li>Nareyek, A. <a class=\"external text\" href=\"http://www.ai-center.com/projects/excalibur/index.html\" rel=\"nofollow\">Excalibur project</a></li>\n<li>Reynolds, C. W. Flocks, Herds, and Schools: A Distributed Behavioral Model. In: Computer Graphics, 21(4) (SIGGRAPH '87 Conference Proceedings) (1987) 25-34.</li>\n<li>de Sevin, E. Thalmann, D.:A motivational Model of Action Selection for Virtual Humans. In: Computer Graphics International (CGI), IEEE Computer SocietyPress, New York (2005)</li>\n<li>Tyrrell, T.: Computational Mechanisms for Action Selection. Ph.D. Dissertation. Centre for Cognitive Science, University of Edinburgh (1993)</li>\n<li>van Waveren, J. M. P.: The Quake III Arena Bot. Master thesis. Faculty ITS, University of Technology Delft (2001)</li>\n<li>Wooldridge, M. An Introduction to MultiAgent Systems. John Wiley &amp; Sons (2002)</li></ul>\n<h2><span class=\"mw-headline\" id=\"External_links\">External links</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Action_selection&amp;action=edit&amp;section=12\" title=\"Edit section: External links\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<ul><li>The University of Memphis: <a class=\"external text\" href=\"http://www.msci.memphis.edu/~classweb/comp7990/fall2002/action.htm\" rel=\"nofollow\">Agents by action selection</a></li>\n<li>Michael Wooldridge: <a class=\"external text\" href=\"http://www.csc.liv.ac.uk/~mjw/pubs/mas99.pdf\" rel=\"nofollow\">Introduction to agents and their action selection mechanisms</a></li>\n<li>Cyril Brom: <a class=\"external text\" href=\"http://ksvi.mff.cuni.cz/~brom/teaching.html#umelebytosti\" rel=\"nofollow\">Slides on a course on action selection of artificial beings</a></li>\n<li><a class=\"external text\" href=\"http://sitemaker.umich.edu/soar\" rel=\"nofollow\">Soar project</a>. University of Michigan.</li>\n<li><a class=\"external text\" href=\"http://publishing.royalsoc.ac.uk/natural-action\" rel=\"nofollow\">Modelling natural action selection</a>, a special issue published by <a class=\"mw-redirect\" href=\"/wiki/The_Royal_Society\" title=\"The Royal Society\">The Royal Society</a> - <a href=\"/wiki/Philosophical_Transactions_of_the_Royal_Society\" title=\"Philosophical Transactions of the Royal Society\">Philosophical Transactions of the Royal Society</a></li></ul>\n<!-- \nNewPP limit report\nParsed by mw1273\nCached time: 20190224215612\nCache expiry: 2073600\nDynamic content: false\nCPU time usage: 0.116 seconds\nReal time usage: 0.165 seconds\nPreprocessor visited node count: 261/1000000\nPreprocessor generated node count: 0/1500000\nPost‐expand include size: 3196/2097152 bytes\nTemplate argument size: 80/2097152 bytes\nHighest expansion depth: 7/40\nExpensive parser function count: 1/500\nUnstrip recursion depth: 1/20\nUnstrip post‐expand size: 2875/5000000 bytes\nNumber of Wikibase entities loaded: 0/400\nLua time usage: 0.051/10.000 seconds\nLua memory usage: 1.61 MB/50 MB\n-->\n<!--\nTransclusion expansion time report (%,ms,calls,template)\n100.00%  119.221      1 -total\n 65.13%   77.645      1 Template:Reflist\n 52.48%   62.570      1 Template:Cite_web\n 21.12%   25.178      1 Template:Main\n 12.23%   14.586      1 Template:Portal\n  2.47%    2.949      1 Template:Main_other\n-->\n<!-- Saved in parser cache with key enwiki:pcache:idhash:5033373-0!canonical and timestamp 20190224215612 and revision id 843537296\n -->\n</div><noscript><img alt=\"\" height=\"1\" src=\"//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1\" style=\"border: none; position: absolute;\" title=\"\" width=\"1\"/></noscript></div> <div class=\"printfooter\">\n\t\t\t\t\t\tRetrieved from \"<a dir=\"ltr\" href=\"https://en.wikipedia.org/w/index.php?title=Action_selection&amp;oldid=843537296\">https://en.wikipedia.org/w/index.php?title=Action_selection&amp;oldid=843537296</a>\"\t\t\t\t\t</div>\n<div class=\"catlinks\" data-mw=\"interface\" id=\"catlinks\"><div class=\"mw-normal-catlinks\" id=\"mw-normal-catlinks\"><a href=\"/wiki/Help:Category\" title=\"Help:Category\">Categories</a>: <ul><li><a href=\"/wiki/Category:Artificial_intelligence\" title=\"Category:Artificial intelligence\">Artificial intelligence</a></li><li><a href=\"/wiki/Category:Motor_control\" title=\"Category:Motor control\">Motor control</a></li><li><a href=\"/wiki/Category:Motor_cognition\" title=\"Category:Motor cognition\">Motor cognition</a></li></ul></div></div> <div class=\"visualClear\"></div>\n</div>\n</div>\n<div id=\"mw-navigation\">\n<h2>Navigation menu</h2>\n<div id=\"mw-head\">\n<div aria-labelledby=\"p-personal-label\" id=\"p-personal\" role=\"navigation\">\n<h3 id=\"p-personal-label\">Personal tools</h3>\n<ul>\n<li id=\"pt-anonuserpage\">Not logged in</li><li id=\"pt-anontalk\"><a accesskey=\"n\" href=\"/wiki/Special:MyTalk\" title=\"Discussion about edits from this IP address [n]\">Talk</a></li><li id=\"pt-anoncontribs\"><a accesskey=\"y\" href=\"/wiki/Special:MyContributions\" title=\"A list of edits made from this IP address [y]\">Contributions</a></li><li id=\"pt-createaccount\"><a href=\"/w/index.php?title=Special:CreateAccount&amp;returnto=Action+selection\" title=\"You are encouraged to create an account and log in; however, it is not mandatory\">Create account</a></li><li id=\"pt-login\"><a accesskey=\"o\" href=\"/w/index.php?title=Special:UserLogin&amp;returnto=Action+selection\" title=\"You're encouraged to log in; however, it's not mandatory. [o]\">Log in</a></li> </ul>\n</div>\n<div id=\"left-navigation\">\n<div aria-labelledby=\"p-namespaces-label\" class=\"vectorTabs\" id=\"p-namespaces\" role=\"navigation\">\n<h3 id=\"p-namespaces-label\">Namespaces</h3>\n<ul>\n<li class=\"selected\" id=\"ca-nstab-main\"><span><a accesskey=\"c\" href=\"/wiki/Action_selection\" title=\"View the content page [c]\">Article</a></span></li><li id=\"ca-talk\"><span><a accesskey=\"t\" href=\"/wiki/Talk:Action_selection\" rel=\"discussion\" title=\"Discussion about the content page [t]\">Talk</a></span></li> </ul>\n</div>\n<div aria-labelledby=\"p-variants-label\" class=\"vectorMenu emptyPortlet\" id=\"p-variants\" role=\"navigation\">\n<input aria-labelledby=\"p-variants-label\" class=\"vectorMenuCheckbox\" type=\"checkbox\"/>\n<h3 id=\"p-variants-label\">\n<span>Variants</span>\n</h3>\n<ul class=\"menu\">\n</ul>\n</div>\n</div>\n<div id=\"right-navigation\">\n<div aria-labelledby=\"p-views-label\" class=\"vectorTabs\" id=\"p-views\" role=\"navigation\">\n<h3 id=\"p-views-label\">Views</h3>\n<ul>\n<li class=\"collapsible selected\" id=\"ca-view\"><span><a href=\"/wiki/Action_selection\">Read</a></span></li><li class=\"collapsible\" id=\"ca-edit\"><span><a accesskey=\"e\" href=\"/w/index.php?title=Action_selection&amp;action=edit\" title=\"Edit this page [e]\">Edit</a></span></li><li class=\"collapsible\" id=\"ca-history\"><span><a accesskey=\"h\" href=\"/w/index.php?title=Action_selection&amp;action=history\" title=\"Past revisions of this page [h]\">View history</a></span></li> </ul>\n</div>\n<div aria-labelledby=\"p-cactions-label\" class=\"vectorMenu emptyPortlet\" id=\"p-cactions\" role=\"navigation\">\n<input aria-labelledby=\"p-cactions-label\" class=\"vectorMenuCheckbox\" type=\"checkbox\"/>\n<h3 id=\"p-cactions-label\"><span>More</span></h3>\n<ul class=\"menu\">\n</ul>\n</div>\n<div id=\"p-search\" role=\"search\">\n<h3>\n<label for=\"searchInput\">Search</label>\n</h3>\n<form action=\"/w/index.php\" id=\"searchform\">\n<div id=\"simpleSearch\">\n<input accesskey=\"f\" id=\"searchInput\" name=\"search\" placeholder=\"Search Wikipedia\" title=\"Search Wikipedia [f]\" type=\"search\"/><input name=\"title\" type=\"hidden\" value=\"Special:Search\"/><input class=\"searchButton mw-fallbackSearchButton\" id=\"mw-searchButton\" name=\"fulltext\" title=\"Search Wikipedia for this text\" type=\"submit\" value=\"Search\"/><input class=\"searchButton\" id=\"searchButton\" name=\"go\" title=\"Go to a page with this exact name if it exists\" type=\"submit\" value=\"Go\"/> </div>\n</form>\n</div>\n</div>\n</div>\n<div id=\"mw-panel\">\n<div id=\"p-logo\" role=\"banner\"><a class=\"mw-wiki-logo\" href=\"/wiki/Main_Page\" title=\"Visit the main page\"></a></div>\n<div aria-labelledby=\"p-navigation-label\" class=\"portal\" id=\"p-navigation\" role=\"navigation\">\n<h3 id=\"p-navigation-label\">Navigation</h3>\n<div class=\"body\">\n<ul>\n<li id=\"n-mainpage-description\"><a accesskey=\"z\" href=\"/wiki/Main_Page\" title=\"Visit the main page [z]\">Main page</a></li><li id=\"n-contents\"><a href=\"/wiki/Portal:Contents\" title=\"Guides to browsing Wikipedia\">Contents</a></li><li id=\"n-featuredcontent\"><a href=\"/wiki/Portal:Featured_content\" title=\"Featured content – the best of Wikipedia\">Featured content</a></li><li id=\"n-currentevents\"><a href=\"/wiki/Portal:Current_events\" title=\"Find background information on current events\">Current events</a></li><li id=\"n-randompage\"><a accesskey=\"x\" href=\"/wiki/Special:Random\" title=\"Load a random article [x]\">Random article</a></li><li id=\"n-sitesupport\"><a href=\"https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_en.wikipedia.org&amp;uselang=en\" title=\"Support us\">Donate to Wikipedia</a></li><li id=\"n-shoplink\"><a href=\"//shop.wikimedia.org\" title=\"Visit the Wikipedia store\">Wikipedia store</a></li> </ul>\n</div>\n</div>\n<div aria-labelledby=\"p-interaction-label\" class=\"portal\" id=\"p-interaction\" role=\"navigation\">\n<h3 id=\"p-interaction-label\">Interaction</h3>\n<div class=\"body\">\n<ul>\n<li id=\"n-help\"><a href=\"/wiki/Help:Contents\" title=\"Guidance on how to use and edit Wikipedia\">Help</a></li><li id=\"n-aboutsite\"><a href=\"/wiki/Wikipedia:About\" title=\"Find out about Wikipedia\">About Wikipedia</a></li><li id=\"n-portal\"><a href=\"/wiki/Wikipedia:Community_portal\" title=\"About the project, what you can do, where to find things\">Community portal</a></li><li id=\"n-recentchanges\"><a accesskey=\"r\" href=\"/wiki/Special:RecentChanges\" title=\"A list of recent changes in the wiki [r]\">Recent changes</a></li><li id=\"n-contactpage\"><a href=\"//en.wikipedia.org/wiki/Wikipedia:Contact_us\" title=\"How to contact Wikipedia\">Contact page</a></li> </ul>\n</div>\n</div>\n<div aria-labelledby=\"p-tb-label\" class=\"portal\" id=\"p-tb\" role=\"navigation\">\n<h3 id=\"p-tb-label\">Tools</h3>\n<div class=\"body\">\n<ul>\n<li id=\"t-whatlinkshere\"><a accesskey=\"j\" href=\"/wiki/Special:WhatLinksHere/Action_selection\" title=\"List of all English Wikipedia pages containing links to this page [j]\">What links here</a></li><li id=\"t-recentchangeslinked\"><a accesskey=\"k\" href=\"/wiki/Special:RecentChangesLinked/Action_selection\" rel=\"nofollow\" title=\"Recent changes in pages linked from this page [k]\">Related changes</a></li><li id=\"t-upload\"><a accesskey=\"u\" href=\"/wiki/Wikipedia:File_Upload_Wizard\" title=\"Upload files [u]\">Upload file</a></li><li id=\"t-specialpages\"><a accesskey=\"q\" href=\"/wiki/Special:SpecialPages\" title=\"A list of all special pages [q]\">Special pages</a></li><li id=\"t-permalink\"><a href=\"/w/index.php?title=Action_selection&amp;oldid=843537296\" title=\"Permanent link to this revision of the page\">Permanent link</a></li><li id=\"t-info\"><a href=\"/w/index.php?title=Action_selection&amp;action=info\" title=\"More information about this page\">Page information</a></li><li id=\"t-wikibase\"><a accesskey=\"g\" href=\"https://www.wikidata.org/wiki/Special:EntityPage/Q4677422\" title=\"Link to connected data repository item [g]\">Wikidata item</a></li><li id=\"t-cite\"><a href=\"/w/index.php?title=Special:CiteThisPage&amp;page=Action_selection&amp;id=843537296\" title=\"Information on how to cite this page\">Cite this page</a></li> </ul>\n</div>\n</div>\n<div aria-labelledby=\"p-coll-print_export-label\" class=\"portal\" id=\"p-coll-print_export\" role=\"navigation\">\n<h3 id=\"p-coll-print_export-label\">Print/export</h3>\n<div class=\"body\">\n<ul>\n<li id=\"coll-create_a_book\"><a href=\"/w/index.php?title=Special:Book&amp;bookcmd=book_creator&amp;referer=Action+selection\">Create a book</a></li><li id=\"coll-download-as-rdf2latex\"><a href=\"/w/index.php?title=Special:ElectronPdf&amp;page=Action+selection&amp;action=show-download-screen\">Download as PDF</a></li><li id=\"t-print\"><a accesskey=\"p\" href=\"/w/index.php?title=Action_selection&amp;printable=yes\" title=\"Printable version of this page [p]\">Printable version</a></li> </ul>\n</div>\n</div>\n<div aria-labelledby=\"p-lang-label\" class=\"portal\" id=\"p-lang\" role=\"navigation\">\n<h3 id=\"p-lang-label\">Languages</h3>\n<div class=\"body\">\n<ul>\n</ul>\n<div class=\"after-portlet after-portlet-lang\"><span class=\"wb-langlinks-add wb-langlinks-link\"><a class=\"wbc-editpage\" href=\"https://www.wikidata.org/wiki/Special:EntityPage/Q4677422#sitelinks-wikipedia\" title=\"Add interlanguage links\">Add links</a></span></div> </div>\n</div>\n</div>\n</div>\n<div id=\"footer\" role=\"contentinfo\">\n<ul id=\"footer-info\">\n<li id=\"footer-info-lastmod\"> This page was last edited on 29 May 2018, at 19:51<span class=\"anonymous-show\"> (UTC)</span>.</li>\n<li id=\"footer-info-copyright\">Text is available under the <a href=\"//en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License\" rel=\"license\">Creative Commons Attribution-ShareAlike License</a><a href=\"//creativecommons.org/licenses/by-sa/3.0/\" rel=\"license\" style=\"display:none;\"></a>;\nadditional terms may apply.  By using this site, you agree to the <a href=\"//foundation.wikimedia.org/wiki/Terms_of_Use\">Terms of Use</a> and <a href=\"//foundation.wikimedia.org/wiki/Privacy_policy\">Privacy Policy</a>. Wikipedia® is a registered trademark of the <a href=\"//www.wikimediafoundation.org/\">Wikimedia Foundation, Inc.</a>, a non-profit organization.</li>\n</ul>\n<ul id=\"footer-places\">\n<li id=\"footer-places-privacy\"><a class=\"extiw\" href=\"https://foundation.wikimedia.org/wiki/Privacy_policy\" title=\"wmf:Privacy policy\">Privacy policy</a></li>\n<li id=\"footer-places-about\"><a href=\"/wiki/Wikipedia:About\" title=\"Wikipedia:About\">About Wikipedia</a></li>\n<li id=\"footer-places-disclaimer\"><a href=\"/wiki/Wikipedia:General_disclaimer\" title=\"Wikipedia:General disclaimer\">Disclaimers</a></li>\n<li id=\"footer-places-contact\"><a href=\"//en.wikipedia.org/wiki/Wikipedia:Contact_us\">Contact Wikipedia</a></li>\n<li id=\"footer-places-developers\"><a href=\"https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute\">Developers</a></li>\n<li id=\"footer-places-cookiestatement\"><a href=\"https://foundation.wikimedia.org/wiki/Cookie_statement\">Cookie statement</a></li>\n<li id=\"footer-places-mobileview\"><a class=\"noprint stopMobileRedirectToggle\" href=\"//en.m.wikipedia.org/w/index.php?title=Action_selection&amp;mobileaction=toggle_view_mobile\">Mobile view</a></li>\n</ul>\n<ul class=\"noprint\" id=\"footer-icons\">\n<li id=\"footer-copyrightico\">\n<a href=\"https://wikimediafoundation.org/\"><img alt=\"Wikimedia Foundation\" height=\"31\" src=\"/static/images/wikimedia-button.png\" srcset=\"/static/images/wikimedia-button-1.5x.png 1.5x, /static/images/wikimedia-button-2x.png 2x\" width=\"88\"/></a> </li>\n<li id=\"footer-poweredbyico\">\n<a href=\"//www.mediawiki.org/\"><img alt=\"Powered by MediaWiki\" height=\"31\" src=\"/static/images/poweredby_mediawiki_88x31.png\" srcset=\"/static/images/poweredby_mediawiki_132x47.png 1.5x, /static/images/poweredby_mediawiki_176x62.png 2x\" width=\"88\"/></a> </li>\n</ul>\n<div style=\"clear: both;\"></div>\n</div>\n<script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({\"wgPageParseReport\":{\"limitreport\":{\"cputime\":\"0.116\",\"walltime\":\"0.165\",\"ppvisitednodes\":{\"value\":261,\"limit\":1000000},\"ppgeneratednodes\":{\"value\":0,\"limit\":1500000},\"postexpandincludesize\":{\"value\":3196,\"limit\":2097152},\"templateargumentsize\":{\"value\":80,\"limit\":2097152},\"expansiondepth\":{\"value\":7,\"limit\":40},\"expensivefunctioncount\":{\"value\":1,\"limit\":500},\"unstrip-depth\":{\"value\":1,\"limit\":20},\"unstrip-size\":{\"value\":2875,\"limit\":5000000},\"entityaccesscount\":{\"value\":0,\"limit\":400},\"timingprofile\":[\"100.00%  119.221      1 -total\",\" 65.13%   77.645      1 Template:Reflist\",\" 52.48%   62.570      1 Template:Cite_web\",\" 21.12%   25.178      1 Template:Main\",\" 12.23%   14.586      1 Template:Portal\",\"  2.47%    2.949      1 Template:Main_other\"]},\"scribunto\":{\"limitreport-timeusage\":{\"value\":\"0.051\",\"limit\":\"10.000\"},\"limitreport-memusage\":{\"value\":1688235,\"limit\":52428800}},\"cachereport\":{\"origin\":\"mw1273\",\"timestamp\":\"20190224215612\",\"ttl\":2073600,\"transientcontent\":false}}});});</script>\n<script type=\"application/ld+json\">{\"@context\":\"https:\\/\\/schema.org\",\"@type\":\"Article\",\"name\":\"Action selection\",\"url\":\"https:\\/\\/en.wikipedia.org\\/wiki\\/Action_selection\",\"sameAs\":\"http:\\/\\/www.wikidata.org\\/entity\\/Q4677422\",\"mainEntity\":\"http:\\/\\/www.wikidata.org\\/entity\\/Q4677422\",\"author\":{\"@type\":\"Organization\",\"name\":\"Contributors to Wikimedia projects\"},\"publisher\":{\"@type\":\"Organization\",\"name\":\"Wikimedia Foundation, Inc.\",\"logo\":{\"@type\":\"ImageObject\",\"url\":\"https:\\/\\/www.wikimedia.org\\/static\\/images\\/wmf-hor-googpub.png\"}},\"datePublished\":\"2006-05-06T16:19:24Z\",\"dateModified\":\"2018-05-29T19:51:34Z\"}</script>\n<script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({\"wgBackendResponseTime\":294,\"wgHostname\":\"mw1273\"});});</script>\n</body>\n</html>\n",
  "table_of_contents": [
    "1 Characteristics of the action selection problem",
    "2 AI mechanisms",
    "2.1 Symbolic approaches",
    "2.2 Distributed approaches",
    "2.3 Dynamic planning approaches",
    "2.4 Others",
    "3 Theories of action selection in nature",
    "3.1 AI models of neural action selection",
    "4 See also",
    "5 References",
    "6 Further reading",
    "7 External links"
  ],
  "graphics": [],
  "paragraphs": [
    {
      "title": "",
      "text": "Action selection is a way of characterizing the most basic problem of intelligent systems: what to do next. In artificial intelligence and computational cognitive science, \"the action selection problem\" is typically associated with intelligent agents and animats—artificial systems that exhibit complex behaviour in an agent environment. The term is also sometimes used in ethology or animal behavior.\n\nOne problem for understanding action selection is determining the level of abstraction used for specifying an \"act\". At the most basic level of abstraction, an atomic act could be anything from contracting a muscle cell to provoking a war. Typically for any one action-selection mechanism, the set of possible actions is predefined and fixed.\n\nMost researchers working in this field place high demands on their agents: \n\nFor these reasons action selection is not trivial and attracts a good deal of research.\n\n"
    },
    {
      "title": "Characteristics of the action selection problem",
      "text": "The main problem for action selection is complexity. Since all computation takes both time and space (in memory), agents cannot possibly consider every option available to them at every instant in time. Consequently, they must be biased, and constrain their search in some way. For AI, the question of action selection is what is the best way to constrain this search? For biology and ethology, the question is how do various types of animals constrain their search? Do all animals use the same approaches? Why do they use the ones they do?\n\nOne fundamental question about action selection is whether it is really a problem at all for an agent, or whether it is just a description of an emergent property of an intelligent agent's behavior. However, if we consider how we are going to build an intelligent agent, then it becomes apparent there must be some mechanism for action selection. This mechanism may be highly distributed (as in the case of distributed organisms such as social insect colonies or slime mold) or it may be a special-purpose module.\n\nThe action selection mechanism (ASM) determines not only the agent’s actions in terms of impact on the world, but also directs its perceptual attention, and updates its memory. These egocentric sorts of actions may in turn result in modifying the agents basic behavioural capacities, particularly in that updating memory implies some form of machine learning is possible. Ideally, action selection itself should also be able to learn and adapt, but there are many problems of combinatorial complexity and computational tractability that may require restricting the search space for learning.\n\nIn AI, an ASM is also sometimes either referred to as an agent architecture or thought of as a substantial part of one.\n\n"
    },
    {
      "title": "AI mechanisms",
      "text": "Generally, artificial action selection mechanisms can be divided into several categories: symbol-based systems sometimes known as classical planning, distributed solutions, and reactive or dynamic planning. Some approaches do not fall neatly into any one of these categories. Others are really more about providing scientific models than practical AI control; these last are described further in the next section.\n\nEarly in the history of artificial intelligence, it was assumed that the best way for an agent to choose what to do next would be to compute a probably optimal plan, and then execute that plan. This led to the physical symbol system hypothesis, that a physical agent that can manipulate symbols is necessary and sufficient for intelligence. Many software agents still use this approach for action selection. It normally requires describing all sensor readings, the world, all of ones actions and all of one's goals in some form of predicate logic. Critics of this approach complain that it is too slow for real-time planning and that, despite the proofs, it is still unlikely to produce optimal plans because reducing descriptions of reality to logic is a process prone to errors.\n\nSatisficing is a decision-making strategy which attempts to meet criteria for adequacy, rather than identify an optimal solution. A satisficing strategy may often, in fact, be (near) optimal if the costs of the decision-making process itself, such as the cost of obtaining complete information, are considered in the outcome calculus.\n\nGoal driven architectures – In these symbolic architectures, the agent's behaviour is typically described by a set of goals. Each goal can be achieved by a process or an activity, which is described by a prescripted plan. The agent must just decide which process to carry on to accomplish a given goal. The plan can expand to subgoals, which makes the process slightly recursive. Technically, more or less, the plans exploits condition-rules. These architectures are reactive or hybrid. Classical examples of goal driven architectures are implementable refinements of belief-desire-intention architecture like JAM or IVE.  \n\nIn contrast to the symbolic approach, distributed systems of action selection actually have no one \"box\" in the agent which decides the next action. At least in their idealized form, distributed systems have many modules running in parallel and determining the best action based on local expertise. In these idealized systems, overall coherence is expected to emerge somehow, possibly through careful design of the interacting components. This approach is often inspired by artificial neural networks research. In practice, there is almost always some centralised system determining which module is \"the most active\" or has the most salience. There is evidence real biological brains also have such executive decision systems which evaluate which of the competing systems deserves the most attention, or more properly, has its desired actions disinhibited.\n\nBecause purely distributed systems are difficult to construct, many researchers have turned to using explicit hard-coded plans to determine the priorities of their system.\n\nDynamic or reactive planning methods compute just one next action in every instant based on the current context and pre-scripted plans. In contrast to classical planning methods, reactive or dynamic approaches do not suffer combinatorial explosion. On the other hand, they are sometimes seen as too rigid to be considered strong AI, since the plans are coded in advance. At the same time, natural intelligence can be rigid in some contexts although it is fluid and able to adapt in others.\n\nExample dynamic planning mechanisms include:\n\nSometimes to attempt to address the perceived inflexibility of dynamic planning, hybrid techniques are used. In these, a more conventional AI planning system searches for new plans when the agent has spare time, and updates the dynamic plan library when it finds good solutions. The important aspect of any such system is that when the agent needs to select an action, some solution exists that can be used immediately (see further anytime algorithm).\n\n"
    },
    {
      "title": "Theories of action selection in nature",
      "text": "Many dynamic models of artificial action selection were originally inspired by research in ethology. In particular, Konrad Lorenz and Nikolaas Tinbergen provided the idea of an innate releasing mechanism to explain instinctive behaviors (fixed action patterns). Influenced by the ideas of William McDougall, Lorenz developed this into a \"psychohydraulic\" model of the motivation of behavior. In ethology, these ideas were influential in the 1960s, but they are now regarded as outdated because of their use of an energy flow metaphor; the nervous system and the control of behavior are now normally treated as involving information transmission rather than energy flow. Dynamic plans and neural networks are more similar to information transmission, while spreading activation is more similar to the diffuse control of emotional / hormonal systems.\n\nStan Franklin has proposed that action selection is the right perspective to take in understanding the role and evolution of mind.  See his page on the action selection paradigm.\n\nSome researchers create elaborate models of neural action selection. See for example:\n\n"
    }
  ],
  "links": [
    "/wiki/Artificial_intelligence",
    "/wiki/Cognitive_science",
    "/wiki/Intelligent_agents",
    "/wiki/Animat",
    "/wiki/Agent_environment",
    "/wiki/Ethology",
    "/wiki/Intelligent_agent",
    "/wiki/Agent_environment",
    "/wiki/Agent_environment",
    "/wiki/Humans",
    "/wiki/Computer_model",
    "/wiki/Behaviour",
    "/wiki/Complexity",
    "/wiki/Computation",
    "/wiki/Bias",
    "/wiki/Emergence",
    "/wiki/Social_insect",
    "/wiki/Slime_mold",
    "/wiki/Attention",
    "/wiki/Memory",
    "/wiki/Egocentric",
    "/wiki/Machine_learning",
    "/wiki/Combinatorics",
    "/wiki/Tractable_problem",
    "/wiki/Agent_architecture",
    "/wiki/Automated_planning_and_scheduling",
    "/wiki/Distributed_systems",
    "/wiki/Reactive_planning",
    "/wiki/Scientific_model",
    "/wiki/Automated_planning_and_scheduling",
    "/wiki/History_of_artificial_intelligence",
    "/wiki/Logical_argument",
    "/wiki/Physical_symbol_system",
    "/wiki/Sufficient",
    "/wiki/Software_agents",
    "/wiki/Predicate_logic",
    "/wiki/Satisficing",
    "/wiki/Symbol",
    "/wiki/Reactive_planning",
    "/wiki/BDI_software_agent",
    "/wiki/Artificial_neural_networks",
    "/wiki/Executive_system",
    "/wiki/Attention",
    "/wiki/Disinhibited",
    "/wiki/Connectionist",
    "/wiki/Behavior_based_AI",
    "/wiki/Subsumption_architecture",
    "/wiki/Artificial_neural_network",
    "/wiki/Reactive_planning",
    "/wiki/Combinatorial_explosion",
    "/wiki/Artificial_general_intelligence",
    "/wiki/Finite_state_machine",
    "/wiki/Reactive_planning",
    "/wiki/Computer_game_bot",
    "/wiki/Softimage",
    "/wiki/Hierarchical",
    "/wiki/Sequential",
    "/wiki/Partial_plan",
    "/wiki/Behavior_based_AI",
    "/wiki/Interoperability",
    "/wiki/Anytime_algorithm",
    "/wiki/Symbol",
    "/wiki/Cognitive_architecture",
    "/wiki/Constraint_satisfaction",
    "/wiki/Artificial_intelligence",
    "/wiki/Bayesian_inference",
    "/wiki/Fuzzy_control_system",
    "/wiki/Fuzzy_logic",
    "/wiki/Reactive_planning",
    "/wiki/Symbol",
    "/wiki/Ethology",
    "/wiki/Konrad_Lorenz",
    "/wiki/Nikolaas_Tinbergen",
    "/wiki/Innate_releasing_mechanism",
    "/wiki/Fixed_action_pattern",
    "/wiki/Motivation",
    "/wiki/Nervous_system",
    "/wiki/Stan_Franklin",
    "/wiki/Mind",
    "/wiki/Action_description_language",
    "/wiki/Utility_system",
    "/wiki/Expert_system",
    "/wiki/Game_artificial_intelligence",
    "/wiki/Inference_engine",
    "/wiki/Intelligent_agent",
    "/wiki/OPS5",
    "/wiki/Rete_algorithm",
    "/wiki/Reinforcement_learning",
    "/wiki/Robot_intelligence",
    "/wiki/Artificial_Intelligence_Center",
    "/wiki/SRI_International",
    "/wiki/The_Royal_Society",
    "/wiki/Philosophical_Transactions_of_the_Royal_Society",
    "/wiki/Action_selection",
    "/wiki/Action_selection",
    "/wiki/Main_Page",
    "/wiki/Main_Page"
  ]
}