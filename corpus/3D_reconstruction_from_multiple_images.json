{
  "title": "3D reconstruction from multiple images",
  "html": "<!DOCTYPE html>\n<html class=\"client-nojs\" dir=\"ltr\" lang=\"en\">\n<head>\n<meta charset=\"utf-8\"/>\n<title>3D reconstruction from multiple images - Wikipedia</title>\n<script>document.documentElement.className = document.documentElement.className.replace( /(^|\\s)client-nojs(\\s|$)/, \"$1client-js$2\" );</script>\n<script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({\"wgCanonicalNamespace\":\"\",\"wgCanonicalSpecialPageName\":false,\"wgNamespaceNumber\":0,\"wgPageName\":\"3D_reconstruction_from_multiple_images\",\"wgTitle\":\"3D reconstruction from multiple images\",\"wgCurRevisionId\":884992410,\"wgRevisionId\":884992410,\"wgArticleId\":34668189,\"wgIsArticle\":true,\"wgIsRedirect\":false,\"wgAction\":\"view\",\"wgUserName\":null,\"wgUserGroups\":[\"*\"],\"wgCategories\":[\"Articles needing cleanup from February 2019\",\"All pages needing cleanup\",\"Cleanup tagged articles with a reason field from February 2019\",\"Wikipedia pages needing cleanup from February 2019\",\"Computer vision\",\"Applications of computer vision\",\"Image processing\",\"Artificial intelligence\",\"Stereophotogrammetry\",\"3D imaging\"],\"wgBreakFrames\":false,\"wgPageContentLanguage\":\"en\",\"wgPageContentModel\":\"wikitext\",\"wgSeparatorTransformTable\":[\"\",\"\"],\"wgDigitTransformTable\":[\"\",\"\"],\"wgDefaultDateFormat\":\"dmy\",\"wgMonthNames\":[\"\",\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"],\"wgMonthNamesShort\":[\"\",\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"],\"wgRelevantPageName\":\"3D_reconstruction_from_multiple_images\",\"wgRelevantArticleId\":34668189,\"wgRequestId\":\"XHOd8QpAMFMAAKYLNz0AAADW\",\"wgCSPNonce\":false,\"wgIsProbablyEditable\":true,\"wgRelevantPageIsProbablyEditable\":true,\"wgRestrictionEdit\":[],\"wgRestrictionMove\":[],\"wgFlaggedRevsParams\":{\"tags\":{}},\"wgStableRevisionId\":null,\"wgCategoryTreePageCategoryOptions\":\"{\\\"mode\\\":0,\\\"hideprefix\\\":20,\\\"showcount\\\":true,\\\"namespaces\\\":false}\",\"wgWikiEditorEnabledModules\":[],\"wgBetaFeaturesFeatures\":[],\"wgMediaViewerOnClick\":true,\"wgMediaViewerEnabledByDefault\":true,\"wgPopupsShouldSendModuleToUser\":true,\"wgPopupsConflictsWithNavPopupGadget\":false,\"wgVisualEditor\":{\"pageLanguageCode\":\"en\",\"pageLanguageDir\":\"ltr\",\"pageVariantFallbacks\":\"en\",\"usePageImages\":true,\"usePageDescriptions\":true},\"wgMFIsPageContentModelEditable\":true,\"wgMFEnableFontChanger\":true,\"wgMFDisplayWikibaseDescriptions\":{\"search\":true,\"nearby\":true,\"watchlist\":true,\"tagline\":false},\"wgRelatedArticles\":null,\"wgRelatedArticlesUseCirrusSearch\":true,\"wgRelatedArticlesOnlyUseCirrusSearch\":false,\"wgWMESchemaEditAttemptStepOversample\":false,\"wgPoweredByHHVM\":true,\"wgULSCurrentAutonym\":\"English\",\"wgNoticeProject\":\"wikipedia\",\"wgCentralNoticeCookiesToDelete\":[],\"wgCentralNoticeCategoriesUsingLegacy\":[\"Fundraising\",\"fundraising\"],\"wgWikibaseItemId\":\"Q3422083\",\"wgScoreNoteLanguages\":{\"arabic\":\"العربية\",\"catalan\":\"català\",\"deutsch\":\"Deutsch\",\"english\":\"English\",\"espanol\":\"español\",\"italiano\":\"italiano\",\"nederlands\":\"Nederlands\",\"norsk\":\"norsk\",\"portugues\":\"português\",\"suomi\":\"suomi\",\"svenska\":\"svenska\",\"vlaams\":\"West-Vlams\"},\"wgScoreDefaultNoteLanguage\":\"nederlands\",\"wgCentralAuthMobileDomain\":false,\"wgCodeMirrorEnabled\":true,\"wgVisualEditorToolbarScrollOffset\":0,\"wgVisualEditorUnsupportedEditParams\":[\"undo\",\"undoafter\",\"veswitched\"],\"wgEditSubmitButtonLabelPublish\":true,\"oresWikiId\":\"enwiki\",\"oresBaseUrl\":\"http://ores.discovery.wmnet:8081/\",\"oresApiVersion\":3});mw.loader.state({\"ext.gadget.charinsert-styles\":\"ready\",\"ext.globalCssJs.user.styles\":\"ready\",\"ext.globalCssJs.site.styles\":\"ready\",\"site.styles\":\"ready\",\"noscript\":\"ready\",\"user.styles\":\"ready\",\"ext.globalCssJs.user\":\"ready\",\"ext.globalCssJs.site\":\"ready\",\"user\":\"ready\",\"user.options\":\"ready\",\"user.tokens\":\"loading\",\"ext.cite.styles\":\"ready\",\"ext.math.styles\":\"ready\",\"mediawiki.legacy.shared\":\"ready\",\"mediawiki.legacy.commonPrint\":\"ready\",\"mediawiki.toc.styles\":\"ready\",\"wikibase.client.init\":\"ready\",\"ext.visualEditor.desktopArticleTarget.noscript\":\"ready\",\"ext.uls.interlanguage\":\"ready\",\"ext.wikimediaBadges\":\"ready\",\"ext.3d.styles\":\"ready\",\"mediawiki.skinning.interface\":\"ready\",\"skins.vector.styles\":\"ready\"});mw.loader.implement(\"user.tokens@0tffind\",function($,jQuery,require,module){/*@nomin*/mw.user.tokens.set({\"editToken\":\"+\\\\\",\"patrolToken\":\"+\\\\\",\"watchToken\":\"+\\\\\",\"csrfToken\":\"+\\\\\"});\n});RLPAGEMODULES=[\"ext.cite.ux-enhancements\",\"ext.math.scripts\",\"site\",\"mediawiki.page.startup\",\"mediawiki.page.ready\",\"mediawiki.toc\",\"mediawiki.searchSuggest\",\"ext.gadget.teahouse\",\"ext.gadget.ReferenceTooltips\",\"ext.gadget.watchlist-notice\",\"ext.gadget.DRN-wizard\",\"ext.gadget.charinsert\",\"ext.gadget.refToolbar\",\"ext.gadget.extra-toolbar-buttons\",\"ext.gadget.switcher\",\"ext.centralauth.centralautologin\",\"mmv.head\",\"mmv.bootstrap.autostart\",\"ext.popups\",\"ext.visualEditor.desktopArticleTarget.init\",\"ext.visualEditor.targetLoader\",\"ext.eventLogging\",\"ext.wikimediaEvents\",\"ext.navigationTiming\",\"ext.uls.eventlogger\",\"ext.uls.init\",\"ext.uls.compactlinks\",\"ext.uls.interface\",\"ext.quicksurveys.init\",\"ext.centralNotice.geoIP\",\"ext.centralNotice.startUp\",\"skins.vector.js\"];mw.loader.load(RLPAGEMODULES);});</script>\n<link href=\"/w/load.php?debug=false&amp;lang=en&amp;modules=ext.3d.styles%7Cext.cite.styles%7Cext.math.styles%7Cext.uls.interlanguage%7Cext.visualEditor.desktopArticleTarget.noscript%7Cext.wikimediaBadges%7Cmediawiki.legacy.commonPrint%2Cshared%7Cmediawiki.skinning.interface%7Cmediawiki.toc.styles%7Cskins.vector.styles%7Cwikibase.client.init&amp;only=styles&amp;skin=vector\" rel=\"stylesheet\"/>\n<script async=\"\" src=\"/w/load.php?debug=false&amp;lang=en&amp;modules=startup&amp;only=scripts&amp;skin=vector\"></script>\n<meta content=\"\" name=\"ResourceLoaderDynamicStyles\"/>\n<link href=\"/w/load.php?debug=false&amp;lang=en&amp;modules=ext.gadget.charinsert-styles&amp;only=styles&amp;skin=vector\" rel=\"stylesheet\"/>\n<link href=\"/w/load.php?debug=false&amp;lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=vector\" rel=\"stylesheet\"/>\n<meta content=\"MediaWiki 1.33.0-wmf.18\" name=\"generator\"/>\n<meta content=\"origin\" name=\"referrer\"/>\n<meta content=\"origin-when-crossorigin\" name=\"referrer\"/>\n<meta content=\"origin-when-cross-origin\" name=\"referrer\"/>\n<meta content=\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/51/Fantasitron_photo_booth_at_Madurodam_can_scan_up_to_two_people_at_a_time_IMG_3797_FRD.jpg/1200px-Fantasitron_photo_booth_at_Madurodam_can_scan_up_to_two_people_at_a_time_IMG_3797_FRD.jpg\" property=\"og:image\"/>\n<link href=\"android-app://org.wikipedia/http/en.m.wikipedia.org/wiki/3D_reconstruction_from_multiple_images\" rel=\"alternate\"/>\n<link href=\"/w/index.php?title=3D_reconstruction_from_multiple_images&amp;action=edit\" rel=\"alternate\" title=\"Edit this page\" type=\"application/x-wiki\"/>\n<link href=\"/w/index.php?title=3D_reconstruction_from_multiple_images&amp;action=edit\" rel=\"edit\" title=\"Edit this page\"/>\n<link href=\"/static/apple-touch/wikipedia.png\" rel=\"apple-touch-icon\"/>\n<link href=\"/static/favicon/wikipedia.ico\" rel=\"shortcut icon\"/>\n<link href=\"/w/opensearch_desc.php\" rel=\"search\" title=\"Wikipedia (en)\" type=\"application/opensearchdescription+xml\"/>\n<link href=\"//en.wikipedia.org/w/api.php?action=rsd\" rel=\"EditURI\" type=\"application/rsd+xml\"/>\n<link href=\"//creativecommons.org/licenses/by-sa/3.0/\" rel=\"license\"/>\n<link href=\"https://en.wikipedia.org/wiki/3D_reconstruction_from_multiple_images\" rel=\"canonical\"/>\n<link href=\"//login.wikimedia.org\" rel=\"dns-prefetch\"/>\n<link href=\"//meta.wikimedia.org\" rel=\"dns-prefetch\"/>\n<!--[if lt IE 9]><script src=\"/w/load.php?debug=false&amp;lang=en&amp;modules=html5shiv&amp;only=scripts&amp;skin=vector&amp;sync=1\"></script><![endif]-->\n</head>\n<body class=\"mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject mw-editable page-3D_reconstruction_from_multiple_images rootpage-3D_reconstruction_from_multiple_images skin-vector action-view\"> <div class=\"noprint\" id=\"mw-page-base\"></div>\n<div class=\"noprint\" id=\"mw-head-base\"></div>\n<div class=\"mw-body\" id=\"content\" role=\"main\">\n<a id=\"top\"></a>\n<div class=\"mw-body-content\" id=\"siteNotice\"><!-- CentralNotice --></div><div class=\"mw-indicators mw-body-content\">\n</div>\n<h1 class=\"firstHeading\" id=\"firstHeading\" lang=\"en\">3D reconstruction from multiple images</h1> <div class=\"mw-body-content\" id=\"bodyContent\">\n<div class=\"noprint\" id=\"siteSub\">From Wikipedia, the free encyclopedia</div> <div id=\"contentSub\"></div>\n<div id=\"jump-to-nav\"></div> <a class=\"mw-jump-link\" href=\"#mw-head\">Jump to navigation</a>\n<a class=\"mw-jump-link\" href=\"#p-search\">Jump to search</a>\n<div class=\"mw-content-ltr\" dir=\"ltr\" id=\"mw-content-text\" lang=\"en\"><div class=\"mw-parser-output\"><table class=\"box-Cleanup plainlinks metadata ambox ambox-style ambox-Cleanup\" role=\"presentation\"><tbody><tr><td class=\"mbox-image\"><div style=\"width:52px\"><img alt=\"\" data-file-height=\"48\" data-file-width=\"48\" decoding=\"async\" height=\"40\" src=\"//upload.wikimedia.org/wikipedia/en/thumb/f/f2/Edit-clear.svg/40px-Edit-clear.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/en/thumb/f/f2/Edit-clear.svg/60px-Edit-clear.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/f/f2/Edit-clear.svg/80px-Edit-clear.svg.png 2x\" width=\"40\"/></div></td><td class=\"mbox-text\"><div class=\"mbox-text-span\">This article may <b>require <a href=\"/wiki/Wikipedia:Cleanup\" title=\"Wikipedia:Cleanup\">cleanup</a></b> to meet Wikipedia's <a href=\"/wiki/Wikipedia:Manual_of_Style\" title=\"Wikipedia:Manual of Style\">quality standards</a>. The specific problem is: <b>Large chunks of the article are incoherent. It seems to be a hodgepodge of collected thoughts and half-thoughts about various topics.</b><span class=\"hide-when-compact\"> Please help <a class=\"external text\" href=\"//en.wikipedia.org/w/index.php?title=3D_reconstruction_from_multiple_images&amp;action=edit\">improve this article</a> if you can.</span> <small class=\"date-container\"><i>(<span class=\"date\">February 2019</span>)</i></small><small class=\"hide-when-compact\"><i> (<a href=\"/wiki/Help:Maintenance_template_removal\" title=\"Help:Maintenance template removal\">Learn how and when to remove this template message</a>)</i></small></div></td></tr></tbody></table>\n<div class=\"thumb tright\"><div class=\"thumbinner\" style=\"width:502px;\"><a class=\"image\" href=\"/wiki/File:Madurodam_Shapeways_3D_selfie_in_1_20_scale_after_a_second_spray_of_varnish_FRD.jpg\"><img alt=\"\" class=\"thumbimage\" data-file-height=\"1887\" data-file-width=\"6610\" decoding=\"async\" height=\"143\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/7/76/Madurodam_Shapeways_3D_selfie_in_1_20_scale_after_a_second_spray_of_varnish_FRD.jpg/500px-Madurodam_Shapeways_3D_selfie_in_1_20_scale_after_a_second_spray_of_varnish_FRD.jpg\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/7/76/Madurodam_Shapeways_3D_selfie_in_1_20_scale_after_a_second_spray_of_varnish_FRD.jpg/750px-Madurodam_Shapeways_3D_selfie_in_1_20_scale_after_a_second_spray_of_varnish_FRD.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/7/76/Madurodam_Shapeways_3D_selfie_in_1_20_scale_after_a_second_spray_of_varnish_FRD.jpg/1000px-Madurodam_Shapeways_3D_selfie_in_1_20_scale_after_a_second_spray_of_varnish_FRD.jpg 2x\" width=\"500\"/></a> <div class=\"thumbcaption\"><div class=\"magnify\"><a class=\"internal\" href=\"/wiki/File:Madurodam_Shapeways_3D_selfie_in_1_20_scale_after_a_second_spray_of_varnish_FRD.jpg\" title=\"Enlarge\"></a></div>A <a href=\"/wiki/3D_selfie\" title=\"3D selfie\">3D selfie</a> in 1:20 scale printed by <a href=\"/wiki/Shapeways\" title=\"Shapeways\">Shapeways</a> using gypsum-based printing, created by <a href=\"/wiki/Madurodam\" title=\"Madurodam\">Madurodam</a> miniature park from 2D pictures taken at its Fantasitron photo booth.</div></div></div>\n<div class=\"thumb tright\"><div class=\"thumbinner\" style=\"width:222px;\"><a class=\"image\" href=\"/wiki/File:Fantasitron_photo_booth_at_Madurodam_can_scan_up_to_two_people_at_a_time_IMG_3797_FRD.jpg\"><img alt=\"\" class=\"thumbimage\" data-file-height=\"3435\" data-file-width=\"2521\" decoding=\"async\" height=\"300\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/5/51/Fantasitron_photo_booth_at_Madurodam_can_scan_up_to_two_people_at_a_time_IMG_3797_FRD.jpg/220px-Fantasitron_photo_booth_at_Madurodam_can_scan_up_to_two_people_at_a_time_IMG_3797_FRD.jpg\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/5/51/Fantasitron_photo_booth_at_Madurodam_can_scan_up_to_two_people_at_a_time_IMG_3797_FRD.jpg/330px-Fantasitron_photo_booth_at_Madurodam_can_scan_up_to_two_people_at_a_time_IMG_3797_FRD.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/5/51/Fantasitron_photo_booth_at_Madurodam_can_scan_up_to_two_people_at_a_time_IMG_3797_FRD.jpg/440px-Fantasitron_photo_booth_at_Madurodam_can_scan_up_to_two_people_at_a_time_IMG_3797_FRD.jpg 2x\" width=\"220\"/></a> <div class=\"thumbcaption\"><div class=\"magnify\"><a class=\"internal\" href=\"/wiki/File:Fantasitron_photo_booth_at_Madurodam_can_scan_up_to_two_people_at_a_time_IMG_3797_FRD.jpg\" title=\"Enlarge\"></a></div>3D models are generated from 2D pictures taken at the Fantasitron 3D photo booth at <a href=\"/wiki/Madurodam\" title=\"Madurodam\">Madurodam</a></div></div></div>\n<div class=\"thumb tright\"><div class=\"thumbinner\" style=\"width:222px;\"><a class=\"image\" href=\"/wiki/File:Synthesizing_3D_Shapes_via_Modeling_Multi-View_Depth_Maps_and_Silhouettes_With_Deep_Generative_Networks.png\"><img alt=\"\" class=\"thumbimage\" data-file-height=\"365\" data-file-width=\"541\" decoding=\"async\" height=\"148\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/6d/Synthesizing_3D_Shapes_via_Modeling_Multi-View_Depth_Maps_and_Silhouettes_With_Deep_Generative_Networks.png/220px-Synthesizing_3D_Shapes_via_Modeling_Multi-View_Depth_Maps_and_Silhouettes_With_Deep_Generative_Networks.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/6/6d/Synthesizing_3D_Shapes_via_Modeling_Multi-View_Depth_Maps_and_Silhouettes_With_Deep_Generative_Networks.png/330px-Synthesizing_3D_Shapes_via_Modeling_Multi-View_Depth_Maps_and_Silhouettes_With_Deep_Generative_Networks.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/6/6d/Synthesizing_3D_Shapes_via_Modeling_Multi-View_Depth_Maps_and_Silhouettes_With_Deep_Generative_Networks.png/440px-Synthesizing_3D_Shapes_via_Modeling_Multi-View_Depth_Maps_and_Silhouettes_With_Deep_Generative_Networks.png 2x\" width=\"220\"/></a> <div class=\"thumbcaption\"><div class=\"magnify\"><a class=\"internal\" href=\"/wiki/File:Synthesizing_3D_Shapes_via_Modeling_Multi-View_Depth_Maps_and_Silhouettes_With_Deep_Generative_Networks.png\" title=\"Enlarge\"></a></div>Generating and reconstructing 3D shapes from single or multi-view depth maps or silhouettes <sup class=\"reference\" id=\"cite_ref-3DVAE_1-0\"><a href=\"#cite_note-3DVAE-1\">[1]</a></sup></div></div></div>\n<p><b>3D reconstruction from multiple images</b> is the creation of <a class=\"mw-redirect\" href=\"/wiki/Three-dimensional_model\" title=\"Three-dimensional model\">three-dimensional models</a> from a set of images. It is the reverse process of obtaining 2D images from 3D scenes.\n</p><p>The essence of an image is a projection from a 3D scene onto a 2D plane, during which process the depth is lost. The 3D point corresponding to a specific image point is constrained to be on the line of sight. From a single image, it is impossible to determine which point on this line corresponds to the image point. If two images are available, then the position of a 3D point can be found as the intersection of the two projection rays. This process is referred to as <a href=\"/wiki/Triangulation_(computer_vision)\" title=\"Triangulation (computer vision)\">triangulation</a>. The key for this process is the relations between multiple views which convey the information that corresponding sets of points must contain some structure and that this structure is related to the poses and the calibration of the camera.\n</p><p>In recent decades, there is an important demand for 3D content for <a href=\"/wiki/Computer_graphics\" title=\"Computer graphics\">computer graphics</a>, <a href=\"/wiki/Virtual_reality\" title=\"Virtual reality\">virtual reality</a> and communication, triggering a change in emphasis for the requirements. Many existing systems for constructing 3D models are built around specialized hardware (e.g. stereo rigs) resulting in a high cost, which cannot satisfy the requirement of its new applications. This gap stimulates the use of digital imaging facilities (like a camera). Moore's law also tells us that more work can be done in software. An early method was proposed by Tomasi and Kanade.<sup class=\"reference\" id=\"cite_ref-Tomasi_2-0\"><a href=\"#cite_note-Tomasi-2\">[2]</a></sup> They used an affine factorization approach to extract 3D from images sequences. However, the assumption of <a href=\"/wiki/Orthographic_projection\" title=\"Orthographic projection\">orthographic projection</a> is a significant limitation of this system.\n</p>\n<div class=\"toc\" id=\"toc\"><input class=\"toctogglecheckbox\" id=\"toctogglecheckbox\" role=\"button\" style=\"display:none\" type=\"checkbox\"/><div class=\"toctitle\" dir=\"ltr\" lang=\"en\"><h2>Contents</h2><span class=\"toctogglespan\"><label class=\"toctogglelabel\" for=\"toctogglecheckbox\"></label></span></div>\n<ul>\n<li class=\"toclevel-1 tocsection-1\"><a href=\"#Processing\"><span class=\"tocnumber\">1</span> <span class=\"toctext\">Processing</span></a></li>\n<li class=\"toclevel-1 tocsection-2\"><a href=\"#Mathematical_description_of_reconstruction\"><span class=\"tocnumber\">2</span> <span class=\"toctext\">Mathematical description of reconstruction</span></a></li>\n<li class=\"toclevel-1 tocsection-3\"><a href=\"#Autocalibration\"><span class=\"tocnumber\">3</span> <span class=\"toctext\">Autocalibration</span></a>\n<ul>\n<li class=\"toclevel-2 tocsection-4\"><a href=\"#Kruppa_equations\"><span class=\"tocnumber\">3.1</span> <span class=\"toctext\">Kruppa equations</span></a></li>\n<li class=\"toclevel-2 tocsection-5\"><a href=\"#Mendonça_and_Cipolla\"><span class=\"tocnumber\">3.2</span> <span class=\"toctext\">Mendonça and Cipolla</span></a></li>\n</ul>\n</li>\n<li class=\"toclevel-1 tocsection-6\"><a href=\"#Stratification\"><span class=\"tocnumber\">4</span> <span class=\"toctext\">Stratification</span></a>\n<ul>\n<li class=\"toclevel-2 tocsection-7\"><a href=\"#The_stratification_of_3D_geometry\"><span class=\"tocnumber\">4.1</span> <span class=\"toctext\">The stratification of 3D geometry</span></a></li>\n<li class=\"toclevel-2 tocsection-8\"><a href=\"#Projective_reconstruction\"><span class=\"tocnumber\">4.2</span> <span class=\"toctext\">Projective reconstruction</span></a></li>\n<li class=\"toclevel-2 tocsection-9\"><a href=\"#Affine_reconstruction\"><span class=\"tocnumber\">4.3</span> <span class=\"toctext\">Affine reconstruction</span></a></li>\n<li class=\"toclevel-2 tocsection-10\"><a href=\"#Euclidean_reconstruction\"><span class=\"tocnumber\">4.4</span> <span class=\"toctext\">Euclidean reconstruction</span></a></li>\n</ul>\n</li>\n<li class=\"toclevel-1 tocsection-11\"><a href=\"#Algebraic_vs_geometric_error\"><span class=\"tocnumber\">5</span> <span class=\"toctext\">Algebraic vs geometric error</span></a></li>\n<li class=\"toclevel-1 tocsection-12\"><a href=\"#3D_reconstruction_of_Medical_Images\"><span class=\"tocnumber\">6</span> <span class=\"toctext\">3D reconstruction of Medical Images</span></a>\n<ul>\n<li class=\"toclevel-2 tocsection-13\"><a href=\"#Motivation_&amp;_applications\"><span class=\"tocnumber\">6.1</span> <span class=\"toctext\">Motivation &amp; applications</span></a></li>\n<li class=\"toclevel-2 tocsection-14\"><a href=\"#Problem_statement_&amp;_Basics\"><span class=\"tocnumber\">6.2</span> <span class=\"toctext\">Problem statement &amp; Basics</span></a>\n<ul>\n<li class=\"toclevel-3 tocsection-15\"><a href=\"#1)_Stereo_Corresponding_Point_Based_Technique\"><span class=\"tocnumber\">6.2.1</span> <span class=\"toctext\">1) Stereo Corresponding Point Based Technique</span></a></li>\n<li class=\"toclevel-3 tocsection-16\"><a href=\"#2)_Non-Stereo_corresponding_contour_method_(NCSS)\"><span class=\"tocnumber\">6.2.2</span> <span class=\"toctext\">2) Non-Stereo corresponding contour method (NCSS)</span></a></li>\n<li class=\"toclevel-3 tocsection-17\"><a href=\"#3)_Surface_Rendering_technique\"><span class=\"tocnumber\">6.2.3</span> <span class=\"toctext\">3) Surface Rendering technique</span></a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li class=\"toclevel-1 tocsection-18\"><a href=\"#See_also\"><span class=\"tocnumber\">7</span> <span class=\"toctext\">See also</span></a></li>\n<li class=\"toclevel-1 tocsection-19\"><a href=\"#References\"><span class=\"tocnumber\">8</span> <span class=\"toctext\">References</span></a></li>\n<li class=\"toclevel-1 tocsection-20\"><a href=\"#Further_reading\"><span class=\"tocnumber\">9</span> <span class=\"toctext\">Further reading</span></a></li>\n<li class=\"toclevel-1 tocsection-21\"><a href=\"#External_links\"><span class=\"tocnumber\">10</span> <span class=\"toctext\">External links</span></a></li>\n</ul>\n</div>\n<h2><span class=\"mw-headline\" id=\"Processing\">Processing</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=3D_reconstruction_from_multiple_images&amp;action=edit&amp;section=1\" title=\"Edit section: Processing\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<div class=\"thumb tright\"><div class=\"thumbinner\" style=\"width:222px;\"><a class=\"image\" href=\"/wiki/File:SilhouetteCones.jpg\"><img alt=\"\" class=\"thumbimage\" data-file-height=\"384\" data-file-width=\"512\" decoding=\"async\" height=\"165\" src=\"//upload.wikimedia.org/wikipedia/en/thumb/2/2f/SilhouetteCones.jpg/220px-SilhouetteCones.jpg\" srcset=\"//upload.wikimedia.org/wikipedia/en/thumb/2/2f/SilhouetteCones.jpg/330px-SilhouetteCones.jpg 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/2/2f/SilhouetteCones.jpg/440px-SilhouetteCones.jpg 2x\" width=\"220\"/></a> <div class=\"thumbcaption\"><div class=\"magnify\"><a class=\"internal\" href=\"/wiki/File:SilhouetteCones.jpg\" title=\"Enlarge\"></a></div>A <i><a href=\"/wiki/Visual_hull\" title=\"Visual hull\">visual hull</a></i> can be reconstructed from multiple silhouettes of an object.<sup class=\"reference\" id=\"cite_ref-LaurentiniVisualHull_3-0\"><a href=\"#cite_note-LaurentiniVisualHull-3\">[3]</a></sup></div></div></div>\n<p>The task of converting multiple 2D images into 3D model consists of a series of processing steps:\n</p><p><a href=\"/wiki/Color_mapping\" title=\"Color mapping\">Camera calibration</a> consists of intrinsic and extrinsic parameters, without which at some level no arrangement of algorithms can work. The dotted line between Calibration and Depth determination represents that the camera calibration is usually required for determining depth.\n</p><p><b>Depth determination</b> serves as the most challenging part in the whole process, as it calculates the 3D component missing from any given image – depth. The <a href=\"/wiki/Correspondence_problem\" title=\"Correspondence problem\">correspondence problem</a>, finding matches between two images so the position of the matched elements can then be triangulated in 3D space is the key issue here.\n</p><p>Once you have the multiple <a href=\"/wiki/Depth_map\" title=\"Depth map\">depth maps</a> you have to combine them to create a final mesh by calculating depth and projecting out of the camera – <b><a href=\"/wiki/Image_registration\" title=\"Image registration\">registration</a></b>. Camera calibration will be used to identify where the many meshes created by depth maps can be combined together to develop a larger one, providing more than one view for observation.\n</p><p>By the stage of <b>Material Application</b> you have a complete 3D mesh, which may be the final goal, but usually you will want to apply the color from the original photographs to the mesh. This can range from projecting the images onto the mesh randomly, through approaches of combining the textures for super resolution and finally to segmenting the mesh by material, such as specular and diffuse properties.\n</p>\n<h2><span class=\"mw-headline\" id=\"Mathematical_description_of_reconstruction\">Mathematical description of reconstruction</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=3D_reconstruction_from_multiple_images&amp;action=edit&amp;section=2\" title=\"Edit section: Mathematical description of reconstruction\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>Given a group of 3D points viewed by N cameras with matrices <b><span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math alttext=\"{\\displaystyle \\{P^{i}\\}_{i=1\\ldots N}}\" xmlns=\"http://www.w3.org/1998/Math/MathML\">\n<semantics>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mstyle displaystyle=\"true\" scriptlevel=\"0\">\n<mo fence=\"false\" stretchy=\"false\">{</mo>\n<msup>\n<mi>P</mi>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mi>i</mi>\n</mrow>\n</msup>\n<msub>\n<mo fence=\"false\" stretchy=\"false\">}</mo>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mi>i</mi>\n<mo>=</mo>\n<mn>1</mn>\n<mo>…<!-- … --></mo>\n<mi>N</mi>\n</mrow>\n</msub>\n</mstyle>\n</mrow>\n<annotation encoding=\"application/x-tex\">{\\displaystyle \\{P^{i}\\}_{i=1\\ldots N}}</annotation>\n</semantics>\n</math></span><img alt=\"\\{P^{i}\\}_{{i=1\\ldots N}}\" aria-hidden=\"true\" class=\"mwe-math-fallback-image-inline\" src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/a2ba68093e559121d5806d5ff27320fcdadacf40\" style=\"vertical-align: -0.838ex; width:11.231ex; height:3.176ex;\"/></span></b>. Define <b><span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math alttext=\"{\\displaystyle m_{j}^{i}\\simeq P^{i}w_{j}}\" xmlns=\"http://www.w3.org/1998/Math/MathML\">\n<semantics>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mstyle displaystyle=\"true\" scriptlevel=\"0\">\n<msubsup>\n<mi>m</mi>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mi>j</mi>\n</mrow>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mi>i</mi>\n</mrow>\n</msubsup>\n<mo>≃<!-- ≃ --></mo>\n<msup>\n<mi>P</mi>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mi>i</mi>\n</mrow>\n</msup>\n<msub>\n<mi>w</mi>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mi>j</mi>\n</mrow>\n</msub>\n</mstyle>\n</mrow>\n<annotation encoding=\"application/x-tex\">{\\displaystyle m_{j}^{i}\\simeq P^{i}w_{j}}</annotation>\n</semantics>\n</math></span><img alt=\"m_{j}^{i}\\simeq P^{i}w_{j}\" aria-hidden=\"true\" class=\"mwe-math-fallback-image-inline\" src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/e44901838aab5e0176712c7b6ad364a3a25b9984\" style=\"vertical-align: -1.338ex; width:11.244ex; height:3.676ex;\"/></span></b> be the homogeneous coordinates of the projection of the <b><span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math alttext=\"{\\displaystyle j^{th}}\" xmlns=\"http://www.w3.org/1998/Math/MathML\">\n<semantics>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mstyle displaystyle=\"true\" scriptlevel=\"0\">\n<msup>\n<mi>j</mi>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mi>t</mi>\n<mi>h</mi>\n</mrow>\n</msup>\n</mstyle>\n</mrow>\n<annotation encoding=\"application/x-tex\">{\\displaystyle j^{th}}</annotation>\n</semantics>\n</math></span><img alt=\"j^{th}\" aria-hidden=\"true\" class=\"mwe-math-fallback-image-inline\" src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/04bfd24f79d376ca8156511feb951588f358a928\" style=\"vertical-align: -0.671ex; margin-left: -0.027ex; width:2.758ex; height:3.009ex;\"/></span></b> point onto the <b><span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math alttext=\"{\\displaystyle i^{th}}\" xmlns=\"http://www.w3.org/1998/Math/MathML\">\n<semantics>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mstyle displaystyle=\"true\" scriptlevel=\"0\">\n<msup>\n<mi>i</mi>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mi>t</mi>\n<mi>h</mi>\n</mrow>\n</msup>\n</mstyle>\n</mrow>\n<annotation encoding=\"application/x-tex\">{\\displaystyle i^{th}}</annotation>\n</semantics>\n</math></span><img alt=\"i^{th}\" aria-hidden=\"true\" class=\"mwe-math-fallback-image-inline\" src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/9c454bb35f050556d361ee85e06ca923b16a3bf4\" style=\"vertical-align: -0.338ex; width:2.575ex; height:2.676ex;\"/></span></b> camera. The reconstruction problem can be changed to: given the group of pixel coordinates <b><span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math alttext=\"{\\displaystyle \\{m_{j}^{i}\\}}\" xmlns=\"http://www.w3.org/1998/Math/MathML\">\n<semantics>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mstyle displaystyle=\"true\" scriptlevel=\"0\">\n<mo fence=\"false\" stretchy=\"false\">{</mo>\n<msubsup>\n<mi>m</mi>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mi>j</mi>\n</mrow>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mi>i</mi>\n</mrow>\n</msubsup>\n<mo fence=\"false\" stretchy=\"false\">}</mo>\n</mstyle>\n</mrow>\n<annotation encoding=\"application/x-tex\">{\\displaystyle \\{m_{j}^{i}\\}}</annotation>\n</semantics>\n</math></span><img alt=\"\\{m_{j}^{i}\\}\" aria-hidden=\"true\" class=\"mwe-math-fallback-image-inline\" src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/289931657e6288c38c2cf4d8897a88b0acc62680\" style=\"vertical-align: -1.338ex; width:5.275ex; height:3.509ex;\"/></span></b>, find the corresponding set of camera matrices <b><span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math alttext=\"{\\displaystyle \\{P^{i}\\}}\" xmlns=\"http://www.w3.org/1998/Math/MathML\">\n<semantics>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mstyle displaystyle=\"true\" scriptlevel=\"0\">\n<mo fence=\"false\" stretchy=\"false\">{</mo>\n<msup>\n<mi>P</mi>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mi>i</mi>\n</mrow>\n</msup>\n<mo fence=\"false\" stretchy=\"false\">}</mo>\n</mstyle>\n</mrow>\n<annotation encoding=\"application/x-tex\">{\\displaystyle \\{P^{i}\\}}</annotation>\n</semantics>\n</math></span><img alt=\"\\{P^{i}\\}\" aria-hidden=\"true\" class=\"mwe-math-fallback-image-inline\" src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/88d8e7e9d5875de973a575900e7797281cfb42b2\" style=\"vertical-align: -0.838ex; width:4.946ex; height:3.176ex;\"/></span></b> and the scene structure <b><span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math alttext=\"{\\displaystyle \\{w_{j}\\}}\" xmlns=\"http://www.w3.org/1998/Math/MathML\">\n<semantics>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mstyle displaystyle=\"true\" scriptlevel=\"0\">\n<mo fence=\"false\" stretchy=\"false\">{</mo>\n<msub>\n<mi>w</mi>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mi>j</mi>\n</mrow>\n</msub>\n<mo fence=\"false\" stretchy=\"false\">}</mo>\n</mstyle>\n</mrow>\n<annotation encoding=\"application/x-tex\">{\\displaystyle \\{w_{j}\\}}</annotation>\n</semantics>\n</math></span><img alt=\"\\{w_{j}\\}\" aria-hidden=\"true\" class=\"mwe-math-fallback-image-inline\" src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/b87ad31d717349a9116532c453ab01b061dd035d\" style=\"vertical-align: -1.005ex; width:4.899ex; height:3.009ex;\"/></span></b> such that\n</p>\n<dl><dd><span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math alttext=\"{\\displaystyle m_{j}^{i}\\simeq P^{i}w_{j}}\" xmlns=\"http://www.w3.org/1998/Math/MathML\">\n<semantics>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mstyle displaystyle=\"true\" scriptlevel=\"0\">\n<msubsup>\n<mi>m</mi>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mi>j</mi>\n</mrow>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mi>i</mi>\n</mrow>\n</msubsup>\n<mo>≃<!-- ≃ --></mo>\n<msup>\n<mi>P</mi>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mi>i</mi>\n</mrow>\n</msup>\n<msub>\n<mi>w</mi>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mi>j</mi>\n</mrow>\n</msub>\n</mstyle>\n</mrow>\n<annotation encoding=\"application/x-tex\">{\\displaystyle m_{j}^{i}\\simeq P^{i}w_{j}}</annotation>\n</semantics>\n</math></span><img alt=\"m_{j}^{i}\\simeq P^{i}w_{j}\" aria-hidden=\"true\" class=\"mwe-math-fallback-image-inline\" src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/e44901838aab5e0176712c7b6ad364a3a25b9984\" style=\"vertical-align: -1.338ex; width:11.244ex; height:3.676ex;\"/></span> (1)</dd></dl>\n<p>Generally, without further restrictions, we will obtain a projective reconstruction.<sup class=\"reference\" id=\"cite_ref-4\"><a href=\"#cite_note-4\">[4]</a></sup><sup class=\"reference\" id=\"cite_ref-5\"><a href=\"#cite_note-5\">[5]</a></sup> If <b><span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math alttext=\"{\\displaystyle \\{P^{i}\\}}\" xmlns=\"http://www.w3.org/1998/Math/MathML\">\n<semantics>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mstyle displaystyle=\"true\" scriptlevel=\"0\">\n<mo fence=\"false\" stretchy=\"false\">{</mo>\n<msup>\n<mi>P</mi>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mi>i</mi>\n</mrow>\n</msup>\n<mo fence=\"false\" stretchy=\"false\">}</mo>\n</mstyle>\n</mrow>\n<annotation encoding=\"application/x-tex\">{\\displaystyle \\{P^{i}\\}}</annotation>\n</semantics>\n</math></span><img alt=\"\\{P^{i}\\}\" aria-hidden=\"true\" class=\"mwe-math-fallback-image-inline\" src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/88d8e7e9d5875de973a575900e7797281cfb42b2\" style=\"vertical-align: -0.838ex; width:4.946ex; height:3.176ex;\"/></span></b> and <b><span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math alttext=\"{\\displaystyle \\{w_{j}\\}}\" xmlns=\"http://www.w3.org/1998/Math/MathML\">\n<semantics>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mstyle displaystyle=\"true\" scriptlevel=\"0\">\n<mo fence=\"false\" stretchy=\"false\">{</mo>\n<msub>\n<mi>w</mi>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mi>j</mi>\n</mrow>\n</msub>\n<mo fence=\"false\" stretchy=\"false\">}</mo>\n</mstyle>\n</mrow>\n<annotation encoding=\"application/x-tex\">{\\displaystyle \\{w_{j}\\}}</annotation>\n</semantics>\n</math></span><img alt=\"\\{w_{j}\\}\" aria-hidden=\"true\" class=\"mwe-math-fallback-image-inline\" src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/b87ad31d717349a9116532c453ab01b061dd035d\" style=\"vertical-align: -1.005ex; width:4.899ex; height:3.009ex;\"/></span></b>  satisfy (1), <b><span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math alttext=\"{\\displaystyle \\{P^{i}T\\}}\" xmlns=\"http://www.w3.org/1998/Math/MathML\">\n<semantics>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mstyle displaystyle=\"true\" scriptlevel=\"0\">\n<mo fence=\"false\" stretchy=\"false\">{</mo>\n<msup>\n<mi>P</mi>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mi>i</mi>\n</mrow>\n</msup>\n<mi>T</mi>\n<mo fence=\"false\" stretchy=\"false\">}</mo>\n</mstyle>\n</mrow>\n<annotation encoding=\"application/x-tex\">{\\displaystyle \\{P^{i}T\\}}</annotation>\n</semantics>\n</math></span><img alt=\"\\{P^{i}T\\}\" aria-hidden=\"true\" class=\"mwe-math-fallback-image-inline\" src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/5281ad3a3ed6162a39393895e1115acb03c783df\" style=\"vertical-align: -0.838ex; width:6.582ex; height:3.176ex;\"/></span></b> and <b><span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math alttext=\"{\\displaystyle \\{T^{-1}w_{j}\\}}\" xmlns=\"http://www.w3.org/1998/Math/MathML\">\n<semantics>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mstyle displaystyle=\"true\" scriptlevel=\"0\">\n<mo fence=\"false\" stretchy=\"false\">{</mo>\n<msup>\n<mi>T</mi>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mo>−<!-- − --></mo>\n<mn>1</mn>\n</mrow>\n</msup>\n<msub>\n<mi>w</mi>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mi>j</mi>\n</mrow>\n</msub>\n<mo fence=\"false\" stretchy=\"false\">}</mo>\n</mstyle>\n</mrow>\n<annotation encoding=\"application/x-tex\">{\\displaystyle \\{T^{-1}w_{j}\\}}</annotation>\n</semantics>\n</math></span><img alt=\"\\{T^{{-1}}w_{j}\\}\" aria-hidden=\"true\" class=\"mwe-math-fallback-image-inline\" src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/962a6eb01ba65e225853237c917cd0531e7c6f56\" style=\"vertical-align: -1.005ex; width:8.952ex; height:3.343ex;\"/></span></b> will satisfy (1) with any <b>4 × 4</b> nonsingular matrix <b>T</b>.\n</p><p>A projective reconstruction can be calculated by points correspondences only, without any a-priori information.\n</p>\n<h2><span class=\"mw-headline\" id=\"Autocalibration\">Autocalibration</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=3D_reconstruction_from_multiple_images&amp;action=edit&amp;section=3\" title=\"Edit section: Autocalibration\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p><b>Autocalibration</b> or self-calibration is the classical approach, in which camera motion and parameters are recovered first, using rigidity, then structure is readily calculated. Two methods implementing this idea are presented as follows:\n</p>\n<h3><span class=\"mw-headline\" id=\"Kruppa_equations\">Kruppa equations</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=3D_reconstruction_from_multiple_images&amp;action=edit&amp;section=4\" title=\"Edit section: Kruppa equations\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>With a minimum of three displacements, we can obtain the internal parameters of the camera using a system of polynomial equations due to Kruppa,<sup class=\"reference\" id=\"cite_ref-6\"><a href=\"#cite_note-6\">[6]</a></sup> which are derived from a geometric interpretation of the rigidity constraint.<sup class=\"reference\" id=\"cite_ref-7\"><a href=\"#cite_note-7\">[7]</a></sup><sup class=\"reference\" id=\"cite_ref-8\"><a href=\"#cite_note-8\">[8]</a></sup>\n</p><p>The matrix <b><span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math alttext=\"{\\displaystyle K=AA^{\\top }}\" xmlns=\"http://www.w3.org/1998/Math/MathML\">\n<semantics>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mstyle displaystyle=\"true\" scriptlevel=\"0\">\n<mi>K</mi>\n<mo>=</mo>\n<mi>A</mi>\n<msup>\n<mi>A</mi>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mi mathvariant=\"normal\">⊤<!-- ⊤ --></mi>\n</mrow>\n</msup>\n</mstyle>\n</mrow>\n<annotation encoding=\"application/x-tex\">{\\displaystyle K=AA^{\\top }}</annotation>\n</semantics>\n</math></span><img alt=\"K=AA^{{\\top }}\" aria-hidden=\"true\" class=\"mwe-math-fallback-image-inline\" src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/127382093ac66394f4b3cdbdf4accbf78c0dd2f2\" style=\"vertical-align: -0.338ex; width:10.161ex; height:2.676ex;\"/></span></b> is unknown in the Kruppa equations, named Kruppa coefficients matrix. With <b> K</b> and by the method of Cholesky factorization one can obtain the intrinsic parameters easily:\n</p>\n<dl><dd><span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math alttext=\"{\\displaystyle K={\\begin{bmatrix}k_{1}&amp;k_{2}&amp;k_{3}\\\\k_{2}&amp;k_{4}&amp;k_{5}\\\\k_{3}&amp;k_{5}&amp;1\\\\\\end{bmatrix}}}\" xmlns=\"http://www.w3.org/1998/Math/MathML\">\n<semantics>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mstyle displaystyle=\"true\" scriptlevel=\"0\">\n<mi>K</mi>\n<mo>=</mo>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mrow>\n<mo>[</mo>\n<mtable columnspacing=\"1em\" rowspacing=\"4pt\">\n<mtr>\n<mtd>\n<msub>\n<mi>k</mi>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mn>1</mn>\n</mrow>\n</msub>\n</mtd>\n<mtd>\n<msub>\n<mi>k</mi>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mn>2</mn>\n</mrow>\n</msub>\n</mtd>\n<mtd>\n<msub>\n<mi>k</mi>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mn>3</mn>\n</mrow>\n</msub>\n</mtd>\n</mtr>\n<mtr>\n<mtd>\n<msub>\n<mi>k</mi>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mn>2</mn>\n</mrow>\n</msub>\n</mtd>\n<mtd>\n<msub>\n<mi>k</mi>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mn>4</mn>\n</mrow>\n</msub>\n</mtd>\n<mtd>\n<msub>\n<mi>k</mi>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mn>5</mn>\n</mrow>\n</msub>\n</mtd>\n</mtr>\n<mtr>\n<mtd>\n<msub>\n<mi>k</mi>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mn>3</mn>\n</mrow>\n</msub>\n</mtd>\n<mtd>\n<msub>\n<mi>k</mi>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mn>5</mn>\n</mrow>\n</msub>\n</mtd>\n<mtd>\n<mn>1</mn>\n</mtd>\n</mtr>\n</mtable>\n<mo>]</mo>\n</mrow>\n</mrow>\n</mstyle>\n</mrow>\n<annotation encoding=\"application/x-tex\">{\\displaystyle K={\\begin{bmatrix}k_{1}&amp;k_{2}&amp;k_{3}\\\\k_{2}&amp;k_{4}&amp;k_{5}\\\\k_{3}&amp;k_{5}&amp;1\\\\\\end{bmatrix}}}</annotation>\n</semantics>\n</math></span><img alt=\"K={\\begin{bmatrix}k_{1}&amp;k_{2}&amp;k_{3}\\\\k_{2}&amp;k_{4}&amp;k_{5}\\\\k_{3}&amp;k_{5}&amp;1\\\\\\end{bmatrix}}\" aria-hidden=\"true\" class=\"mwe-math-fallback-image-inline\" src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/0e0f00e449c5bb03a37f619904346f6446cfea5b\" style=\"vertical-align: -4.005ex; width:20.458ex; height:9.176ex;\"/></span></dd></dl>\n<p>Recently Hartley <sup class=\"reference\" id=\"cite_ref-Hartley_9-0\"><a href=\"#cite_note-Hartley-9\">[9]</a></sup> proposed a simpler form. Let <b><span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math alttext=\"{\\displaystyle F}\" xmlns=\"http://www.w3.org/1998/Math/MathML\">\n<semantics>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mstyle displaystyle=\"true\" scriptlevel=\"0\">\n<mi>F</mi>\n</mstyle>\n</mrow>\n<annotation encoding=\"application/x-tex\">{\\displaystyle F}</annotation>\n</semantics>\n</math></span><img alt=\"F\" aria-hidden=\"true\" class=\"mwe-math-fallback-image-inline\" src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/545fd099af8541605f7ee55f08225526be88ce57\" style=\"vertical-align: -0.338ex; width:1.741ex; height:2.176ex;\"/></span></b> be written as <b><span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math alttext=\"{\\displaystyle F=DUV^{\\top }}\" xmlns=\"http://www.w3.org/1998/Math/MathML\">\n<semantics>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mstyle displaystyle=\"true\" scriptlevel=\"0\">\n<mi>F</mi>\n<mo>=</mo>\n<mi>D</mi>\n<mi>U</mi>\n<msup>\n<mi>V</mi>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mi mathvariant=\"normal\">⊤<!-- ⊤ --></mi>\n</mrow>\n</msup>\n</mstyle>\n</mrow>\n<annotation encoding=\"application/x-tex\">{\\displaystyle F=DUV^{\\top }}</annotation>\n</semantics>\n</math></span><img alt=\"F=DUV^{\\top }\" aria-hidden=\"true\" class=\"mwe-math-fallback-image-inline\" src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/2a759c4c5cdaa1489d2d99c30e29f0990d67c92d\" style=\"vertical-align: -0.338ex; width:11.974ex; height:2.676ex;\"/></span></b>, where\n</p><p>Then the Kruppa equations are rewritten (the derivation can be found in <sup class=\"reference\" id=\"cite_ref-Hartley_9-1\"><a href=\"#cite_note-Hartley-9\">[9]</a></sup>)\n</p>\n<h3><span id=\"Mendon.C3.A7a_and_Cipolla\"></span><span class=\"mw-headline\" id=\"Mendonça_and_Cipolla\">Mendonça and Cipolla</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=3D_reconstruction_from_multiple_images&amp;action=edit&amp;section=5\" title=\"Edit section: Mendonça and Cipolla\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>This method is based on the use of rigidity constraint. Design a cost function, which considers the intrinsic parameters as arguments and the <a href=\"/wiki/Fundamental_matrix_(computer_vision)\" title=\"Fundamental matrix (computer vision)\">fundamental matrices</a> as parameters. <b><span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math alttext=\"{\\displaystyle {F}_{i}j}\" xmlns=\"http://www.w3.org/1998/Math/MathML\">\n<semantics>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mstyle displaystyle=\"true\" scriptlevel=\"0\">\n<msub>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mi>F</mi>\n</mrow>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mi>i</mi>\n</mrow>\n</msub>\n<mi>j</mi>\n</mstyle>\n</mrow>\n<annotation encoding=\"application/x-tex\">{\\displaystyle {F}_{i}j}</annotation>\n</semantics>\n</math></span><img alt=\"{F}_{i}j\" aria-hidden=\"true\" class=\"mwe-math-fallback-image-inline\" src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/9a29163bdc48a69df9ffc7bdf4089e32dce5e8f9\" style=\"vertical-align: -0.671ex; width:3.252ex; height:2.509ex;\"/></span></b> is defined as the fundamental matrix, <b><span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math alttext=\"{\\displaystyle {A}_{i}}\" xmlns=\"http://www.w3.org/1998/Math/MathML\">\n<semantics>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mstyle displaystyle=\"true\" scriptlevel=\"0\">\n<msub>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mi>A</mi>\n</mrow>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mi>i</mi>\n</mrow>\n</msub>\n</mstyle>\n</mrow>\n<annotation encoding=\"application/x-tex\">{\\displaystyle {A}_{i}}</annotation>\n</semantics>\n</math></span><img alt=\"{A}_{i}\" aria-hidden=\"true\" class=\"mwe-math-fallback-image-inline\" src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/cb7170d545866196897e484f39e205c1d817a701\" style=\"vertical-align: -0.671ex; width:2.543ex; height:2.509ex;\"/></span></b>and <b><span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math alttext=\"{\\displaystyle {A}_{j}}\" xmlns=\"http://www.w3.org/1998/Math/MathML\">\n<semantics>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mstyle displaystyle=\"true\" scriptlevel=\"0\">\n<msub>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mi>A</mi>\n</mrow>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mi>j</mi>\n</mrow>\n</msub>\n</mstyle>\n</mrow>\n<annotation encoding=\"application/x-tex\">{\\displaystyle {A}_{j}}</annotation>\n</semantics>\n</math></span><img alt=\"{A}_{j}\" aria-hidden=\"true\" class=\"mwe-math-fallback-image-inline\" src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/694315a09b163ac68069fd91bcd0e8b97559f50d\" style=\"vertical-align: -1.005ex; width:2.653ex; height:2.843ex;\"/></span></b> as intrinsic parameters matrices.\n</p>\n<h2><span class=\"mw-headline\" id=\"Stratification\">Stratification</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=3D_reconstruction_from_multiple_images&amp;action=edit&amp;section=6\" title=\"Edit section: Stratification\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>Recently, new methods based on the concept of <b>stratification</b> have been proposed. Starting from a projective structure, which can be calculated from correspondences only, upgrade this projective reconstruction to a Euclidean reconstruction, by making use of all the available constraints. With this idea the problem can be stratified into different sections: according to the amount of constraints available, it can be analyzed at a different level, projective, affine or Euclidean.\n</p>\n<h3><span class=\"mw-headline\" id=\"The_stratification_of_3D_geometry\">The stratification of 3D geometry</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=3D_reconstruction_from_multiple_images&amp;action=edit&amp;section=7\" title=\"Edit section: The stratification of 3D geometry\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>Usually, the world is perceived as a 3D <a href=\"/wiki/Euclidean_space\" title=\"Euclidean space\">Euclidean space</a>. In some cases, it is not possible to use the full Euclidean structure of 3D space. The simplest being projective, then the affine geometry which forms the intermediate layers and finally Euclidean geometry. The concept of stratification is closely related to the series of transformations on geometric entities: in the projective stratum is a series of projective transformations (a <a href=\"/wiki/Homography_(computer_vision)\" title=\"Homography (computer vision)\">homography</a>), in the affine stratum is a series of <a class=\"mw-redirect\" href=\"/wiki/Affine_transformations\" title=\"Affine transformations\">affine transformations</a>, and in Euclidean stratum is a series of Euclidean transformations.\n</p><p>Suppose that a fixed scene is captured by two or more perspective cameras and the correspondences between visible points in different images are already given. However, in practice, the matching is an essential and extremely challenging issue in computer vision. Here, we suppose that <span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math alttext=\"{\\displaystyle n}\" xmlns=\"http://www.w3.org/1998/Math/MathML\">\n<semantics>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mstyle displaystyle=\"true\" scriptlevel=\"0\">\n<mi>n</mi>\n</mstyle>\n</mrow>\n<annotation encoding=\"application/x-tex\">{\\displaystyle n}</annotation>\n</semantics>\n</math></span><img alt=\"n\" aria-hidden=\"true\" class=\"mwe-math-fallback-image-inline\" src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/a601995d55609f2d9f5e233e36fbe9ea26011b3b\" style=\"vertical-align: -0.338ex; width:1.395ex; height:1.676ex;\"/></span> 3D points <span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math alttext=\"{\\displaystyle A_{i}}\" xmlns=\"http://www.w3.org/1998/Math/MathML\">\n<semantics>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mstyle displaystyle=\"true\" scriptlevel=\"0\">\n<msub>\n<mi>A</mi>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mi>i</mi>\n</mrow>\n</msub>\n</mstyle>\n</mrow>\n<annotation encoding=\"application/x-tex\">{\\displaystyle A_{i}}</annotation>\n</semantics>\n</math></span><img alt=\"A_{i}\" aria-hidden=\"true\" class=\"mwe-math-fallback-image-inline\" src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/1aed3b5def921afbe6cc48aaf8f9b11c6f1c1e2d\" style=\"vertical-align: -0.671ex; width:2.543ex; height:2.509ex;\"/></span> are observed by <span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math alttext=\"{\\displaystyle m}\" xmlns=\"http://www.w3.org/1998/Math/MathML\">\n<semantics>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mstyle displaystyle=\"true\" scriptlevel=\"0\">\n<mi>m</mi>\n</mstyle>\n</mrow>\n<annotation encoding=\"application/x-tex\">{\\displaystyle m}</annotation>\n</semantics>\n</math></span><img alt=\"m\" aria-hidden=\"true\" class=\"mwe-math-fallback-image-inline\" src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/0a07d98bb302f3856cbabc47b2b9016692e3f7bc\" style=\"vertical-align: -0.338ex; width:2.04ex; height:1.676ex;\"/></span> cameras with projection matrices <span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math alttext=\"{\\displaystyle P_{j},j=1,\\ldots ,m.}\" xmlns=\"http://www.w3.org/1998/Math/MathML\">\n<semantics>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mstyle displaystyle=\"true\" scriptlevel=\"0\">\n<msub>\n<mi>P</mi>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mi>j</mi>\n</mrow>\n</msub>\n<mo>,</mo>\n<mi>j</mi>\n<mo>=</mo>\n<mn>1</mn>\n<mo>,</mo>\n<mo>…<!-- … --></mo>\n<mo>,</mo>\n<mi>m</mi>\n<mo>.</mo>\n</mstyle>\n</mrow>\n<annotation encoding=\"application/x-tex\">{\\displaystyle P_{j},j=1,\\ldots ,m.}</annotation>\n</semantics>\n</math></span><img alt=\"P_{{j}},j=1,\\ldots ,m.\" aria-hidden=\"true\" class=\"mwe-math-fallback-image-inline\" src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/bc303443732eec6af229f765729a9290ed712b0c\" style=\"vertical-align: -1.005ex; width:16.52ex; height:2.843ex;\"/></span> Neither the positions of point nor the projection of camera are known. Only the projections <span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math alttext=\"{\\displaystyle a_{ij}}\" xmlns=\"http://www.w3.org/1998/Math/MathML\">\n<semantics>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mstyle displaystyle=\"true\" scriptlevel=\"0\">\n<msub>\n<mi>a</mi>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mi>i</mi>\n<mi>j</mi>\n</mrow>\n</msub>\n</mstyle>\n</mrow>\n<annotation encoding=\"application/x-tex\">{\\displaystyle a_{ij}}</annotation>\n</semantics>\n</math></span><img alt=\"a_{ij}\" aria-hidden=\"true\" class=\"mwe-math-fallback-image-inline\" src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/ebea6cd2813c330c798921a2894b358f7b643917\" style=\"vertical-align: -1.005ex; width:2.707ex; height:2.343ex;\"/></span> of the <span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math alttext=\"{\\displaystyle i^{th}}\" xmlns=\"http://www.w3.org/1998/Math/MathML\">\n<semantics>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mstyle displaystyle=\"true\" scriptlevel=\"0\">\n<msup>\n<mi>i</mi>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mi>t</mi>\n<mi>h</mi>\n</mrow>\n</msup>\n</mstyle>\n</mrow>\n<annotation encoding=\"application/x-tex\">{\\displaystyle i^{th}}</annotation>\n</semantics>\n</math></span><img alt=\"i^{th}\" aria-hidden=\"true\" class=\"mwe-math-fallback-image-inline\" src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/9c454bb35f050556d361ee85e06ca923b16a3bf4\" style=\"vertical-align: -0.338ex; width:2.575ex; height:2.676ex;\"/></span> point in the <span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math alttext=\"{\\displaystyle j^{th}}\" xmlns=\"http://www.w3.org/1998/Math/MathML\">\n<semantics>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mstyle displaystyle=\"true\" scriptlevel=\"0\">\n<msup>\n<mi>j</mi>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mi>t</mi>\n<mi>h</mi>\n</mrow>\n</msup>\n</mstyle>\n</mrow>\n<annotation encoding=\"application/x-tex\">{\\displaystyle j^{th}}</annotation>\n</semantics>\n</math></span><img alt=\"j^{th}\" aria-hidden=\"true\" class=\"mwe-math-fallback-image-inline\" src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/04bfd24f79d376ca8156511feb951588f358a928\" style=\"vertical-align: -0.671ex; margin-left: -0.027ex; width:2.758ex; height:3.009ex;\"/></span> image are known.\n</p>\n<h3><span class=\"mw-headline\" id=\"Projective_reconstruction\">Projective reconstruction</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=3D_reconstruction_from_multiple_images&amp;action=edit&amp;section=8\" title=\"Edit section: Projective reconstruction\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>Simple counting indicates we have <span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math alttext=\"{\\displaystyle 2nm}\" xmlns=\"http://www.w3.org/1998/Math/MathML\">\n<semantics>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mstyle displaystyle=\"true\" scriptlevel=\"0\">\n<mn>2</mn>\n<mi>n</mi>\n<mi>m</mi>\n</mstyle>\n</mrow>\n<annotation encoding=\"application/x-tex\">{\\displaystyle 2nm}</annotation>\n</semantics>\n</math></span><img alt=\"2nm\" aria-hidden=\"true\" class=\"mwe-math-fallback-image-inline\" src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/4ec69063750cddbe43e4e638a5d222aeb5156541\" style=\"vertical-align: -0.338ex; width:4.598ex; height:2.176ex;\"/></span> independent measurements and only <span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math alttext=\"{\\displaystyle 11m+3n}\" xmlns=\"http://www.w3.org/1998/Math/MathML\">\n<semantics>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mstyle displaystyle=\"true\" scriptlevel=\"0\">\n<mn>11</mn>\n<mi>m</mi>\n<mo>+</mo>\n<mn>3</mn>\n<mi>n</mi>\n</mstyle>\n</mrow>\n<annotation encoding=\"application/x-tex\">{\\displaystyle 11m+3n}</annotation>\n</semantics>\n</math></span><img alt=\"11m+3n\" aria-hidden=\"true\" class=\"mwe-math-fallback-image-inline\" src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/873aa0e924f9f638e634d6c75907156e02615aba\" style=\"vertical-align: -0.505ex; width:9.763ex; height:2.343ex;\"/></span> unknowns, so the problem is supposed to be soluble with enough points and images. The equations in homogeneous coordinates can be represented:\n</p>\n<dl><dd><span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math alttext=\"{\\displaystyle a_{ij}\\sim P_{j}A_{i}\\qquad i=1,\\ldots n,~~j=1,\\ldots m}\" xmlns=\"http://www.w3.org/1998/Math/MathML\">\n<semantics>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mstyle displaystyle=\"true\" scriptlevel=\"0\">\n<msub>\n<mi>a</mi>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mi>i</mi>\n<mi>j</mi>\n</mrow>\n</msub>\n<mo>∼<!-- ∼ --></mo>\n<msub>\n<mi>P</mi>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mi>j</mi>\n</mrow>\n</msub>\n<msub>\n<mi>A</mi>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mi>i</mi>\n</mrow>\n</msub>\n<mspace width=\"2em\"></mspace>\n<mi>i</mi>\n<mo>=</mo>\n<mn>1</mn>\n<mo>,</mo>\n<mo>…<!-- … --></mo>\n<mi>n</mi>\n<mo>,</mo>\n<mtext> </mtext>\n<mtext> </mtext>\n<mi>j</mi>\n<mo>=</mo>\n<mn>1</mn>\n<mo>,</mo>\n<mo>…<!-- … --></mo>\n<mi>m</mi>\n</mstyle>\n</mrow>\n<annotation encoding=\"application/x-tex\">{\\displaystyle a_{ij}\\sim P_{j}A_{i}\\qquad i=1,\\ldots n,~~j=1,\\ldots m}</annotation>\n</semantics>\n</math></span><img alt=\"a_{{ij}}\\sim P_{{j}}A_{{i}}\\qquad i=1,\\ldots n,~~j=1,\\ldots m\" aria-hidden=\"true\" class=\"mwe-math-fallback-image-inline\" src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/882eae9e7a0ea91b2c82a2393a7bf286148c4ba0\" style=\"vertical-align: -1.005ex; width:39.597ex; height:2.843ex;\"/></span>       (2)</dd></dl>\n<p>So we can apply a nonsingular <b>4 × 4</b> transformation <i>H</i> to projections <b><span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math alttext=\"{\\displaystyle P_{j}}\" xmlns=\"http://www.w3.org/1998/Math/MathML\">\n<semantics>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mstyle displaystyle=\"true\" scriptlevel=\"0\">\n<msub>\n<mi>P</mi>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mi>j</mi>\n</mrow>\n</msub>\n</mstyle>\n</mrow>\n<annotation encoding=\"application/x-tex\">{\\displaystyle P_{j}}</annotation>\n</semantics>\n</math></span><img alt=\"P_{j}\" aria-hidden=\"true\" class=\"mwe-math-fallback-image-inline\" src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/4a5da6c3564a2129f714ef11acd8ba649d18e604\" style=\"vertical-align: -1.005ex; width:2.402ex; height:2.843ex;\"/></span>→<span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math alttext=\"{\\displaystyle P_{j}H^{-1}}\" xmlns=\"http://www.w3.org/1998/Math/MathML\">\n<semantics>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mstyle displaystyle=\"true\" scriptlevel=\"0\">\n<msub>\n<mi>P</mi>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mi>j</mi>\n</mrow>\n</msub>\n<msup>\n<mi>H</mi>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mo>−<!-- − --></mo>\n<mn>1</mn>\n</mrow>\n</msup>\n</mstyle>\n</mrow>\n<annotation encoding=\"application/x-tex\">{\\displaystyle P_{j}H^{-1}}</annotation>\n</semantics>\n</math></span><img alt=\"P_{{j}}H^{{-1}}\" aria-hidden=\"true\" class=\"mwe-math-fallback-image-inline\" src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/4a81e73136652a4227d1570589e93e035a62995c\" style=\"vertical-align: -1.005ex; width:6.838ex; height:3.343ex;\"/></span></b> and world points <b><span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math alttext=\"{\\displaystyle A_{i}}\" xmlns=\"http://www.w3.org/1998/Math/MathML\">\n<semantics>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mstyle displaystyle=\"true\" scriptlevel=\"0\">\n<msub>\n<mi>A</mi>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mi>i</mi>\n</mrow>\n</msub>\n</mstyle>\n</mrow>\n<annotation encoding=\"application/x-tex\">{\\displaystyle A_{i}}</annotation>\n</semantics>\n</math></span><img alt=\"A_{i}\" aria-hidden=\"true\" class=\"mwe-math-fallback-image-inline\" src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/1aed3b5def921afbe6cc48aaf8f9b11c6f1c1e2d\" style=\"vertical-align: -0.671ex; width:2.543ex; height:2.509ex;\"/></span>→<span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math alttext=\"{\\displaystyle HA_{i}}\" xmlns=\"http://www.w3.org/1998/Math/MathML\">\n<semantics>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mstyle displaystyle=\"true\" scriptlevel=\"0\">\n<mi>H</mi>\n<msub>\n<mi>A</mi>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mi>i</mi>\n</mrow>\n</msub>\n</mstyle>\n</mrow>\n<annotation encoding=\"application/x-tex\">{\\displaystyle HA_{i}}</annotation>\n</semantics>\n</math></span><img alt=\"HA_{i}\" aria-hidden=\"true\" class=\"mwe-math-fallback-image-inline\" src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/d9d4841e8f90b25cb89ef78ae52d311f703368c9\" style=\"vertical-align: -0.671ex; width:4.606ex; height:2.509ex;\"/></span></b>. Hence, without further constraints, reconstruction is only an unknown projective deformation of the 3D world.\n</p>\n<h3><span class=\"mw-headline\" id=\"Affine_reconstruction\">Affine reconstruction</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=3D_reconstruction_from_multiple_images&amp;action=edit&amp;section=9\" title=\"Edit section: Affine reconstruction\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p><i>See <a href=\"/wiki/Affine_space\" title=\"Affine space\">affine space</a> for more detailed information about computing the location of the plane at infinity <b><span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math alttext=\"{\\displaystyle {\\Pi }_{\\infty }}\" xmlns=\"http://www.w3.org/1998/Math/MathML\">\n<semantics>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mstyle displaystyle=\"true\" scriptlevel=\"0\">\n<msub>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mi mathvariant=\"normal\">Π<!-- Π --></mi>\n</mrow>\n<mrow class=\"MJX-TeXAtom-ORD\">\n<mi mathvariant=\"normal\">∞<!-- ∞ --></mi>\n</mrow>\n</msub>\n</mstyle>\n</mrow>\n<annotation encoding=\"application/x-tex\">{\\displaystyle {\\Pi }_{\\infty }}</annotation>\n</semantics>\n</math></span><img alt=\"{\\Pi }_{{\\infty }}\" aria-hidden=\"true\" class=\"mwe-math-fallback-image-inline\" src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/1b6a36bc0597259c739fad4ec0598d27458850fe\" style=\"vertical-align: -0.671ex; width:3.619ex; height:2.509ex;\"/></span></b>.</i>\nThe simplest way is to exploit prior knowledge, for example the information that lines in the scene are parallel or that a point is the one thirds between two others.\n</p><p>We can also use prior constraints on the camera motion. By analyzing different images of the same point can obtain a line in the direction of motion. The intersection of several lines is the point at infinity in the motion direction, and one constraint on the affine structure.\n</p>\n<h3><span class=\"mw-headline\" id=\"Euclidean_reconstruction\">Euclidean reconstruction</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=3D_reconstruction_from_multiple_images&amp;action=edit&amp;section=10\" title=\"Edit section: Euclidean reconstruction\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>By mapping the projective reconstruction to one that satisfies a group of redundant Euclidean constraints, we can find a projective transformation <i>H</i> in equation (2).The equations are highly nonlinear and a good initial guess for the structure is required. This can be obtained by assuming a linear projection - parallel projection, which also allows easy reconstruction by SVD decomposition.<sup class=\"reference\" id=\"cite_ref-Tomasi_2-1\"><a href=\"#cite_note-Tomasi-2\">[2]</a></sup>\n</p>\n<h2><span class=\"mw-headline\" id=\"Algebraic_vs_geometric_error\">Algebraic vs geometric error</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=3D_reconstruction_from_multiple_images&amp;action=edit&amp;section=11\" title=\"Edit section: Algebraic vs geometric error\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>Inevitably, measured data (i.e., image or world point positions) is noisy and the noise comes from many sources. To reduce the effect of noise, we usually use more equations than necessary and solve with <a href=\"/wiki/Least_squares\" title=\"Least squares\">least squares</a>.\n</p><p>For example, in a typical null-space problem formulation Ax = 0 (like the DLT algorithm), the square of the residual ||Ax|| is being minimized with the least squares method.\n</p><p>In general, if ||Ax|| can be considered as a distance between the geometrical entities (points, lines, planes, etc.), then what is being minimized is a <b>geometric error</b>, otherwise (when the error lacks a good geometrical interpretation) it is called an <b>algebraic error</b>.\n</p><p>Therefore, compared with algebraic error, we prefer to minimize a geometric error for the reasons listed:\n</p>\n<ol><li>The quantity being minimized has a meaning.</li>\n<li>The solution is more stable.</li>\n<li>The solution is constant under Euclidean transforms.</li></ol>\n<p>All the linear algorithms (DLT and others) we have seen so far minimize an algebraic error. Actually, there is no justification in minimizing an algebraic error apart from the ease of implementation, as it results in a linear problem. The minimization of a geometric error is often a non-linear problem, that admit only iterative solutions and requires a starting point.\n</p><p>Usually, linear solution based on algebraic residuals serves as a starting point for a non-linear minimization of a geometric cost function, which provides the solution a final “polish”.<sup class=\"reference\" id=\"cite_ref-10\"><a href=\"#cite_note-10\">[10]</a></sup>\n</p>\n<h2><span class=\"mw-headline\" id=\"3D_reconstruction_of_Medical_Images\">3D reconstruction of Medical Images</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=3D_reconstruction_from_multiple_images&amp;action=edit&amp;section=12\" title=\"Edit section: 3D reconstruction of Medical Images\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<h3><span id=\"Motivation_.26_applications\"></span><span class=\"mw-headline\" id=\"Motivation_&amp;_applications\">Motivation &amp; applications</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=3D_reconstruction_from_multiple_images&amp;action=edit&amp;section=13\" title=\"Edit section: Motivation &amp; applications\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>The 2-D imaging has problems of anatomy overlapping with each other and don’t disclose the abnormalities. The 3-D imaging can be used for both diagnostic and therapeutic purposes.\n</p><p>3-D models are used for planning the operation, morphometric studies and has more reliability in orthopedics.\n</p>\n<div class=\"thumb tright\"><div class=\"thumbinner\" style=\"width:222px;\"><a class=\"image\" href=\"/wiki/File:Epipolar_Geometry1.svg\"><img alt=\"\" class=\"thumbimage\" data-file-height=\"285\" data-file-width=\"431\" decoding=\"async\" height=\"145\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/f/f2/Epipolar_Geometry1.svg/220px-Epipolar_Geometry1.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/f/f2/Epipolar_Geometry1.svg/330px-Epipolar_Geometry1.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/f/f2/Epipolar_Geometry1.svg/440px-Epipolar_Geometry1.svg.png 2x\" width=\"220\"/></a> <div class=\"thumbcaption\"><div class=\"magnify\"><a class=\"internal\" href=\"/wiki/File:Epipolar_Geometry1.svg\" title=\"Enlarge\"></a></div>Projection of P on both cameras</div></div></div>\n<h3><span id=\"Problem_statement_.26_Basics\"></span><span class=\"mw-headline\" id=\"Problem_statement_&amp;_Basics\">Problem statement &amp; Basics</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=3D_reconstruction_from_multiple_images&amp;action=edit&amp;section=14\" title=\"Edit section: Problem statement &amp; Basics\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>To reconstruct 3-D images from 2-D images taken by a camera at multiple angles. <a href=\"/wiki/Medical_imaging\" title=\"Medical imaging\">Medical imaging</a> techniques like <a class=\"mw-redirect\" href=\"/wiki/CT_scanning\" title=\"CT scanning\">CT scanning</a> and MRI are expensive, and although CT scans are accurate, they can induce high radiation doses which is a risk for patients with certain diseases. Methods based on MRI are not accurate. Since we are exposed to powerful magnetic fields during an MRI scan, this method is not suitable for patients with ferromagnetic metallic implants. Both the methods can be done only when in lying position where the global structure of the bone changes. So, we discuss the following methods which can be performed while standing and require low radiation dose.\n</p><p>Though these techniques are 3-D imaging, the region of interest is restricted to a slice; data are acquired to form a time sequence.  \n</p>\n<h4><span id=\"1.29_Stereo_Corresponding_Point_Based_Technique\"></span><span class=\"mw-headline\" id=\"1)_Stereo_Corresponding_Point_Based_Technique\">1) Stereo Corresponding Point Based Technique</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=3D_reconstruction_from_multiple_images&amp;action=edit&amp;section=15\" title=\"Edit section: 1) Stereo Corresponding Point Based Technique\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h4>\n<p>This method is simple and implemented by identifying the points manually in multi-view radiographs. The first step is to extract the corresponding points in two x-ray images and second step is the 3D reconstruction with algorithms like Discrete Linear Transform.<sup class=\"reference\" id=\"cite_ref-11\"><a href=\"#cite_note-11\">[11]</a></sup> Using DLT, the reconstruction is done only where there are SCPs. By increasing the number of points, the results improve <sup class=\"reference\" id=\"cite_ref-12\"><a href=\"#cite_note-12\">[12]</a></sup> but it is time consuming. This method has low accuracy because of low reproducibility and time consumption. This method is dependent on the skill of the operator. This method is not suitable for bony structures with continuous shape. This method is generally used as an initial solution for other methods.<sup class=\"reference\" id=\"cite_ref-:0_13-0\"><a href=\"#cite_note-:0-13\">[13]</a></sup>\n</p>\n<h4><span id=\"2.29_Non-Stereo_corresponding_contour_method_.28NCSS.29\"></span><span class=\"mw-headline\" id=\"2)_Non-Stereo_corresponding_contour_method_(NCSS)\">2) Non-Stereo corresponding contour method (NCSS)</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=3D_reconstruction_from_multiple_images&amp;action=edit&amp;section=16\" title=\"Edit section: 2) Non-Stereo corresponding contour method (NCSS)\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h4>\n<p>This method uses X-ray images for 3D Reconstruction and to develop 3D models with low dose radiations in weight bearing positions.\n</p><p>In NSCC algorithm, the preliminary step is calculation of an initial solution. Firstly anatomical regions from the generic object are defined. Secondly, manual 2D contours identification on the radiographs is performed. From each radiograph 2D contours are generated using the 3D initial solution object. 3D contours of the initial object surface are projected onto their associated radiograph.<sup class=\"reference\" id=\"cite_ref-:0_13-1\"><a href=\"#cite_note-:0-13\">[13]</a></sup> The 2D association performed between these 2 set points is based on point-to-point distances and contours derivations developing a correspondence between the 2D contours and the 3D contours. Next step is optimization of the initial solution. Lastly deformation of the optimized solution is done by applying Kriging algorithm to the optimized solution.<sup class=\"reference\" id=\"cite_ref-14\"><a href=\"#cite_note-14\">[14]</a></sup> Finally, by iterating the final step until the distance between two set points is superior to a given precision value the reconstructed object is obtained.\n</p><p>The advantage of this method is it can be used for bony structures with continuous shape and it also reduced human intervention but they are time consuming.\n</p>\n<h4><span id=\"3.29_Surface_Rendering_technique\"></span><span class=\"mw-headline\" id=\"3)_Surface_Rendering_technique\">3) Surface Rendering technique</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=3D_reconstruction_from_multiple_images&amp;action=edit&amp;section=17\" title=\"Edit section: 3) Surface Rendering technique\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h4>\n<p>Surface Rendering technique visualizes a 3D object as a set of surfaces called iso-surfaces. Each surface has points with the same intensity (called iso-value). It is used when we want to see the separated structures e.g. skull from slices of head, blood vessel system from slices of body etc. This technique is used mostly for high contrast data. Two main methods for reconstructing are:\n</p>\n<ul><li>Contour based reconstruction: Iso-contours are attached to form iso-surfaces<sup class=\"reference\" id=\"cite_ref-:1_15-0\"><a href=\"#cite_note-:1-15\">[15]</a></sup></li>\n<li>Voxel based reconstruction: Voxels having same intensity values are used to form iso-surfaces. One popular algorithm is Marching Cubes.<sup class=\"reference\" id=\"cite_ref-:1_15-1\"><a href=\"#cite_note-:1-15\">[15]</a></sup> Some similar algorithms as Marching Tetrahedrons, Dividing Cubes <sup class=\"reference\" id=\"cite_ref-:1_15-2\"><a href=\"#cite_note-:1-15\">[15]</a></sup> can be considered.</li></ul>\n<p>Other proposed or developed techniques include Statistical Shape Model Based Methods, Parametric Methods, Hybrid methods.\n</p>\n<h2><span class=\"mw-headline\" id=\"See_also\">See also</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=3D_reconstruction_from_multiple_images&amp;action=edit&amp;section=18\" title=\"Edit section: See also\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<ul><li><a href=\"/wiki/3D_pose_estimation\" title=\"3D pose estimation\">3D pose estimation</a></li>\n<li><a href=\"/wiki/3D_reconstruction\" title=\"3D reconstruction\">3D reconstruction</a></li>\n<li><a class=\"mw-redirect\" href=\"/wiki/3D_photography\" title=\"3D photography\">3D photography</a></li>\n<li><a href=\"/wiki/2D_to_3D_conversion\" title=\"2D to 3D conversion\">2D to 3D conversion</a></li>\n<li><a href=\"/wiki/3D_data_acquisition_and_object_reconstruction\" title=\"3D data acquisition and object reconstruction\">3D data acquisition and object reconstruction</a></li>\n<li><a href=\"/wiki/Epipolar_geometry\" title=\"Epipolar geometry\">Epipolar geometry</a></li>\n<li><a href=\"/wiki/Camera_resectioning\" title=\"Camera resectioning\">Camera resectioning</a></li>\n<li><a href=\"/wiki/Computer_stereo_vision\" title=\"Computer stereo vision\">Computer stereo vision</a></li>\n<li><a class=\"mw-redirect\" href=\"/wiki/Stereophotogrammetry\" title=\"Stereophotogrammetry\">Stereophotogrammetry</a></li>\n<li><a href=\"/wiki/Comparison_of_photogrammetry_software\" title=\"Comparison of photogrammetry software\">Comparison of photogrammetry software</a></li>\n<li><a href=\"/wiki/Visual_hull\" title=\"Visual hull\">Visual hull</a></li></ul>\n<h2><span class=\"mw-headline\" id=\"References\">References</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=3D_reconstruction_from_multiple_images&amp;action=edit&amp;section=19\" title=\"Edit section: References\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<div class=\"mw-references-wrap mw-references-columns\"><ol class=\"references\">\n<li id=\"cite_note-3DVAE-1\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-3DVAE_1-0\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation web\"><a class=\"external text\" href=\"https://github.com/Amir-Arsalan/Synthesize3DviaDepthOrSil\" rel=\"nofollow\">\"Soltani, A. A., Huang, H., Wu, J., Kulkarni, T. D., &amp; Tenenbaum, J. B. Synthesizing 3D Shapes via Modeling Multi-View Depth Maps and Silhouettes With Deep Generative Networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (pp. 1511-1519)\"</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Soltani%2C+A.+A.%2C+Huang%2C+H.%2C+Wu%2C+J.%2C+Kulkarni%2C+T.+D.%2C+%26+Tenenbaum%2C+J.+B.+Synthesizing+3D+Shapes+via+Modeling+Multi-View+Depth+Maps+and+Silhouettes+With+Deep+Generative+Networks.+In+Proceedings+of+the+IEEE+Conference+on+Computer+Vision+and+Pattern+Recognition+%28pp.+1511-1519%29.&amp;rft_id=https%3A%2F%2Fgithub.com%2FAmir-Arsalan%2FSynthesize3DviaDepthOrSil&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+reconstruction+from+multiple+images\"></span><style data-mw-deduplicate=\"TemplateStyles:r879151008\">.mw-parser-output cite.citation{font-style:inherit}.mw-parser-output .citation q{quotes:\"\\\"\"\"\\\"\"\"'\"\"'\"}.mw-parser-output .citation .cs1-lock-free a{background:url(\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png\")no-repeat;background-position:right .1em center}.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:url(\"//upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Lock-gray-alt-2.svg/9px-Lock-gray-alt-2.svg.png\")no-repeat;background-position:right .1em center}.mw-parser-output .citation .cs1-lock-subscription a{background:url(\"//upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Lock-red-alt-2.svg/9px-Lock-red-alt-2.svg.png\")no-repeat;background-position:right .1em center}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration{color:#555}.mw-parser-output .cs1-subscription span,.mw-parser-output .cs1-registration span{border-bottom:1px dotted;cursor:help}.mw-parser-output .cs1-ws-icon a{background:url(\"//upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Wikisource-logo.svg/12px-Wikisource-logo.svg.png\")no-repeat;background-position:right .1em center}.mw-parser-output code.cs1-code{color:inherit;background:inherit;border:inherit;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;font-size:100%}.mw-parser-output .cs1-visible-error{font-size:100%}.mw-parser-output .cs1-maint{display:none;color:#33aa33;margin-left:0.3em}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration,.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left,.mw-parser-output .cs1-kern-wl-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right,.mw-parser-output .cs1-kern-wl-right{padding-right:0.2em}</style></span>\n</li>\n<li id=\"cite_note-Tomasi-2\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-Tomasi_2-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-Tomasi_2-1\"><sup><i><b>b</b></i></sup></a></span> <span class=\"reference-text\">C. Tomasi and T. Kanade, “<a class=\"external text\" href=\"http://repository.cmu.edu/cgi/viewcontent.cgi?article=3040&amp;context=compsci\" rel=\"nofollow\">Shape and motion from image streams under orthography: A factorization approach</a>”, International Journal of Computer Vision, 9(2):137-154, 1992.</span>\n</li>\n<li id=\"cite_note-LaurentiniVisualHull-3\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-LaurentiniVisualHull_3-0\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation web\">A. Laurentini (February 1994). <a class=\"external text\" href=\"http://portal.acm.org/citation.cfm?coll=GUIDE&amp;dl=GUIDE&amp;id=628563\" rel=\"nofollow\">\"The visual hull concept for silhouette-based image understanding\"</a>. <i>IEEE Trans. Pattern Analysis and Machine Intelligence</i>. pp. 150–162.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=IEEE+Trans.+Pattern+Analysis+and+Machine+Intelligence.&amp;rft.atitle=The+visual+hull+concept+for+silhouette-based+image+understanding&amp;rft.pages=150-162&amp;rft.date=1994-02&amp;rft.au=A.+Laurentini&amp;rft_id=http%3A%2F%2Fportal.acm.org%2Fcitation.cfm%3Fcoll%3DGUIDE%26dl%3DGUIDE%26id%3D628563&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+reconstruction+from+multiple+images\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></span>\n</li>\n<li id=\"cite_note-4\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-4\">^</a></b></span> <span class=\"reference-text\">R. Mohr and E. Arbogast. \nIt can be done without camera calibration. \nPattern Recognition Letters, 12:39-43, 1991.</span>\n</li>\n<li id=\"cite_note-5\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-5\">^</a></b></span> <span class=\"reference-text\">O. Faugeras. \n<a class=\"external text\" href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.462.4708&amp;rep=rep1&amp;type=pdf\" rel=\"nofollow\">What can be seen in three dimensions with an uncalibrated stereo rig?</a> \nIn Proceedings of the European Conference on Computer Vision, pages 563-578, Santa Margherita L., 1992.</span>\n</li>\n<li id=\"cite_note-6\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-6\">^</a></b></span> <span class=\"reference-text\">E. Kruppa. Zur Ermittlung eines Objektes aus zwei Perspektiven mit innerer Orientierung. Sitz.-Ber.Akad.Wiss., Wien, math. naturw. Kl., Abt. IIa., 122:1939-1948, 1913.</span>\n</li>\n<li id=\"cite_note-7\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-7\">^</a></b></span> <span class=\"reference-text\">S. J. Maybank and O. Faugeras. A theory of self-calibration of a moving camera. International Journal of Computer Vision, 8(2):123-151, 1992.</span>\n</li>\n<li id=\"cite_note-8\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-8\">^</a></b></span> <span class=\"reference-text\">O. Faugeras and S. Maybank. <a class=\"external text\" href=\"https://hal.inria.fr/docs/00/07/54/01/PDF/RR-1157.pdf\" rel=\"nofollow\">Motion from point matches: multiplicity of solutions</a>. International Journal of Computer Vision, 4(3):225-246, June 1990.</span>\n</li>\n<li id=\"cite_note-Hartley-9\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-Hartley_9-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-Hartley_9-1\"><sup><i><b>b</b></i></sup></a></span> <span class=\"reference-text\">R. I. Hartley. <a class=\"external text\" href=\"http://users.rsise.anu.edu.au/hartley/public_html/Papers/kruppa/final-version/kruppa2.pdf\" rel=\"nofollow\">Kruppa's equations derived from the fundamental matrix</a>. \nIEEE Transactions on Pattern Analysis and Machine Intelligence, 19(2):133-135, February 1997.</span>\n</li>\n<li id=\"cite_note-10\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-10\">^</a></b></span> <span class=\"reference-text\">R. Hartley and A. Zisserman. Multiple view geometry in computer vision. Cambridge University Press, 2nd edition, 2003.</span>\n</li>\n<li id=\"cite_note-11\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-11\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation web\"><a class=\"external text\" href=\"https://www.researchgate.net/profile/Mark_Pearcy/publication/19301926_Stereo_radiography_of_lumbar_spine_motion/links/543b04fb0cf204cab1daf4ee.pdf\" rel=\"nofollow\">\"Pearcy MJ. 1985. Stereo radiography of lumbar spine motion. Acta Orthop Scand Suppl\"</a> <span class=\"cs1-format\">(PDF)</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Pearcy+MJ.+1985.+Stereo+radiography+of+lumbar+spine+motion.+Acta+Orthop+Scand+Suppl&amp;rft_id=https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FMark_Pearcy%2Fpublication%2F19301926_Stereo_radiography_of_lumbar_spine_motion%2Flinks%2F543b04fb0cf204cab1daf4ee.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+reconstruction+from+multiple+images\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></span>\n</li>\n<li id=\"cite_note-12\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-12\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">\"Aubin CE, Dansereau J, Parent F, Labelle H, de Guise JA. 1997. Morphometric evaluations of personalised 3D reconstructions and geometric models of the human spine\". <i>Med Biol Eng Comput</i>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Med+Biol+Eng+Comput&amp;rft.atitle=Aubin+CE%2C+Dansereau+J%2C+Parent+F%2C+Labelle+H%2C+de+Guise+JA.+1997.+Morphometric+evaluations+of+personalised+3D+reconstructions+and+geometric+models+of+the+human+spine&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+reconstruction+from+multiple+images\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></span>\n</li>\n<li id=\"cite_note-:0-13\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-:0_13-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-:0_13-1\"><sup><i><b>b</b></i></sup></a></span> <span class=\"reference-text\"><cite class=\"citation web\"><a class=\"external text\" href=\"http://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XL-1-W5/319/2015/isprsarchives-XL-1-W5-319-2015.pdf\" rel=\"nofollow\">\"S.Hosseinian, H.Arefi, 3D Reconstruction from multiview medical X-ray images- Review and evaluation of existing methods\"</a> <span class=\"cs1-format\">(PDF)</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=S.Hosseinian%2C+H.Arefi%2C+3D+Reconstruction+from+multiview+medical+X-ray+images-+Review+and+evaluation+of+existing+methods.&amp;rft_id=http%3A%2F%2Fwww.int-arch-photogramm-remote-sens-spatial-inf-sci.net%2FXL-1-W5%2F319%2F2015%2Fisprsarchives-XL-1-W5-319-2015.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+reconstruction+from+multiple+images\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></span>\n</li>\n<li id=\"cite_note-14\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-14\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Laporte, S; Skalli, W; de Guise, JA; Lavaste, F; Mitton, D (2003). <a class=\"external text\" href=\"https://www.researchgate.net/profile/Sebastien_Laporte2/publication/10868711_A_Biplanar_Reconstruction_Method_Based_on_2D_and_3D_Contours_Application_to_the_Distal_Femur/links/0912f50dc38102144b000000.pdf\" rel=\"nofollow\">\"A biplanar reconstruction method based on 2D and 3D contours: application to distal femur\"</a> <span class=\"cs1-format\">(PDF)</span>. <i>Comput Methods Biomech Biomed Engin</i>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Comput+Methods+Biomech+Biomed+Engin&amp;rft.atitle=A+biplanar+reconstruction+method+based+on+2D+and+3D+contours%3A+application+to+distal+femur&amp;rft.date=2003&amp;rft.aulast=Laporte&amp;rft.aufirst=S&amp;rft.au=Skalli%2C+W&amp;rft.au=de+Guise%2C+JA&amp;rft.au=Lavaste%2C+F&amp;rft.au=Mitton%2C+D&amp;rft_id=https%3A%2F%2Fwww.researchgate.net%2Fprofile%2FSebastien_Laporte2%2Fpublication%2F10868711_A_Biplanar_Reconstruction_Method_Based_on_2D_and_3D_Contours_Application_to_the_Distal_Femur%2Flinks%2F0912f50dc38102144b000000.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+reconstruction+from+multiple+images\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></span>\n</li>\n<li id=\"cite_note-:1-15\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-:1_15-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-:1_15-1\"><sup><i><b>b</b></i></sup></a> <a href=\"#cite_ref-:1_15-2\"><sup><i><b>c</b></i></sup></a></span> <span class=\"reference-text\"><cite class=\"citation book\"><i>G.Scott Owen, HyperVis. ACM SIGGRAPH Education Committee, the National Science Foundation (DUE-9752398), and the Hypermedia and Visualization Laboratory, Georgia State University</i>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=G.Scott+Owen%2C+HyperVis.+ACM+SIGGRAPH+Education+Committee%2C+the+National+Science+Foundation+%28DUE-9752398%29%2C+and+the+Hypermedia+and+Visualization+Laboratory%2C+Georgia+State+University.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+reconstruction+from+multiple+images\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></span>\n</li>\n</ol></div>\n<h2><span class=\"mw-headline\" id=\"Further_reading\">Further reading</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=3D_reconstruction_from_multiple_images&amp;action=edit&amp;section=20\" title=\"Edit section: Further reading\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<ul><li>Yasutaka Furukawa and Carlos Hernández (2015) <i>Multi-View Stereo: A Tutorial</i> <a class=\"external autonumber\" href=\"http://carlos-hernandez.org/papers/fnt_mvs_2015.pdf\" rel=\"nofollow\">[1]</a></li>\n<li>Flynn, John, et al. \"<a class=\"external text\" href=\"https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Flynn_DeepStereo_Learning_to_CVPR_2016_paper.pdf\" rel=\"nofollow\">Deepstereo: Learning to predict new views from the world's imagery</a>.\" Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2016.</li></ul>\n<h2><span class=\"mw-headline\" id=\"External_links\">External links</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=3D_reconstruction_from_multiple_images&amp;action=edit&amp;section=21\" title=\"Edit section: External links\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<table class=\"mbox-small plainlinks sistersitebox\" role=\"presentation\" style=\"background-color:#f9f9f9;border:1px solid #aaa;color:#000\">\n<tbody><tr>\n<td class=\"mbox-image\"><img alt=\"\" class=\"noviewer\" data-file-height=\"512\" data-file-width=\"512\" decoding=\"async\" height=\"40\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/9/99/Wiktionary-logo-en-v2.svg/40px-Wiktionary-logo-en-v2.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/9/99/Wiktionary-logo-en-v2.svg/60px-Wiktionary-logo-en-v2.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/9/99/Wiktionary-logo-en-v2.svg/80px-Wiktionary-logo-en-v2.svg.png 2x\" width=\"40\"/></td>\n<td class=\"mbox-text plainlist\">Look up <i><b><a class=\"extiw\" href=\"https://en.wiktionary.org/wiki/Special:Search/3d_reconstruction_from_multiple_images\" title=\"wiktionary:Special:Search/3d reconstruction from multiple images\">3d reconstruction from multiple images</a></b></i> in Wiktionary, the free dictionary.</td></tr></tbody></table>\n<ul><li><a class=\"external text\" href=\"http://dl.acm.org/citation.cfm?id=1754449&amp;preflayout=tabs\" rel=\"nofollow\">3D Reconstruction from Multiple Images</a> - discusses methods to extract 3D models from plain images.</li>\n<li><a class=\"external text\" href=\"http://sites.google.com/site/leeplus/bmvs\" rel=\"nofollow\">Visual 3D Modeling from Images and Videos</a> - a tech-report describes the theory, practice and tricks on 3D reconstruction from images and videos.</li>\n<li><a class=\"external text\" href=\"https://github.com/Amir-Arsalan/Synthesize3DviaDepthOrSil\" rel=\"nofollow\">Synthesizing 3D Shapes via Modeling Multi-View Depth Maps and Silhouettes with Deep Generative Networks</a> - Generate and reconstruct 3D shapes via modeling multi-view depth maps or silhouettes.</li></ul>\n<!-- \nNewPP limit report\nParsed by mw1276\nCached time: 20190225074809\nCache expiry: 2073600\nDynamic content: false\nCPU time usage: 0.296 seconds\nReal time usage: 0.545 seconds\nPreprocessor visited node count: 1021/1000000\nPreprocessor generated node count: 0/1500000\nPost‐expand include size: 23950/2097152 bytes\nTemplate argument size: 2308/2097152 bytes\nHighest expansion depth: 15/40\nExpensive parser function count: 4/500\nUnstrip recursion depth: 1/20\nUnstrip post‐expand size: 27032/5000000 bytes\nNumber of Wikibase entities loaded: 0/400\nLua time usage: 0.116/10.000 seconds\nLua memory usage: 2.89 MB/50 MB\n-->\n<!--\nTransclusion expansion time report (%,ms,calls,template)\n100.00%  270.469      1 -total\n 38.09%  103.028      1 Template:Cleanup\n 36.85%   99.664      4 Template:Cite_web\n 18.75%   50.725      1 Template:Main_other\n 17.47%   47.259      1 Template:Ambox\n  9.91%   26.803      1 Template:Category_handler\n  6.41%   17.347      2 Template:Cite_journal\n  5.89%   15.934      1 Template:DMC\n  5.48%   14.818      1 Template:Wiktionary\n  3.88%   10.500      2 Template:FULLROOTPAGENAME\n-->\n<!-- Saved in parser cache with key enwiki:pcache:idhash:34668189-0!canonical!math=5 and timestamp 20190225074808 and revision id 884992410\n -->\n</div><noscript><img alt=\"\" height=\"1\" src=\"//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1\" style=\"border: none; position: absolute;\" title=\"\" width=\"1\"/></noscript></div> <div class=\"printfooter\">\n\t\t\t\t\t\tRetrieved from \"<a dir=\"ltr\" href=\"https://en.wikipedia.org/w/index.php?title=3D_reconstruction_from_multiple_images&amp;oldid=884992410\">https://en.wikipedia.org/w/index.php?title=3D_reconstruction_from_multiple_images&amp;oldid=884992410</a>\"\t\t\t\t\t</div>\n<div class=\"catlinks\" data-mw=\"interface\" id=\"catlinks\"><div class=\"mw-normal-catlinks\" id=\"mw-normal-catlinks\"><a href=\"/wiki/Help:Category\" title=\"Help:Category\">Categories</a>: <ul><li><a href=\"/wiki/Category:Computer_vision\" title=\"Category:Computer vision\">Computer vision</a></li><li><a href=\"/wiki/Category:Applications_of_computer_vision\" title=\"Category:Applications of computer vision\">Applications of computer vision</a></li><li><a href=\"/wiki/Category:Image_processing\" title=\"Category:Image processing\">Image processing</a></li><li><a href=\"/wiki/Category:Artificial_intelligence\" title=\"Category:Artificial intelligence\">Artificial intelligence</a></li><li><a href=\"/wiki/Category:Stereophotogrammetry\" title=\"Category:Stereophotogrammetry\">Stereophotogrammetry</a></li><li><a href=\"/wiki/Category:3D_imaging\" title=\"Category:3D imaging\">3D imaging</a></li></ul></div><div class=\"mw-hidden-catlinks mw-hidden-cats-hidden\" id=\"mw-hidden-catlinks\">Hidden categories: <ul><li><a href=\"/wiki/Category:Articles_needing_cleanup_from_February_2019\" title=\"Category:Articles needing cleanup from February 2019\">Articles needing cleanup from February 2019</a></li><li><a href=\"/wiki/Category:All_pages_needing_cleanup\" title=\"Category:All pages needing cleanup\">All pages needing cleanup</a></li><li><a href=\"/wiki/Category:Cleanup_tagged_articles_with_a_reason_field_from_February_2019\" title=\"Category:Cleanup tagged articles with a reason field from February 2019\">Cleanup tagged articles with a reason field from February 2019</a></li><li><a href=\"/wiki/Category:Wikipedia_pages_needing_cleanup_from_February_2019\" title=\"Category:Wikipedia pages needing cleanup from February 2019\">Wikipedia pages needing cleanup from February 2019</a></li></ul></div></div> <div class=\"visualClear\"></div>\n</div>\n</div>\n<div id=\"mw-navigation\">\n<h2>Navigation menu</h2>\n<div id=\"mw-head\">\n<div aria-labelledby=\"p-personal-label\" id=\"p-personal\" role=\"navigation\">\n<h3 id=\"p-personal-label\">Personal tools</h3>\n<ul>\n<li id=\"pt-anonuserpage\">Not logged in</li><li id=\"pt-anontalk\"><a accesskey=\"n\" href=\"/wiki/Special:MyTalk\" title=\"Discussion about edits from this IP address [n]\">Talk</a></li><li id=\"pt-anoncontribs\"><a accesskey=\"y\" href=\"/wiki/Special:MyContributions\" title=\"A list of edits made from this IP address [y]\">Contributions</a></li><li id=\"pt-createaccount\"><a href=\"/w/index.php?title=Special:CreateAccount&amp;returnto=3D+reconstruction+from+multiple+images\" title=\"You are encouraged to create an account and log in; however, it is not mandatory\">Create account</a></li><li id=\"pt-login\"><a accesskey=\"o\" href=\"/w/index.php?title=Special:UserLogin&amp;returnto=3D+reconstruction+from+multiple+images\" title=\"You're encouraged to log in; however, it's not mandatory. [o]\">Log in</a></li> </ul>\n</div>\n<div id=\"left-navigation\">\n<div aria-labelledby=\"p-namespaces-label\" class=\"vectorTabs\" id=\"p-namespaces\" role=\"navigation\">\n<h3 id=\"p-namespaces-label\">Namespaces</h3>\n<ul>\n<li class=\"selected\" id=\"ca-nstab-main\"><span><a accesskey=\"c\" href=\"/wiki/3D_reconstruction_from_multiple_images\" title=\"View the content page [c]\">Article</a></span></li><li id=\"ca-talk\"><span><a accesskey=\"t\" href=\"/wiki/Talk:3D_reconstruction_from_multiple_images\" rel=\"discussion\" title=\"Discussion about the content page [t]\">Talk</a></span></li> </ul>\n</div>\n<div aria-labelledby=\"p-variants-label\" class=\"vectorMenu emptyPortlet\" id=\"p-variants\" role=\"navigation\">\n<input aria-labelledby=\"p-variants-label\" class=\"vectorMenuCheckbox\" type=\"checkbox\"/>\n<h3 id=\"p-variants-label\">\n<span>Variants</span>\n</h3>\n<ul class=\"menu\">\n</ul>\n</div>\n</div>\n<div id=\"right-navigation\">\n<div aria-labelledby=\"p-views-label\" class=\"vectorTabs\" id=\"p-views\" role=\"navigation\">\n<h3 id=\"p-views-label\">Views</h3>\n<ul>\n<li class=\"collapsible selected\" id=\"ca-view\"><span><a href=\"/wiki/3D_reconstruction_from_multiple_images\">Read</a></span></li><li class=\"collapsible\" id=\"ca-edit\"><span><a accesskey=\"e\" href=\"/w/index.php?title=3D_reconstruction_from_multiple_images&amp;action=edit\" title=\"Edit this page [e]\">Edit</a></span></li><li class=\"collapsible\" id=\"ca-history\"><span><a accesskey=\"h\" href=\"/w/index.php?title=3D_reconstruction_from_multiple_images&amp;action=history\" title=\"Past revisions of this page [h]\">View history</a></span></li> </ul>\n</div>\n<div aria-labelledby=\"p-cactions-label\" class=\"vectorMenu emptyPortlet\" id=\"p-cactions\" role=\"navigation\">\n<input aria-labelledby=\"p-cactions-label\" class=\"vectorMenuCheckbox\" type=\"checkbox\"/>\n<h3 id=\"p-cactions-label\"><span>More</span></h3>\n<ul class=\"menu\">\n</ul>\n</div>\n<div id=\"p-search\" role=\"search\">\n<h3>\n<label for=\"searchInput\">Search</label>\n</h3>\n<form action=\"/w/index.php\" id=\"searchform\">\n<div id=\"simpleSearch\">\n<input accesskey=\"f\" id=\"searchInput\" name=\"search\" placeholder=\"Search Wikipedia\" title=\"Search Wikipedia [f]\" type=\"search\"/><input name=\"title\" type=\"hidden\" value=\"Special:Search\"/><input class=\"searchButton mw-fallbackSearchButton\" id=\"mw-searchButton\" name=\"fulltext\" title=\"Search Wikipedia for this text\" type=\"submit\" value=\"Search\"/><input class=\"searchButton\" id=\"searchButton\" name=\"go\" title=\"Go to a page with this exact name if it exists\" type=\"submit\" value=\"Go\"/> </div>\n</form>\n</div>\n</div>\n</div>\n<div id=\"mw-panel\">\n<div id=\"p-logo\" role=\"banner\"><a class=\"mw-wiki-logo\" href=\"/wiki/Main_Page\" title=\"Visit the main page\"></a></div>\n<div aria-labelledby=\"p-navigation-label\" class=\"portal\" id=\"p-navigation\" role=\"navigation\">\n<h3 id=\"p-navigation-label\">Navigation</h3>\n<div class=\"body\">\n<ul>\n<li id=\"n-mainpage-description\"><a accesskey=\"z\" href=\"/wiki/Main_Page\" title=\"Visit the main page [z]\">Main page</a></li><li id=\"n-contents\"><a href=\"/wiki/Portal:Contents\" title=\"Guides to browsing Wikipedia\">Contents</a></li><li id=\"n-featuredcontent\"><a href=\"/wiki/Portal:Featured_content\" title=\"Featured content – the best of Wikipedia\">Featured content</a></li><li id=\"n-currentevents\"><a href=\"/wiki/Portal:Current_events\" title=\"Find background information on current events\">Current events</a></li><li id=\"n-randompage\"><a accesskey=\"x\" href=\"/wiki/Special:Random\" title=\"Load a random article [x]\">Random article</a></li><li id=\"n-sitesupport\"><a href=\"https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_en.wikipedia.org&amp;uselang=en\" title=\"Support us\">Donate to Wikipedia</a></li><li id=\"n-shoplink\"><a href=\"//shop.wikimedia.org\" title=\"Visit the Wikipedia store\">Wikipedia store</a></li> </ul>\n</div>\n</div>\n<div aria-labelledby=\"p-interaction-label\" class=\"portal\" id=\"p-interaction\" role=\"navigation\">\n<h3 id=\"p-interaction-label\">Interaction</h3>\n<div class=\"body\">\n<ul>\n<li id=\"n-help\"><a href=\"/wiki/Help:Contents\" title=\"Guidance on how to use and edit Wikipedia\">Help</a></li><li id=\"n-aboutsite\"><a href=\"/wiki/Wikipedia:About\" title=\"Find out about Wikipedia\">About Wikipedia</a></li><li id=\"n-portal\"><a href=\"/wiki/Wikipedia:Community_portal\" title=\"About the project, what you can do, where to find things\">Community portal</a></li><li id=\"n-recentchanges\"><a accesskey=\"r\" href=\"/wiki/Special:RecentChanges\" title=\"A list of recent changes in the wiki [r]\">Recent changes</a></li><li id=\"n-contactpage\"><a href=\"//en.wikipedia.org/wiki/Wikipedia:Contact_us\" title=\"How to contact Wikipedia\">Contact page</a></li> </ul>\n</div>\n</div>\n<div aria-labelledby=\"p-tb-label\" class=\"portal\" id=\"p-tb\" role=\"navigation\">\n<h3 id=\"p-tb-label\">Tools</h3>\n<div class=\"body\">\n<ul>\n<li id=\"t-whatlinkshere\"><a accesskey=\"j\" href=\"/wiki/Special:WhatLinksHere/3D_reconstruction_from_multiple_images\" title=\"List of all English Wikipedia pages containing links to this page [j]\">What links here</a></li><li id=\"t-recentchangeslinked\"><a accesskey=\"k\" href=\"/wiki/Special:RecentChangesLinked/3D_reconstruction_from_multiple_images\" rel=\"nofollow\" title=\"Recent changes in pages linked from this page [k]\">Related changes</a></li><li id=\"t-upload\"><a accesskey=\"u\" href=\"/wiki/Wikipedia:File_Upload_Wizard\" title=\"Upload files [u]\">Upload file</a></li><li id=\"t-specialpages\"><a accesskey=\"q\" href=\"/wiki/Special:SpecialPages\" title=\"A list of all special pages [q]\">Special pages</a></li><li id=\"t-permalink\"><a href=\"/w/index.php?title=3D_reconstruction_from_multiple_images&amp;oldid=884992410\" title=\"Permanent link to this revision of the page\">Permanent link</a></li><li id=\"t-info\"><a href=\"/w/index.php?title=3D_reconstruction_from_multiple_images&amp;action=info\" title=\"More information about this page\">Page information</a></li><li id=\"t-wikibase\"><a accesskey=\"g\" href=\"https://www.wikidata.org/wiki/Special:EntityPage/Q3422083\" title=\"Link to connected data repository item [g]\">Wikidata item</a></li><li id=\"t-cite\"><a href=\"/w/index.php?title=Special:CiteThisPage&amp;page=3D_reconstruction_from_multiple_images&amp;id=884992410\" title=\"Information on how to cite this page\">Cite this page</a></li> </ul>\n</div>\n</div>\n<div aria-labelledby=\"p-coll-print_export-label\" class=\"portal\" id=\"p-coll-print_export\" role=\"navigation\">\n<h3 id=\"p-coll-print_export-label\">Print/export</h3>\n<div class=\"body\">\n<ul>\n<li id=\"coll-create_a_book\"><a href=\"/w/index.php?title=Special:Book&amp;bookcmd=book_creator&amp;referer=3D+reconstruction+from+multiple+images\">Create a book</a></li><li id=\"coll-download-as-rdf2latex\"><a href=\"/w/index.php?title=Special:ElectronPdf&amp;page=3D+reconstruction+from+multiple+images&amp;action=show-download-screen\">Download as PDF</a></li><li id=\"t-print\"><a accesskey=\"p\" href=\"/w/index.php?title=3D_reconstruction_from_multiple_images&amp;printable=yes\" title=\"Printable version of this page [p]\">Printable version</a></li> </ul>\n</div>\n</div>\n<div aria-labelledby=\"p-lang-label\" class=\"portal\" id=\"p-lang\" role=\"navigation\">\n<h3 id=\"p-lang-label\">Languages</h3>\n<div class=\"body\">\n<ul>\n<li class=\"interlanguage-link interwiki-ar\"><a class=\"interlanguage-link-target\" href=\"https://ar.wikipedia.org/wiki/%D8%A8%D9%86%D8%A7%D8%A1_%D9%86%D9%85%D9%88%D8%B0%D8%AC_%D8%AB%D9%84%D8%A7%D8%AB%D9%8A_%D8%A7%D9%84%D8%A3%D8%A8%D8%B9%D8%A7%D8%AF_%D9%85%D9%86_%D8%B9%D8%AF%D8%A9_%D8%B5%D9%88%D8%B1\" hreflang=\"ar\" lang=\"ar\" title=\"بناء نموذج ثلاثي الأبعاد من عدة صور – Arabic\">العربية</a></li><li class=\"interlanguage-link interwiki-fr\"><a class=\"interlanguage-link-target\" href=\"https://fr.wikipedia.org/wiki/Reconstruction_3D_%C3%A0_partir_d%27images\" hreflang=\"fr\" lang=\"fr\" title=\"Reconstruction 3D à partir d'images – French\">Français</a></li> </ul>\n<div class=\"after-portlet after-portlet-lang\"><span class=\"wb-langlinks-edit wb-langlinks-link\"><a class=\"wbc-editpage\" href=\"https://www.wikidata.org/wiki/Special:EntityPage/Q3422083#sitelinks-wikipedia\" title=\"Edit interlanguage links\">Edit links</a></span></div> </div>\n</div>\n</div>\n</div>\n<div id=\"footer\" role=\"contentinfo\">\n<ul id=\"footer-info\">\n<li id=\"footer-info-lastmod\"> This page was last edited on 25 February 2019, at 07:48<span class=\"anonymous-show\"> (UTC)</span>.</li>\n<li id=\"footer-info-copyright\">Text is available under the <a href=\"//en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License\" rel=\"license\">Creative Commons Attribution-ShareAlike License</a><a href=\"//creativecommons.org/licenses/by-sa/3.0/\" rel=\"license\" style=\"display:none;\"></a>;\nadditional terms may apply.  By using this site, you agree to the <a href=\"//foundation.wikimedia.org/wiki/Terms_of_Use\">Terms of Use</a> and <a href=\"//foundation.wikimedia.org/wiki/Privacy_policy\">Privacy Policy</a>. Wikipedia® is a registered trademark of the <a href=\"//www.wikimediafoundation.org/\">Wikimedia Foundation, Inc.</a>, a non-profit organization.</li>\n</ul>\n<ul id=\"footer-places\">\n<li id=\"footer-places-privacy\"><a class=\"extiw\" href=\"https://foundation.wikimedia.org/wiki/Privacy_policy\" title=\"wmf:Privacy policy\">Privacy policy</a></li>\n<li id=\"footer-places-about\"><a href=\"/wiki/Wikipedia:About\" title=\"Wikipedia:About\">About Wikipedia</a></li>\n<li id=\"footer-places-disclaimer\"><a href=\"/wiki/Wikipedia:General_disclaimer\" title=\"Wikipedia:General disclaimer\">Disclaimers</a></li>\n<li id=\"footer-places-contact\"><a href=\"//en.wikipedia.org/wiki/Wikipedia:Contact_us\">Contact Wikipedia</a></li>\n<li id=\"footer-places-developers\"><a href=\"https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute\">Developers</a></li>\n<li id=\"footer-places-cookiestatement\"><a href=\"https://foundation.wikimedia.org/wiki/Cookie_statement\">Cookie statement</a></li>\n<li id=\"footer-places-mobileview\"><a class=\"noprint stopMobileRedirectToggle\" href=\"//en.m.wikipedia.org/w/index.php?title=3D_reconstruction_from_multiple_images&amp;mobileaction=toggle_view_mobile\">Mobile view</a></li>\n</ul>\n<ul class=\"noprint\" id=\"footer-icons\">\n<li id=\"footer-copyrightico\">\n<a href=\"https://wikimediafoundation.org/\"><img alt=\"Wikimedia Foundation\" height=\"31\" src=\"/static/images/wikimedia-button.png\" srcset=\"/static/images/wikimedia-button-1.5x.png 1.5x, /static/images/wikimedia-button-2x.png 2x\" width=\"88\"/></a> </li>\n<li id=\"footer-poweredbyico\">\n<a href=\"//www.mediawiki.org/\"><img alt=\"Powered by MediaWiki\" height=\"31\" src=\"/static/images/poweredby_mediawiki_88x31.png\" srcset=\"/static/images/poweredby_mediawiki_132x47.png 1.5x, /static/images/poweredby_mediawiki_176x62.png 2x\" width=\"88\"/></a> </li>\n</ul>\n<div style=\"clear: both;\"></div>\n</div>\n<script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({\"wgPageParseReport\":{\"limitreport\":{\"cputime\":\"0.296\",\"walltime\":\"0.545\",\"ppvisitednodes\":{\"value\":1021,\"limit\":1000000},\"ppgeneratednodes\":{\"value\":0,\"limit\":1500000},\"postexpandincludesize\":{\"value\":23950,\"limit\":2097152},\"templateargumentsize\":{\"value\":2308,\"limit\":2097152},\"expansiondepth\":{\"value\":15,\"limit\":40},\"expensivefunctioncount\":{\"value\":4,\"limit\":500},\"unstrip-depth\":{\"value\":1,\"limit\":20},\"unstrip-size\":{\"value\":27032,\"limit\":5000000},\"entityaccesscount\":{\"value\":0,\"limit\":400},\"timingprofile\":[\"100.00%  270.469      1 -total\",\" 38.09%  103.028      1 Template:Cleanup\",\" 36.85%   99.664      4 Template:Cite_web\",\" 18.75%   50.725      1 Template:Main_other\",\" 17.47%   47.259      1 Template:Ambox\",\"  9.91%   26.803      1 Template:Category_handler\",\"  6.41%   17.347      2 Template:Cite_journal\",\"  5.89%   15.934      1 Template:DMC\",\"  5.48%   14.818      1 Template:Wiktionary\",\"  3.88%   10.500      2 Template:FULLROOTPAGENAME\"]},\"scribunto\":{\"limitreport-timeusage\":{\"value\":\"0.116\",\"limit\":\"10.000\"},\"limitreport-memusage\":{\"value\":3031388,\"limit\":52428800}},\"cachereport\":{\"origin\":\"mw1276\",\"timestamp\":\"20190225074809\",\"ttl\":2073600,\"transientcontent\":false}}});});</script>\n<script type=\"application/ld+json\">{\"@context\":\"https:\\/\\/schema.org\",\"@type\":\"Article\",\"name\":\"3D reconstruction from multiple images\",\"url\":\"https:\\/\\/en.wikipedia.org\\/wiki\\/3D_reconstruction_from_multiple_images\",\"sameAs\":\"http:\\/\\/www.wikidata.org\\/entity\\/Q3422083\",\"mainEntity\":\"http:\\/\\/www.wikidata.org\\/entity\\/Q3422083\",\"author\":{\"@type\":\"Organization\",\"name\":\"Contributors to Wikimedia projects\"},\"publisher\":{\"@type\":\"Organization\",\"name\":\"Wikimedia Foundation, Inc.\",\"logo\":{\"@type\":\"ImageObject\",\"url\":\"https:\\/\\/www.wikimedia.org\\/static\\/images\\/wmf-hor-googpub.png\"}},\"datePublished\":\"2012-02-09T16:18:42Z\",\"dateModified\":\"2019-02-25T07:48:08Z\",\"image\":\"https:\\/\\/upload.wikimedia.org\\/wikipedia\\/commons\\/5\\/51\\/Fantasitron_photo_booth_at_Madurodam_can_scan_up_to_two_people_at_a_time_IMG_3797_FRD.jpg\"}</script>\n<script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({\"wgBackendResponseTime\":105,\"wgHostname\":\"mw1248\"});});</script>\n</body>\n</html>\n",
  "table_of_contents": [
    "1 Processing",
    "2 Mathematical description of reconstruction",
    "3 Autocalibration",
    "3.1 Kruppa equations",
    "3.2 Mendonça and Cipolla",
    "4 Stratification",
    "4.1 The stratification of 3D geometry",
    "4.2 Projective reconstruction",
    "4.3 Affine reconstruction",
    "4.4 Euclidean reconstruction",
    "5 Algebraic vs geometric error",
    "6 3D reconstruction of Medical Images",
    "6.1 Motivation & applications",
    "6.2 Problem statement & Basics",
    "6.2.1 1) Stereo Corresponding Point Based Technique",
    "6.2.2 2) Non-Stereo corresponding contour method (NCSS)",
    "6.2.3 3) Surface Rendering technique",
    "7 See also",
    "8 References",
    "9 Further reading",
    "10 External links"
  ],
  "graphics": [
    {
      "url": "/wiki/File:Madurodam_Shapeways_3D_selfie_in_1_20_scale_after_a_second_spray_of_varnish_FRD.jpg",
      "caption": "A 3D selfie in 1:20 scale printed by Shapeways using gypsum-based printing, created by Madurodam miniature park from 2D pictures taken at its Fantasitron photo booth."
    },
    {
      "url": "/wiki/File:Fantasitron_photo_booth_at_Madurodam_can_scan_up_to_two_people_at_a_time_IMG_3797_FRD.jpg",
      "caption": "3D models are generated from 2D pictures taken at the Fantasitron 3D photo booth at Madurodam"
    },
    {
      "url": "/wiki/File:Synthesizing_3D_Shapes_via_Modeling_Multi-View_Depth_Maps_and_Silhouettes_With_Deep_Generative_Networks.png",
      "caption": "Generating and reconstructing 3D shapes from single or multi-view depth maps or silhouettes [1]"
    },
    {
      "url": "/wiki/File:SilhouetteCones.jpg",
      "caption": "A visual hull can be reconstructed from multiple silhouettes of an object.[3]"
    },
    {
      "url": "/wiki/File:Epipolar_Geometry1.svg",
      "caption": "Projection of P on both cameras"
    }
  ],
  "paragraphs": [
    {
      "title": "",
      "text": "3D reconstruction from multiple images is the creation of three-dimensional models from a set of images. It is the reverse process of obtaining 2D images from 3D scenes.\n\nThe essence of an image is a projection from a 3D scene onto a 2D plane, during which process the depth is lost. The 3D point corresponding to a specific image point is constrained to be on the line of sight. From a single image, it is impossible to determine which point on this line corresponds to the image point. If two images are available, then the position of a 3D point can be found as the intersection of the two projection rays. This process is referred to as triangulation. The key for this process is the relations between multiple views which convey the information that corresponding sets of points must contain some structure and that this structure is related to the poses and the calibration of the camera.\n\nIn recent decades, there is an important demand for 3D content for computer graphics, virtual reality and communication, triggering a change in emphasis for the requirements. Many existing systems for constructing 3D models are built around specialized hardware (e.g. stereo rigs) resulting in a high cost, which cannot satisfy the requirement of its new applications. This gap stimulates the use of digital imaging facilities (like a camera). Moore's law also tells us that more work can be done in software. An early method was proposed by Tomasi and Kanade.[2] They used an affine factorization approach to extract 3D from images sequences. However, the assumption of orthographic projection is a significant limitation of this system.\n\n"
    },
    {
      "title": "Processing",
      "text": "The task of converting multiple 2D images into 3D model consists of a series of processing steps:\n\nCamera calibration consists of intrinsic and extrinsic parameters, without which at some level no arrangement of algorithms can work. The dotted line between Calibration and Depth determination represents that the camera calibration is usually required for determining depth.\n\nDepth determination serves as the most challenging part in the whole process, as it calculates the 3D component missing from any given image – depth. The correspondence problem, finding matches between two images so the position of the matched elements can then be triangulated in 3D space is the key issue here.\n\nOnce you have the multiple depth maps you have to combine them to create a final mesh by calculating depth and projecting out of the camera – registration. Camera calibration will be used to identify where the many meshes created by depth maps can be combined together to develop a larger one, providing more than one view for observation.\n\nBy the stage of Material Application you have a complete 3D mesh, which may be the final goal, but usually you will want to apply the color from the original photographs to the mesh. This can range from projecting the images onto the mesh randomly, through approaches of combining the textures for super resolution and finally to segmenting the mesh by material, such as specular and diffuse properties.\n\n"
    },
    {
      "title": "Mathematical description of reconstruction",
      "text": "Given a group of 3D points viewed by N cameras with matrices \n\n\n\n{\n\nP\n\ni\n\n\n\n}\n\ni\n=\n1\n…\nN\n\n\n\n\n{\\displaystyle \\{P^{i}\\}_{i=1\\ldots N}}\n\n. Define \n\n\n\n\nm\n\nj\n\n\ni\n\n\n≃\n\nP\n\ni\n\n\n\nw\n\nj\n\n\n\n\n{\\displaystyle m_{j}^{i}\\simeq P^{i}w_{j}}\n\n be the homogeneous coordinates of the projection of the \n\n\n\n\nj\n\nt\nh\n\n\n\n\n{\\displaystyle j^{th}}\n\n point onto the \n\n\n\n\ni\n\nt\nh\n\n\n\n\n{\\displaystyle i^{th}}\n\n camera. The reconstruction problem can be changed to: given the group of pixel coordinates \n\n\n\n{\n\nm\n\nj\n\n\ni\n\n\n}\n\n\n{\\displaystyle \\{m_{j}^{i}\\}}\n\n, find the corresponding set of camera matrices \n\n\n\n{\n\nP\n\ni\n\n\n}\n\n\n{\\displaystyle \\{P^{i}\\}}\n\n and the scene structure \n\n\n\n{\n\nw\n\nj\n\n\n}\n\n\n{\\displaystyle \\{w_{j}\\}}\n\n such that\n\nGenerally, without further restrictions, we will obtain a projective reconstruction.[4][5] If \n\n\n\n{\n\nP\n\ni\n\n\n}\n\n\n{\\displaystyle \\{P^{i}\\}}\n\n and \n\n\n\n{\n\nw\n\nj\n\n\n}\n\n\n{\\displaystyle \\{w_{j}\\}}\n\n  satisfy (1), \n\n\n\n{\n\nP\n\ni\n\n\nT\n}\n\n\n{\\displaystyle \\{P^{i}T\\}}\n\n and \n\n\n\n{\n\nT\n\n−\n1\n\n\n\nw\n\nj\n\n\n}\n\n\n{\\displaystyle \\{T^{-1}w_{j}\\}}\n\n will satisfy (1) with any 4 × 4 nonsingular matrix T.\n\nA projective reconstruction can be calculated by points correspondences only, without any a-priori information.\n\n"
    },
    {
      "title": "Autocalibration",
      "text": "Autocalibration or self-calibration is the classical approach, in which camera motion and parameters are recovered first, using rigidity, then structure is readily calculated. Two methods implementing this idea are presented as follows:\n\nWith a minimum of three displacements, we can obtain the internal parameters of the camera using a system of polynomial equations due to Kruppa,[6] which are derived from a geometric interpretation of the rigidity constraint.[7][8]\n\nThe matrix \n\n\n\nK\n=\nA\n\nA\n\n⊤\n\n\n\n\n{\\displaystyle K=AA^{\\top }}\n\n is unknown in the Kruppa equations, named Kruppa coefficients matrix. With  K and by the method of Cholesky factorization one can obtain the intrinsic parameters easily:\n\nRecently Hartley [9] proposed a simpler form. Let \n\n\n\nF\n\n\n{\\displaystyle F}\n\n be written as \n\n\n\nF\n=\nD\nU\n\nV\n\n⊤\n\n\n\n\n{\\displaystyle F=DUV^{\\top }}\n\n, where\n\nThen the Kruppa equations are rewritten (the derivation can be found in [9])\n\nThis method is based on the use of rigidity constraint. Design a cost function, which considers the intrinsic parameters as arguments and the fundamental matrices as parameters. \n\n\n\n\n\nF\n\n\ni\n\n\nj\n\n\n{\\displaystyle {F}_{i}j}\n\n is defined as the fundamental matrix, \n\n\n\n\n\nA\n\n\ni\n\n\n\n\n{\\displaystyle {A}_{i}}\n\nand \n\n\n\n\n\nA\n\n\nj\n\n\n\n\n{\\displaystyle {A}_{j}}\n\n as intrinsic parameters matrices.\n\n"
    },
    {
      "title": "Stratification",
      "text": "Recently, new methods based on the concept of stratification have been proposed. Starting from a projective structure, which can be calculated from correspondences only, upgrade this projective reconstruction to a Euclidean reconstruction, by making use of all the available constraints. With this idea the problem can be stratified into different sections: according to the amount of constraints available, it can be analyzed at a different level, projective, affine or Euclidean.\n\nUsually, the world is perceived as a 3D Euclidean space. In some cases, it is not possible to use the full Euclidean structure of 3D space. The simplest being projective, then the affine geometry which forms the intermediate layers and finally Euclidean geometry. The concept of stratification is closely related to the series of transformations on geometric entities: in the projective stratum is a series of projective transformations (a homography), in the affine stratum is a series of affine transformations, and in Euclidean stratum is a series of Euclidean transformations.\n\nSuppose that a fixed scene is captured by two or more perspective cameras and the correspondences between visible points in different images are already given. However, in practice, the matching is an essential and extremely challenging issue in computer vision. Here, we suppose that \n\n\n\nn\n\n\n{\\displaystyle n}\n\n 3D points \n\n\n\n\nA\n\ni\n\n\n\n\n{\\displaystyle A_{i}}\n\n are observed by \n\n\n\nm\n\n\n{\\displaystyle m}\n\n cameras with projection matrices \n\n\n\n\nP\n\nj\n\n\n,\nj\n=\n1\n,\n…\n,\nm\n.\n\n\n{\\displaystyle P_{j},j=1,\\ldots ,m.}\n\n Neither the positions of point nor the projection of camera are known. Only the projections \n\n\n\n\na\n\ni\nj\n\n\n\n\n{\\displaystyle a_{ij}}\n\n of the \n\n\n\n\ni\n\nt\nh\n\n\n\n\n{\\displaystyle i^{th}}\n\n point in the \n\n\n\n\nj\n\nt\nh\n\n\n\n\n{\\displaystyle j^{th}}\n\n image are known.\n\nSimple counting indicates we have \n\n\n\n2\nn\nm\n\n\n{\\displaystyle 2nm}\n\n independent measurements and only \n\n\n\n11\nm\n+\n3\nn\n\n\n{\\displaystyle 11m+3n}\n\n unknowns, so the problem is supposed to be soluble with enough points and images. The equations in homogeneous coordinates can be represented:\n\nSo we can apply a nonsingular 4 × 4 transformation H to projections \n\n\n\n\nP\n\nj\n\n\n\n\n{\\displaystyle P_{j}}\n\n→\n\n\n\n\nP\n\nj\n\n\n\nH\n\n−\n1\n\n\n\n\n{\\displaystyle P_{j}H^{-1}}\n\n and world points \n\n\n\n\nA\n\ni\n\n\n\n\n{\\displaystyle A_{i}}\n\n→\n\n\n\nH\n\nA\n\ni\n\n\n\n\n{\\displaystyle HA_{i}}\n\n. Hence, without further constraints, reconstruction is only an unknown projective deformation of the 3D world.\n\nSee affine space for more detailed information about computing the location of the plane at infinity \n\n\n\n\n\nΠ\n\n\n∞\n\n\n\n\n{\\displaystyle {\\Pi }_{\\infty }}\n\n.\nThe simplest way is to exploit prior knowledge, for example the information that lines in the scene are parallel or that a point is the one thirds between two others.\n\nWe can also use prior constraints on the camera motion. By analyzing different images of the same point can obtain a line in the direction of motion. The intersection of several lines is the point at infinity in the motion direction, and one constraint on the affine structure.\n\nBy mapping the projective reconstruction to one that satisfies a group of redundant Euclidean constraints, we can find a projective transformation H in equation (2).The equations are highly nonlinear and a good initial guess for the structure is required. This can be obtained by assuming a linear projection - parallel projection, which also allows easy reconstruction by SVD decomposition.[2]\n\n"
    },
    {
      "title": "Algebraic vs geometric error",
      "text": "Inevitably, measured data (i.e., image or world point positions) is noisy and the noise comes from many sources. To reduce the effect of noise, we usually use more equations than necessary and solve with least squares.\n\nFor example, in a typical null-space problem formulation Ax = 0 (like the DLT algorithm), the square of the residual ||Ax|| is being minimized with the least squares method.\n\nIn general, if ||Ax|| can be considered as a distance between the geometrical entities (points, lines, planes, etc.), then what is being minimized is a geometric error, otherwise (when the error lacks a good geometrical interpretation) it is called an algebraic error.\n\nTherefore, compared with algebraic error, we prefer to minimize a geometric error for the reasons listed:\n\nAll the linear algorithms (DLT and others) we have seen so far minimize an algebraic error. Actually, there is no justification in minimizing an algebraic error apart from the ease of implementation, as it results in a linear problem. The minimization of a geometric error is often a non-linear problem, that admit only iterative solutions and requires a starting point.\n\nUsually, linear solution based on algebraic residuals serves as a starting point for a non-linear minimization of a geometric cost function, which provides the solution a final “polish”.[10]\n\n"
    },
    {
      "title": "3D reconstruction of Medical Images",
      "text": "The 2-D imaging has problems of anatomy overlapping with each other and don’t disclose the abnormalities. The 3-D imaging can be used for both diagnostic and therapeutic purposes.\n\n3-D models are used for planning the operation, morphometric studies and has more reliability in orthopedics.\n\nTo reconstruct 3-D images from 2-D images taken by a camera at multiple angles. Medical imaging techniques like CT scanning and MRI are expensive, and although CT scans are accurate, they can induce high radiation doses which is a risk for patients with certain diseases. Methods based on MRI are not accurate. Since we are exposed to powerful magnetic fields during an MRI scan, this method is not suitable for patients with ferromagnetic metallic implants. Both the methods can be done only when in lying position where the global structure of the bone changes. So, we discuss the following methods which can be performed while standing and require low radiation dose.\n\nThough these techniques are 3-D imaging, the region of interest is restricted to a slice; data are acquired to form a time sequence.  \n\nThis method is simple and implemented by identifying the points manually in multi-view radiographs. The first step is to extract the corresponding points in two x-ray images and second step is the 3D reconstruction with algorithms like Discrete Linear Transform.[11] Using DLT, the reconstruction is done only where there are SCPs. By increasing the number of points, the results improve [12] but it is time consuming. This method has low accuracy because of low reproducibility and time consumption. This method is dependent on the skill of the operator. This method is not suitable for bony structures with continuous shape. This method is generally used as an initial solution for other methods.[13]\n\nThis method uses X-ray images for 3D Reconstruction and to develop 3D models with low dose radiations in weight bearing positions.\n\nIn NSCC algorithm, the preliminary step is calculation of an initial solution. Firstly anatomical regions from the generic object are defined. Secondly, manual 2D contours identification on the radiographs is performed. From each radiograph 2D contours are generated using the 3D initial solution object. 3D contours of the initial object surface are projected onto their associated radiograph.[13] The 2D association performed between these 2 set points is based on point-to-point distances and contours derivations developing a correspondence between the 2D contours and the 3D contours. Next step is optimization of the initial solution. Lastly deformation of the optimized solution is done by applying Kriging algorithm to the optimized solution.[14] Finally, by iterating the final step until the distance between two set points is superior to a given precision value the reconstructed object is obtained.\n\nThe advantage of this method is it can be used for bony structures with continuous shape and it also reduced human intervention but they are time consuming.\n\nSurface Rendering technique visualizes a 3D object as a set of surfaces called iso-surfaces. Each surface has points with the same intensity (called iso-value). It is used when we want to see the separated structures e.g. skull from slices of head, blood vessel system from slices of body etc. This technique is used mostly for high contrast data. Two main methods for reconstructing are:\n\nOther proposed or developed techniques include Statistical Shape Model Based Methods, Parametric Methods, Hybrid methods.\n\n"
    }
  ],
  "links": [
    "/wiki/3D_selfie",
    "/wiki/Shapeways",
    "/wiki/Madurodam",
    "/wiki/Madurodam",
    "/wiki/Computer_graphics",
    "/wiki/Virtual_reality",
    "/wiki/Orthographic_projection",
    "/wiki/Visual_hull",
    "/wiki/Color_mapping",
    "/wiki/Correspondence_problem",
    "/wiki/Depth_map",
    "/wiki/Image_registration",
    "/wiki/Euclidean_space",
    "/wiki/Affine_transformations",
    "/wiki/Affine_space",
    "/wiki/Least_squares",
    "/wiki/Medical_imaging",
    "/wiki/CT_scanning",
    "/wiki/3D_pose_estimation",
    "/wiki/3D_reconstruction",
    "/wiki/3D_photography",
    "/wiki/2D_to_3D_conversion",
    "/wiki/3D_data_acquisition_and_object_reconstruction",
    "/wiki/Epipolar_geometry",
    "/wiki/Camera_resectioning",
    "/wiki/Computer_stereo_vision",
    "/wiki/Stereophotogrammetry",
    "/wiki/Comparison_of_photogrammetry_software",
    "/wiki/Visual_hull",
    "/wiki/3D_reconstruction_from_multiple_images",
    "/wiki/3D_reconstruction_from_multiple_images",
    "/wiki/Main_Page",
    "/wiki/Main_Page"
  ]
}