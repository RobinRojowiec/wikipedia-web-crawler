{
  "url": "https://en.wikipedia.org/wiki/Artificial_general_intelligence",
  "title": "Artificial general intelligence",
  "html": "<!DOCTYPE html>\n<html class=\"client-nojs\" dir=\"ltr\" lang=\"en\">\n<head>\n<meta charset=\"utf-8\"/>\n<title>Artificial general intelligence - Wikipedia</title>\n<script>document.documentElement.className = document.documentElement.className.replace( /(^|\\s)client-nojs(\\s|$)/, \"$1client-js$2\" );</script>\n<script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({\"wgCanonicalNamespace\":\"\",\"wgCanonicalSpecialPageName\":false,\"wgNamespaceNumber\":0,\"wgPageName\":\"Artificial_general_intelligence\",\"wgTitle\":\"Artificial general intelligence\",\"wgCurRevisionId\":884942405,\"wgRevisionId\":884942405,\"wgArticleId\":586357,\"wgIsArticle\":true,\"wgIsRedirect\":false,\"wgAction\":\"view\",\"wgUserName\":null,\"wgUserGroups\":[\"*\"],\"wgCategories\":[\"CS1 maint: Archived copy as title\",\"All articles with unsourced statements\",\"Articles with unsourced statements from June 2011\",\"Articles with unsourced statements from January 2017\",\"Articles with unsourced statements from December 2017\",\"Articles with unsourced statements from April 2011\",\"All articles needing examples\",\"Articles needing examples from September 2017\",\"Articles to be expanded from February 2016\",\"All articles to be expanded\",\"Articles using small message boxes\",\"Use dmy dates from April 2011\",\"Hypothetical technology\",\"Artificial intelligence\",\"Computational neuroscience\"],\"wgBreakFrames\":false,\"wgPageContentLanguage\":\"en\",\"wgPageContentModel\":\"wikitext\",\"wgSeparatorTransformTable\":[\"\",\"\"],\"wgDigitTransformTable\":[\"\",\"\"],\"wgDefaultDateFormat\":\"dmy\",\"wgMonthNames\":[\"\",\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"],\"wgMonthNamesShort\":[\"\",\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"],\"wgRelevantPageName\":\"Artificial_general_intelligence\",\"wgRelevantArticleId\":586357,\"wgRequestId\":\"XHM87ApAMFQAAJqKnHcAAABK\",\"wgCSPNonce\":false,\"wgIsProbablyEditable\":true,\"wgRelevantPageIsProbablyEditable\":true,\"wgRestrictionEdit\":[],\"wgRestrictionMove\":[],\"wgFlaggedRevsParams\":{\"tags\":{}},\"wgStableRevisionId\":null,\"wgCategoryTreePageCategoryOptions\":\"{\\\"mode\\\":0,\\\"hideprefix\\\":20,\\\"showcount\\\":true,\\\"namespaces\\\":false}\",\"wgWikiEditorEnabledModules\":[],\"wgBetaFeaturesFeatures\":[],\"wgMediaViewerOnClick\":true,\"wgMediaViewerEnabledByDefault\":true,\"wgPopupsShouldSendModuleToUser\":true,\"wgPopupsConflictsWithNavPopupGadget\":false,\"wgVisualEditor\":{\"pageLanguageCode\":\"en\",\"pageLanguageDir\":\"ltr\",\"pageVariantFallbacks\":\"en\",\"usePageImages\":true,\"usePageDescriptions\":true},\"wgMFIsPageContentModelEditable\":true,\"wgMFEnableFontChanger\":true,\"wgMFDisplayWikibaseDescriptions\":{\"search\":true,\"nearby\":true,\"watchlist\":true,\"tagline\":false},\"wgRelatedArticles\":null,\"wgRelatedArticlesUseCirrusSearch\":true,\"wgRelatedArticlesOnlyUseCirrusSearch\":false,\"wgWMESchemaEditAttemptStepOversample\":false,\"wgPoweredByHHVM\":true,\"wgULSCurrentAutonym\":\"English\",\"wgNoticeProject\":\"wikipedia\",\"wgCentralNoticeCookiesToDelete\":[],\"wgCentralNoticeCategoriesUsingLegacy\":[\"Fundraising\",\"fundraising\"],\"wgWikibaseItemId\":\"Q2264109\",\"wgScoreNoteLanguages\":{\"arabic\":\"العربية\",\"catalan\":\"català\",\"deutsch\":\"Deutsch\",\"english\":\"English\",\"espanol\":\"español\",\"italiano\":\"italiano\",\"nederlands\":\"Nederlands\",\"norsk\":\"norsk\",\"portugues\":\"português\",\"suomi\":\"suomi\",\"svenska\":\"svenska\",\"vlaams\":\"West-Vlams\"},\"wgScoreDefaultNoteLanguage\":\"nederlands\",\"wgCentralAuthMobileDomain\":false,\"wgCodeMirrorEnabled\":true,\"wgVisualEditorToolbarScrollOffset\":0,\"wgVisualEditorUnsupportedEditParams\":[\"undo\",\"undoafter\",\"veswitched\"],\"wgEditSubmitButtonLabelPublish\":true,\"oresWikiId\":\"enwiki\",\"oresBaseUrl\":\"http://ores.discovery.wmnet:8081/\",\"oresApiVersion\":3});mw.loader.state({\"ext.gadget.charinsert-styles\":\"ready\",\"ext.globalCssJs.user.styles\":\"ready\",\"ext.globalCssJs.site.styles\":\"ready\",\"site.styles\":\"ready\",\"noscript\":\"ready\",\"user.styles\":\"ready\",\"ext.globalCssJs.user\":\"ready\",\"ext.globalCssJs.site\":\"ready\",\"user\":\"ready\",\"user.options\":\"ready\",\"user.tokens\":\"loading\",\"ext.cite.styles\":\"ready\",\"mediawiki.legacy.shared\":\"ready\",\"mediawiki.legacy.commonPrint\":\"ready\",\"mediawiki.toc.styles\":\"ready\",\"wikibase.client.init\":\"ready\",\"ext.visualEditor.desktopArticleTarget.noscript\":\"ready\",\"ext.uls.interlanguage\":\"ready\",\"ext.wikimediaBadges\":\"ready\",\"ext.3d.styles\":\"ready\",\"mediawiki.skinning.interface\":\"ready\",\"skins.vector.styles\":\"ready\"});mw.loader.implement(\"user.tokens@0tffind\",function($,jQuery,require,module){/*@nomin*/mw.user.tokens.set({\"editToken\":\"+\\\\\",\"patrolToken\":\"+\\\\\",\"watchToken\":\"+\\\\\",\"csrfToken\":\"+\\\\\"});\n});RLPAGEMODULES=[\"ext.cite.ux-enhancements\",\"site\",\"mediawiki.page.startup\",\"mediawiki.page.ready\",\"mediawiki.toc\",\"mediawiki.searchSuggest\",\"ext.gadget.teahouse\",\"ext.gadget.ReferenceTooltips\",\"ext.gadget.watchlist-notice\",\"ext.gadget.DRN-wizard\",\"ext.gadget.charinsert\",\"ext.gadget.refToolbar\",\"ext.gadget.extra-toolbar-buttons\",\"ext.gadget.switcher\",\"ext.centralauth.centralautologin\",\"mmv.head\",\"mmv.bootstrap.autostart\",\"ext.popups\",\"ext.visualEditor.desktopArticleTarget.init\",\"ext.visualEditor.targetLoader\",\"ext.eventLogging\",\"ext.wikimediaEvents\",\"ext.navigationTiming\",\"ext.uls.eventlogger\",\"ext.uls.init\",\"ext.uls.compactlinks\",\"ext.uls.interface\",\"ext.quicksurveys.init\",\"ext.centralNotice.geoIP\",\"ext.centralNotice.startUp\",\"skins.vector.js\"];mw.loader.load(RLPAGEMODULES);});</script>\n<link href=\"/w/load.php?debug=false&amp;lang=en&amp;modules=ext.3d.styles%7Cext.cite.styles%7Cext.uls.interlanguage%7Cext.visualEditor.desktopArticleTarget.noscript%7Cext.wikimediaBadges%7Cmediawiki.legacy.commonPrint%2Cshared%7Cmediawiki.skinning.interface%7Cmediawiki.toc.styles%7Cskins.vector.styles%7Cwikibase.client.init&amp;only=styles&amp;skin=vector\" rel=\"stylesheet\"/>\n<script async=\"\" src=\"/w/load.php?debug=false&amp;lang=en&amp;modules=startup&amp;only=scripts&amp;skin=vector\"></script>\n<meta content=\"\" name=\"ResourceLoaderDynamicStyles\"/>\n<link href=\"/w/load.php?debug=false&amp;lang=en&amp;modules=ext.gadget.charinsert-styles&amp;only=styles&amp;skin=vector\" rel=\"stylesheet\"/>\n<link href=\"/w/load.php?debug=false&amp;lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=vector\" rel=\"stylesheet\"/>\n<meta content=\"MediaWiki 1.33.0-wmf.18\" name=\"generator\"/>\n<meta content=\"origin\" name=\"referrer\"/>\n<meta content=\"origin-when-crossorigin\" name=\"referrer\"/>\n<meta content=\"origin-when-cross-origin\" name=\"referrer\"/>\n<link href=\"android-app://org.wikipedia/http/en.m.wikipedia.org/wiki/Artificial_general_intelligence\" rel=\"alternate\"/>\n<link href=\"/w/index.php?title=Artificial_general_intelligence&amp;action=edit\" rel=\"alternate\" title=\"Edit this page\" type=\"application/x-wiki\"/>\n<link href=\"/w/index.php?title=Artificial_general_intelligence&amp;action=edit\" rel=\"edit\" title=\"Edit this page\"/>\n<link href=\"/static/apple-touch/wikipedia.png\" rel=\"apple-touch-icon\"/>\n<link href=\"/static/favicon/wikipedia.ico\" rel=\"shortcut icon\"/>\n<link href=\"/w/opensearch_desc.php\" rel=\"search\" title=\"Wikipedia (en)\" type=\"application/opensearchdescription+xml\"/>\n<link href=\"//en.wikipedia.org/w/api.php?action=rsd\" rel=\"EditURI\" type=\"application/rsd+xml\"/>\n<link href=\"//creativecommons.org/licenses/by-sa/3.0/\" rel=\"license\"/>\n<link href=\"https://en.wikipedia.org/wiki/Artificial_general_intelligence\" rel=\"canonical\"/>\n<link href=\"//login.wikimedia.org\" rel=\"dns-prefetch\"/>\n<link href=\"//meta.wikimedia.org\" rel=\"dns-prefetch\"/>\n<!--[if lt IE 9]><script src=\"/w/load.php?debug=false&amp;lang=en&amp;modules=html5shiv&amp;only=scripts&amp;skin=vector&amp;sync=1\"></script><![endif]-->\n</head>\n<body class=\"mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject mw-editable page-Artificial_general_intelligence rootpage-Artificial_general_intelligence skin-vector action-view\"> <div class=\"noprint\" id=\"mw-page-base\"></div>\n<div class=\"noprint\" id=\"mw-head-base\"></div>\n<div class=\"mw-body\" id=\"content\" role=\"main\">\n<a id=\"top\"></a>\n<div class=\"mw-body-content\" id=\"siteNotice\"><!-- CentralNotice --></div><div class=\"mw-indicators mw-body-content\">\n</div>\n<h1 class=\"firstHeading\" id=\"firstHeading\" lang=\"en\">Artificial general intelligence</h1> <div class=\"mw-body-content\" id=\"bodyContent\">\n<div class=\"noprint\" id=\"siteSub\">From Wikipedia, the free encyclopedia</div> <div id=\"contentSub\"></div>\n<div id=\"jump-to-nav\"></div> <a class=\"mw-jump-link\" href=\"#mw-head\">Jump to navigation</a>\n<a class=\"mw-jump-link\" href=\"#p-search\">Jump to search</a>\n<div class=\"mw-content-ltr\" dir=\"ltr\" id=\"mw-content-text\" lang=\"en\"><div class=\"mw-parser-output\"><p><b>Artificial general intelligence</b> (<b>AGI</b>) is the intelligence of a machine that could successfully perform any intellectual task that a <a href=\"/wiki/Human\" title=\"Human\">human</a> being can. It is a primary goal of some <a href=\"/wiki/Artificial_intelligence\" title=\"Artificial intelligence\">artificial intelligence</a> research and a common topic in <a href=\"/wiki/Science_fiction\" title=\"Science fiction\">science fiction</a> and <a href=\"/wiki/Futures_studies\" title=\"Futures studies\">future studies</a>. Some researchers refer to Artificial general intelligence as \"<b>strong AI</b>\",<sup class=\"reference\" id=\"cite_ref-K_1-0\"><a href=\"#cite_note-K-1\">[1]</a></sup> \"<b>full AI</b>\"<sup class=\"reference\" id=\"cite_ref-2\"><a href=\"#cite_note-2\">[2]</a></sup> or as the ability of a machine to perform \"general intelligent action\"<sup class=\"reference\" id=\"cite_ref-3\"><a href=\"#cite_note-3\">[3]</a></sup>; others reserve \"strong AI\" for machines capable of experiencing <a href=\"/wiki/Chinese_room#Strong_AI\" title=\"Chinese room\">consciousness</a>.\n</p><p>Some references emphasize a distinction between strong AI and \"applied AI\"<sup class=\"reference\" id=\"cite_ref-4\"><a href=\"#cite_note-4\">[4]</a></sup> (also called \"narrow AI\"<sup class=\"reference\" id=\"cite_ref-K_1-1\"><a href=\"#cite_note-K-1\">[1]</a></sup> or \"<a href=\"/wiki/Weak_AI\" title=\"Weak AI\">weak AI</a>\"<sup class=\"reference\" id=\"cite_ref-5\"><a href=\"#cite_note-5\">[5]</a></sup>): the use of software to study or accomplish specific <a href=\"/wiki/Problem_solving\" title=\"Problem solving\">problem solving</a> or <a href=\"/wiki/Reason\" title=\"Reason\">reasoning</a> tasks. Weak AI, in contrast to strong AI, does not attempt to perform the full range of human <a class=\"mw-redirect\" href=\"/wiki/Cognitive\" title=\"Cognitive\">cognitive</a> abilities.\n</p><p>As of 2017, over forty organizations worldwide are doing active research on AGI.<sup class=\"reference\" id=\"cite_ref-baum_6-0\"><a href=\"#cite_note-baum-6\">[6]</a></sup>\n</p>\n<div class=\"toc\" id=\"toc\"><input class=\"toctogglecheckbox\" id=\"toctogglecheckbox\" role=\"button\" style=\"display:none\" type=\"checkbox\"/><div class=\"toctitle\" dir=\"ltr\" lang=\"en\"><h2>Contents</h2><span class=\"toctogglespan\"><label class=\"toctogglelabel\" for=\"toctogglecheckbox\"></label></span></div>\n<ul>\n<li class=\"toclevel-1 tocsection-1\"><a href=\"#Requirements\"><span class=\"tocnumber\">1</span> <span class=\"toctext\">Requirements</span></a>\n<ul>\n<li class=\"toclevel-2 tocsection-2\"><a href=\"#Tests_for_confirming_human-level_AGI[13]\"><span class=\"tocnumber\">1.1</span> <span class=\"toctext\">Tests for confirming human-level AGI<sup>[13]</sup></span></a></li>\n<li class=\"toclevel-2 tocsection-3\"><a href=\"#IQ-Tests_AGI\"><span class=\"tocnumber\">1.2</span> <span class=\"toctext\">IQ-Tests AGI</span></a></li>\n</ul>\n</li>\n<li class=\"toclevel-1 tocsection-4\"><a href=\"#Problems_requiring_AGI_to_solve\"><span class=\"tocnumber\">2</span> <span class=\"toctext\">Problems requiring AGI to solve</span></a></li>\n<li class=\"toclevel-1 tocsection-5\"><a href=\"#Classical_AI\"><span class=\"tocnumber\">3</span> <span class=\"toctext\">Classical AI</span></a></li>\n<li class=\"toclevel-1 tocsection-6\"><a href=\"#Current_narrow_AI_research\"><span class=\"tocnumber\">4</span> <span class=\"toctext\">Current narrow AI research</span></a></li>\n<li class=\"toclevel-1 tocsection-7\"><a href=\"#Artificial_general_intelligence_research\"><span class=\"tocnumber\">5</span> <span class=\"toctext\">Artificial general intelligence research</span></a></li>\n<li class=\"toclevel-1 tocsection-8\"><a href=\"#Processing_power_needed_to_simulate_a_brain\"><span class=\"tocnumber\">6</span> <span class=\"toctext\">Processing power needed to simulate a brain</span></a>\n<ul>\n<li class=\"toclevel-2 tocsection-9\"><a href=\"#Whole_brain_emulation\"><span class=\"tocnumber\">6.1</span> <span class=\"toctext\">Whole brain emulation</span></a></li>\n<li class=\"toclevel-2 tocsection-10\"><a href=\"#Early_estimates\"><span class=\"tocnumber\">6.2</span> <span class=\"toctext\">Early estimates</span></a></li>\n<li class=\"toclevel-2 tocsection-11\"><a href=\"#Modelling_the_neurons_in_more_detail\"><span class=\"tocnumber\">6.3</span> <span class=\"toctext\">Modelling the neurons in more detail</span></a></li>\n<li class=\"toclevel-2 tocsection-12\"><a href=\"#Current_research\"><span class=\"tocnumber\">6.4</span> <span class=\"toctext\">Current research</span></a></li>\n<li class=\"toclevel-2 tocsection-13\"><a href=\"#Complications_of_and_criticisms_to_AI_approaches,_based_on_simulation\"><span class=\"tocnumber\">6.5</span> <span class=\"toctext\">Complications of and criticisms to AI approaches, based on simulation</span></a></li>\n</ul>\n</li>\n<li class=\"toclevel-1 tocsection-14\"><a href=\"#Artificial_consciousness_research\"><span class=\"tocnumber\">7</span> <span class=\"toctext\">Artificial consciousness research</span></a></li>\n<li class=\"toclevel-1 tocsection-15\"><a href='#Relationship_to_\"strong_AI\"'><span class=\"tocnumber\">8</span> <span class=\"toctext\">Relationship to \"strong AI\"</span></a></li>\n<li class=\"toclevel-1 tocsection-16\"><a href=\"#Possible_explanations_for_the_slow_progress_of_AI_research\"><span class=\"tocnumber\">9</span> <span class=\"toctext\">Possible explanations for the slow progress of AI research</span></a></li>\n<li class=\"toclevel-1 tocsection-17\"><a href=\"#Consciousness\"><span class=\"tocnumber\">10</span> <span class=\"toctext\">Consciousness</span></a></li>\n<li class=\"toclevel-1 tocsection-18\"><a href=\"#Controversies_and_dangers\"><span class=\"tocnumber\">11</span> <span class=\"toctext\">Controversies and dangers</span></a>\n<ul>\n<li class=\"toclevel-2 tocsection-19\"><a href=\"#Feasibility\"><span class=\"tocnumber\">11.1</span> <span class=\"toctext\">Feasibility</span></a></li>\n<li class=\"toclevel-2 tocsection-20\"><a href=\"#Potential_threat_to_human_existence\"><span class=\"tocnumber\">11.2</span> <span class=\"toctext\">Potential threat to human existence</span></a>\n<ul>\n<li class=\"toclevel-3 tocsection-21\"><a href=\"#Self-replicating_machines\"><span class=\"tocnumber\">11.2.1</span> <span class=\"toctext\">Self-replicating machines</span></a></li>\n<li class=\"toclevel-3 tocsection-22\"><a href=\"#Emergent_superintelligence\"><span class=\"tocnumber\">11.2.2</span> <span class=\"toctext\">Emergent superintelligence</span></a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li class=\"toclevel-1 tocsection-23\"><a href=\"#See_also\"><span class=\"tocnumber\">12</span> <span class=\"toctext\">See also</span></a></li>\n<li class=\"toclevel-1 tocsection-24\"><a href=\"#Notes\"><span class=\"tocnumber\">13</span> <span class=\"toctext\">Notes</span></a></li>\n<li class=\"toclevel-1 tocsection-25\"><a href=\"#References\"><span class=\"tocnumber\">14</span> <span class=\"toctext\">References</span></a></li>\n<li class=\"toclevel-1 tocsection-26\"><a href=\"#External_links\"><span class=\"tocnumber\">15</span> <span class=\"toctext\">External links</span></a></li>\n</ul>\n</div>\n<h2><span class=\"mw-headline\" id=\"Requirements\">Requirements</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=1\" title=\"Edit section: Requirements\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<div class=\"hatnote navigation-not-searchable\" role=\"note\">Main article: <a href=\"/wiki/Cognitive_science\" title=\"Cognitive science\">Cognitive science</a></div>\n<p>Various criteria for <a href=\"/wiki/Intelligence\" title=\"Intelligence\">intelligence</a> have been proposed (most famously the <a href=\"/wiki/Turing_test\" title=\"Turing test\">Turing test</a>) but to date, there is no definition that satisfies everyone.<sup class=\"reference\" id=\"cite_ref-7\"><a href=\"#cite_note-7\">[7]</a></sup> However, there <i>is</i> wide agreement among artificial intelligence researchers that intelligence is required to do the following:<sup class=\"reference\" id=\"cite_ref-8\"><a href=\"#cite_note-8\">[8]</a></sup>\n</p>\n<ul><li><a href=\"/wiki/Automated_reasoning\" title=\"Automated reasoning\">reason</a>, use strategy, solve puzzles, and make judgments under <a href=\"/wiki/Uncertainty\" title=\"Uncertainty\">uncertainty</a>;</li>\n<li><a class=\"mw-redirect\" href=\"/wiki/Knowledge_representation\" title=\"Knowledge representation\">represent knowledge</a>, including <a class=\"mw-redirect\" href=\"/wiki/Commonsense_knowledge_base\" title=\"Commonsense knowledge base\">commonsense knowledge</a>;</li>\n<li><a href=\"/wiki/Automated_planning_and_scheduling\" title=\"Automated planning and scheduling\">plan</a>;</li>\n<li><a href=\"/wiki/Machine_learning\" title=\"Machine learning\">learn</a>;</li>\n<li>communicate in <a href=\"/wiki/Natural_language_processing\" title=\"Natural language processing\">natural language</a>;</li>\n<li>and integrate all these skills towards common goals.</li></ul>\n<p>Other important capabilities include the ability to <a href=\"/wiki/Machine_perception\" title=\"Machine perception\">sense</a> (e.g. <a href=\"/wiki/Computer_vision\" title=\"Computer vision\">see</a>) and the ability to act (e.g. <a href=\"/wiki/Robotics\" title=\"Robotics\">move and manipulate objects</a>) in the world where intelligent behaviour is to be observed.<sup class=\"reference\" id=\"cite_ref-9\"><a href=\"#cite_note-9\">[9]</a></sup> This would include an ability to detect and respond to <a href=\"/wiki/Hazard\" title=\"Hazard\">hazard</a>.<sup class=\"reference\" id=\"cite_ref-10\"><a href=\"#cite_note-10\">[10]</a></sup> Many interdisciplinary approaches to intelligence (e.g. <a href=\"/wiki/Cognitive_science\" title=\"Cognitive science\">cognitive science</a>, <a href=\"/wiki/Computational_intelligence\" title=\"Computational intelligence\">computational intelligence</a> and <a class=\"mw-redirect\" href=\"/wiki/Decision_making\" title=\"Decision making\">decision making</a>) tend to emphasise the need to consider additional traits such as <a href=\"/wiki/Imagination\" title=\"Imagination\">imagination</a> (taken as the ability to form mental images and concepts that were not programmed in)<sup class=\"reference\" id=\"cite_ref-11\"><a href=\"#cite_note-11\">[11]</a></sup> and <a href=\"/wiki/Self-determination_theory\" title=\"Self-determination theory\">autonomy</a>.<sup class=\"reference\" id=\"cite_ref-12\"><a href=\"#cite_note-12\">[12]</a></sup>\nComputer based systems that exhibit many of these capabilities do exist (e.g. see <a href=\"/wiki/Computational_creativity\" title=\"Computational creativity\">computational creativity</a>, <a href=\"/wiki/Automated_reasoning\" title=\"Automated reasoning\">automated reasoning</a>, <a href=\"/wiki/Decision_support_system\" title=\"Decision support system\">decision support system</a>, <a href=\"/wiki/Robot\" title=\"Robot\">robot</a>, <a href=\"/wiki/Evolutionary_computation\" title=\"Evolutionary computation\">evolutionary computation</a>, <a href=\"/wiki/Intelligent_agent\" title=\"Intelligent agent\">intelligent agent</a>), but not yet at human levels.\n</p>\n<h3><span id=\"Tests_for_confirming_human-level_AGI.5B13.5D\"></span><span class=\"mw-headline\" id=\"Tests_for_confirming_human-level_AGI[13]\">Tests for confirming human-level AGI<span id=\"Tests_for_confirming_human-level_AGI\"></span><sup class=\"reference\" id=\"cite_ref-13\"><a href=\"#cite_note-13\">[13]</a></sup></span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=2\" title=\"Edit section: Tests for confirming human-level AGI[13]\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<dl><dt><a href=\"/wiki/Turing_test\" title=\"Turing test\">The Turing Test</a> (<a href=\"/wiki/Alan_Turing\" title=\"Alan Turing\"><i>Turing</i></a>)</dt>\n<dd>A machine and a human both converse sight unseen with a second human, who must evaluate which of the two is the machine, which passes the test if it can fool the evaluator a significant fraction of the time. Note: Turing does not prescribe what should qualify as intelligence, only that knowing that it is a machine should not disqualify it.</dd>\n<dt>The Coffee Test (<a href=\"/wiki/Steve_Wozniak\" title=\"Steve Wozniak\"><i>Wozniak</i></a>)</dt>\n<dd>A machine is required to enter an average American home and figure out how to make coffee: find the coffee machine, find the coffee, add water, find a mug, and brew the coffee by pushing the proper buttons.</dd>\n<dt>The Robot College Student Test (<a href=\"/wiki/Ben_Goertzel\" title=\"Ben Goertzel\"><i>Goertzel</i></a>)</dt>\n<dd>A machine enrolls in a university, taking and passing the same classes that humans would, and obtaining a degree.</dd>\n<dt>The Employment Test (<a href=\"/wiki/Nils_John_Nilsson\" title=\"Nils John Nilsson\"><i>Nilsson</i></a>)</dt>\n<dd>A machine works an economically important job, performing at least as well as humans in the same job.</dd>\n<dt>The flat pack furniture test (<i>Tony Severyns</i>)</dt>\n<dd>A machine is required to unpack and assemble an item of flat-packed furniture. It has to read the instructions and assemble the item as described, correctly installing all fixtures.</dd></dl>\n<h3><span class=\"mw-headline\" id=\"IQ-Tests_AGI\">IQ-Tests AGI<span id=\"IQ-Tests_AGI\"></span></span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=3\" title=\"Edit section: IQ-Tests AGI\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>Chinese researchers Feng Liu, Yong Shi and Ying Liu conducted intelligence tests in the summer of 2017 with public available and freely accessible weak AI such as Google AI or Apple's Siri and others. At the maximum, these AI reached a value of about 47, which corresponds approximately to a six-year-old child in first grade. An adult comes to about 100 on average. In 2014, similar tests were carried out in which the AI reached a maximum value of 27. <sup class=\"reference\" id=\"cite_ref-14\"><a href=\"#cite_note-14\">[14]</a></sup><sup class=\"reference\" id=\"cite_ref-15\"><a href=\"#cite_note-15\">[15]</a></sup>.\n</p>\n<h2><span class=\"mw-headline\" id=\"Problems_requiring_AGI_to_solve\">Problems requiring AGI to solve</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=4\" title=\"Edit section: Problems requiring AGI to solve\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<div class=\"hatnote navigation-not-searchable\" role=\"note\">Main article: <a href=\"/wiki/AI-complete\" title=\"AI-complete\">AI-complete</a></div>\n<p>The most difficult problems for computers are informally known as \"AI-complete\" or \"AI-hard\", implying that solving them is equivalent to the general aptitude of human intelligence, or strong AI, beyond the capabilities of a purpose-specific algorithm.<sup class=\"reference\" id=\"cite_ref-Shapiro92_16-0\"><a href=\"#cite_note-Shapiro92-16\">[16]</a></sup>\n</p><p>AI-complete problems are hypothesised to include general <a href=\"/wiki/Computer_vision\" title=\"Computer vision\">computer vision</a>, <a class=\"mw-redirect\" href=\"/wiki/Natural_language_understanding\" title=\"Natural language understanding\">natural language understanding</a>, and dealing with unexpected circumstances while solving any real world problem.<sup class=\"reference\" id=\"cite_ref-17\"><a href=\"#cite_note-17\">[17]</a></sup>\n</p><p>AI-complete problems cannot be solved with current computer technology alone, and also require <a class=\"mw-redirect\" href=\"/wiki/Human_computation\" title=\"Human computation\">human computation</a>.  This property can be useful to test for the presence of humans, as with <a href=\"/wiki/CAPTCHA\" title=\"CAPTCHA\">CAPTCHAs</a>, and for <a href=\"/wiki/Computer_security\" title=\"Computer security\">computer security</a> to repel <a href=\"/wiki/Brute-force_attack\" title=\"Brute-force attack\">brute-force attacks</a>.<sup class=\"reference\" id=\"cite_ref-18\"><a href=\"#cite_note-18\">[18]</a></sup><sup class=\"reference\" id=\"cite_ref-19\"><a href=\"#cite_note-19\">[19]</a></sup>\n</p>\n<h2><span class=\"mw-headline\" id=\"Classical_AI\">Classical AI</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=5\" title=\"Edit section: Classical AI\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<div class=\"hatnote navigation-not-searchable\" role=\"note\">Main article: <a href=\"/wiki/History_of_artificial_intelligence\" title=\"History of artificial intelligence\">History of artificial intelligence</a></div>\n<p>Modern AI research began in the mid 1950s.<sup class=\"reference\" id=\"cite_ref-20\"><a href=\"#cite_note-20\">[20]</a></sup> The first generation of AI researchers was convinced that artificial general intelligence was possible and that it would exist in just a few decades. As AI pioneer <a href=\"/wiki/Herbert_A._Simon\" title=\"Herbert A. Simon\">Herbert A. Simon</a> wrote in 1965: \"machines will be capable, within twenty years, of doing any work a man can do.\"<sup class=\"reference\" id=\"cite_ref-21\"><a href=\"#cite_note-21\">[21]</a></sup> Their predictions were the inspiration for <a href=\"/wiki/Stanley_Kubrick\" title=\"Stanley Kubrick\">Stanley Kubrick</a> and <a href=\"/wiki/Arthur_C._Clarke\" title=\"Arthur C. Clarke\">Arthur C. Clarke</a>'s character <a href=\"/wiki/HAL_9000\" title=\"HAL 9000\">HAL 9000</a>, who accurately embodied what AI researchers believed they could create by the year 2001. Of note is the fact that AI pioneer <a href=\"/wiki/Marvin_Minsky\" title=\"Marvin Minsky\">Marvin Minsky</a> was a consultant<sup class=\"reference\" id=\"cite_ref-22\"><a href=\"#cite_note-22\">[22]</a></sup> on the project of making HAL 9000 as realistic as possible according to the consensus predictions of the time; Crevier quotes him as having said on the subject in 1967, \"Within a generation ... the problem of creating 'artificial intelligence' will substantially be solved,\"<sup class=\"reference\" id=\"cite_ref-23\"><a href=\"#cite_note-23\">[23]</a></sup> although Minsky states that he was misquoted.<sup class=\"noprint Inline-Template Template-Fact\" style=\"white-space:nowrap;\">[<i><a href=\"/wiki/Wikipedia:Citation_needed\" title=\"Wikipedia:Citation needed\"><span title=\"This claim needs references to reliable sources. (June 2011)\">citation needed</span></a></i>]</sup>\n</p><p>However, in the early 1970s, it became obvious that researchers had grossly underestimated the difficulty of the project. Funding agencies became skeptical of AGI and put researchers under increasing pressure to produce useful \"applied AI\".<sup class=\"reference\" id=\"cite_ref-24\"><a href=\"#cite_note-24\">[24]</a></sup> As the 1980s began, Japan's <a class=\"mw-redirect\" href=\"/wiki/Fifth_Generation_Computer\" title=\"Fifth Generation Computer\">Fifth Generation Computer</a> Project revived interest in AGI, setting out a ten-year timeline that included AGI goals like \"carry on a casual conversation\".<sup class=\"reference\" id=\"cite_ref-25\"><a href=\"#cite_note-25\">[25]</a></sup> In response to this and the success of <a class=\"mw-redirect\" href=\"/wiki/Expert_systems\" title=\"Expert systems\">expert systems</a>, both industry and government pumped money back into the field.<sup class=\"reference\" id=\"cite_ref-26\"><a href=\"#cite_note-26\">[26]</a></sup> However, confidence in AI spectacularly collapsed in the late 1980s, and the goals of the Fifth Generation Computer Project were never fulfilled.<sup class=\"reference\" id=\"cite_ref-27\"><a href=\"#cite_note-27\">[27]</a></sup> For the second time in 20 years, AI researchers who had predicted the imminent achievement of AGI had been shown to be fundamentally mistaken. By the 1990s, AI researchers had gained a reputation for making vain promises. They became reluctant to make predictions at all<sup class=\"reference\" id=\"cite_ref-28\"><a href=\"#cite_note-28\">[28]</a></sup> and to avoid any mention of \"human level\" artificial intelligence for fear of being labeled \"wild-eyed dreamer[s].\"<sup class=\"reference\" id=\"cite_ref-29\"><a href=\"#cite_note-29\">[29]</a></sup>\n</p>\n<h2><span class=\"mw-headline\" id=\"Current_narrow_AI_research\">Current narrow AI research</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=6\" title=\"Edit section: Current narrow AI research\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<div class=\"hatnote navigation-not-searchable\" role=\"note\">Main article: <a href=\"/wiki/Artificial_intelligence\" title=\"Artificial intelligence\">Artificial intelligence</a></div>\n<p>In the 1990s and early 21st century, mainstream AI has achieved far greater commercial success and academic respectability by focusing on specific sub-problems where they can produce verifiable results and commercial applications, such as <a class=\"mw-redirect\" href=\"/wiki/Artificial_neural_networks\" title=\"Artificial neural networks\">artificial neural networks</a>, <a href=\"/wiki/Computer_vision\" title=\"Computer vision\">computer vision</a> or <a href=\"/wiki/Data_mining\" title=\"Data mining\">data mining</a>.<sup class=\"reference\" id=\"cite_ref-30\"><a href=\"#cite_note-30\">[30]</a></sup> These \"applied AI\" systems are now used extensively throughout the technology industry, and research in this vein is very heavily funded in both academia and industry.\n</p><p>\nMost mainstream AI researchers hope that strong AI can be developed by combining the programs that solve various sub-problems using an integrated <a href=\"/wiki/Agent_architecture\" title=\"Agent architecture\">agent architecture</a>, <a href=\"/wiki/Cognitive_architecture\" title=\"Cognitive architecture\">cognitive architecture</a> or <a href=\"/wiki/Subsumption_architecture\" title=\"Subsumption architecture\">subsumption architecture</a>. <a href=\"/wiki/Hans_Moravec\" title=\"Hans Moravec\">Hans Moravec</a> wrote in 1988: </p><blockquote><p>\"I am confident that this bottom-up route to artificial intelligence will one day meet the traditional top-down route more than half way, ready to provide the real world competence and the <a class=\"mw-redirect\" href=\"/wiki/Commonsense_knowledge_base\" title=\"Commonsense knowledge base\">commonsense knowledge</a> that has been so frustratingly elusive in reasoning programs. Fully intelligent machines will result when the metaphorical <a href=\"/wiki/Golden_spike\" title=\"Golden spike\">golden spike</a> is driven uniting the two efforts.\"<sup class=\"reference\" id=\"cite_ref-31\"><a href=\"#cite_note-31\">[31]</a></sup></p></blockquote><p>\nHowever, even this fundamental philosophy has been disputed; for example, Stevan Harnad of Princeton concluded his 1990 paper on the <a href=\"/wiki/Symbol_grounding_problem\" title=\"Symbol grounding problem\">Symbol Grounding Hypothesis</a> by stating: </p><blockquote><p>\"The expectation has often been voiced that \"top-down\" (symbolic) approaches to modeling cognition will somehow meet \"bottom-up\" (sensory) approaches somewhere in between. If the grounding considerations in this paper are valid, then this expectation is hopelessly modular and there is really only one viable route from sense to symbols: from the ground up. A free-floating symbolic level like the software level of a computer will never be reached by this route (or vice versa) – nor is it clear why we should even try to reach such a level, since it looks as if getting there would just amount to uprooting our symbols from their intrinsic meanings (thereby merely reducing ourselves to the functional equivalent of a programmable computer).\"<sup class=\"reference\" id=\"cite_ref-32\"><a href=\"#cite_note-32\">[32]</a></sup></p></blockquote>\n<h2><span class=\"mw-headline\" id=\"Artificial_general_intelligence_research\">Artificial general intelligence research</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=7\" title=\"Edit section: Artificial general intelligence research\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>Artificial general intelligence<sup class=\"reference\" id=\"cite_ref-FOOTNOTEGoertzelPennachin2006_33-0\"><a href=\"#cite_note-FOOTNOTEGoertzelPennachin2006-33\">[33]</a></sup> (AGI) describes research that aims to create machines capable of general intelligent action. The term was used as early as 1997, by Mark Gubrud<sup class=\"reference\" id=\"cite_ref-34\"><a href=\"#cite_note-34\">[34]</a></sup> in a discussion of the implications of fully automated military production and operations. The term was re-introduced and popularized by <a href=\"/wiki/Shane_Legg\" title=\"Shane Legg\">Shane Legg</a> and <a href=\"/wiki/Ben_Goertzel\" title=\"Ben Goertzel\">Ben Goertzel</a> around 2002.<sup class=\"reference\" id=\"cite_ref-35\"><a href=\"#cite_note-35\">[35]</a></sup> The research objective is much older, for example <a class=\"mw-redirect\" href=\"/wiki/Doug_Lenat\" title=\"Doug Lenat\">Doug Lenat</a>'s <a href=\"/wiki/Cyc\" title=\"Cyc\">Cyc</a> project (that began in 1984), and <a href=\"/wiki/Allen_Newell\" title=\"Allen Newell\">Allen Newell</a>'s <a href=\"/wiki/Soar_(cognitive_architecture)\" title=\"Soar (cognitive architecture)\">Soar</a> project are regarded as within the scope of AGI. AGI research activity in 2006 was described by Pei Wang and Ben Goertzel<sup class=\"reference\" id=\"cite_ref-36\"><a href=\"#cite_note-36\">[36]</a></sup> as \"producing publications and preliminary results\". As yet, most AI researchers have devoted little attention to AGI, with some claiming that intelligence is too complex to be completely replicated in the near term. However, a small number of computer scientists are active in AGI research, and many of this group are contributing to a series of <a href=\"/wiki/Conference_on_Artificial_General_Intelligence\" title=\"Conference on Artificial General Intelligence\">AGI conferences</a>. The research is extremely diverse and often pioneering in nature. In the introduction to his book,<sup class=\"reference\" id=\"cite_ref-FOOTNOTEGoertzelPennachin2006_33-1\"><a href=\"#cite_note-FOOTNOTEGoertzelPennachin2006-33\">[33]</a></sup> Goertzel says that estimates of the time needed before a truly flexible AGI is built vary from 10 years to over a century, but the consensus in the AGI research community seems to be that the timeline discussed by <a href=\"/wiki/Ray_Kurzweil\" title=\"Ray Kurzweil\">Ray Kurzweil</a> in <i><a class=\"mw-redirect\" href=\"/wiki/The_Singularity_is_Near\" title=\"The Singularity is Near\">The Singularity is Near</a></i><sup class=\"reference\" id=\"cite_ref-K_1-2\"><a href=\"#cite_note-K-1\">[1]</a></sup> (i.e. between 2015 and 2045) is plausible.<sup class=\"reference\" id=\"cite_ref-FOOTNOTEGoertzel2007_37-0\"><a href=\"#cite_note-FOOTNOTEGoertzel2007-37\">[37]</a></sup> Most mainstream AI researchers doubt that progress will be this rapid.<sup class=\"noprint Inline-Template Template-Fact\" style=\"white-space:nowrap;\">[<i><a href=\"/wiki/Wikipedia:Citation_needed\" title=\"Wikipedia:Citation needed\"><span title=\"This claim needs references to reliable sources. (January 2017)\">citation needed</span></a></i>]</sup> Organizations explicitly pursuing AGI include the Swiss AI lab <a class=\"mw-redirect\" href=\"/wiki/IDSIA\" title=\"IDSIA\">IDSIA</a>,<sup class=\"noprint Inline-Template Template-Fact\" style=\"white-space:nowrap;\">[<i><a href=\"/wiki/Wikipedia:Citation_needed\" title=\"Wikipedia:Citation needed\"><span title=\"This claim needs references to reliable sources. (December 2017)\">citation needed</span></a></i>]</sup> Nnaisense,<sup class=\"reference\" id=\"cite_ref-38\"><a href=\"#cite_note-38\">[38]</a></sup> <a href=\"/wiki/Vicarious_(company)\" title=\"Vicarious (company)\">Vicarious</a>, <a href=\"/wiki/Maluuba\" title=\"Maluuba\">Maluuba</a>,<sup class=\"reference\" id=\"cite_ref-baum_6-1\"><a href=\"#cite_note-baum-6\">[6]</a></sup> the <a href=\"/wiki/OpenCog\" title=\"OpenCog\">OpenCog Foundation</a>, Adaptive AI, <a href=\"/wiki/LIDA_(cognitive_architecture)\" title=\"LIDA (cognitive architecture)\">LIDA</a>, and <a href=\"/wiki/Numenta\" title=\"Numenta\">Numenta</a> and the associated <a class=\"mw-redirect\" href=\"/wiki/Redwood_Neuroscience_Institute\" title=\"Redwood Neuroscience Institute\">Redwood Neuroscience Institute</a>.<sup class=\"reference\" id=\"cite_ref-39\"><a href=\"#cite_note-39\">[39]</a></sup> In addition, organizations such as the <a href=\"/wiki/Machine_Intelligence_Research_Institute\" title=\"Machine Intelligence Research Institute\">Machine Intelligence Research Institute</a><sup class=\"reference\" id=\"cite_ref-40\"><a href=\"#cite_note-40\">[40]</a></sup> and <a href=\"/wiki/OpenAI\" title=\"OpenAI\">OpenAI</a><sup class=\"reference\" id=\"cite_ref-41\"><a href=\"#cite_note-41\">[41]</a></sup> have been founded to influence the development path of AGI. Finally, projects such as the <a href=\"/wiki/Human_Brain_Project\" title=\"Human Brain Project\">Human Brain Project</a><sup class=\"reference\" id=\"cite_ref-42\"><a href=\"#cite_note-42\">[42]</a></sup> have the goal of building a functioning simulation of the human brain. A 2017 survey of AGI categorized forty-five known \"active R&amp;D projects\" that explicitly or implicitly (through published research) research AGI, with the largest three being <a href=\"/wiki/DeepMind\" title=\"DeepMind\">DeepMind</a>, the Human Brain Project, and <a href=\"/wiki/OpenAI\" title=\"OpenAI\">OpenAI</a> based article <sup class=\"reference\" id=\"cite_ref-43\"><a href=\"#cite_note-43\">[43]</a></sup>.\n</p><p>Namely <a href=\"/wiki/DeepMind\" title=\"DeepMind\">DeepMind</a> with their success in Human Player Simulation for e.g <a href=\"/wiki/AlphaGo\" title=\"AlphaGo\">AlphaGo</a> made use of new concepts:\n</p>\n<ul><li><a href=\"/wiki/Reinforcement_learning\" title=\"Reinforcement learning\">Reinforcement learning</a> to improve already trained networks with new data or</li>\n<li><a href=\"/wiki/Unsupervised_learning\" title=\"Unsupervised learning\">Unsupervised learning</a>, e.g by <a href=\"/wiki/Generative_adversarial_network\" title=\"Generative adversarial network\">Generative adversarial network</a> to get improved networks by competition.</li></ul>\n<h2><span class=\"mw-headline\" id=\"Processing_power_needed_to_simulate_a_brain\">Processing power needed to simulate a brain</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=8\" title=\"Edit section: Processing power needed to simulate a brain\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<h3><span class=\"mw-headline\" id=\"Whole_brain_emulation\">Whole brain emulation</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=9\" title=\"Edit section: Whole brain emulation\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<div class=\"hatnote navigation-not-searchable\" role=\"note\">Main article: <a href=\"/wiki/Mind_uploading\" title=\"Mind uploading\">Mind uploading</a></div>\n<p>A popular approach discussed to achieving general intelligent action is <a class=\"mw-redirect\" href=\"/wiki/Whole_brain_emulation\" title=\"Whole brain emulation\">whole brain emulation</a>. A low-level brain model is built by <a class=\"mw-redirect\" href=\"/wiki/Brain_scanning\" title=\"Brain scanning\">scanning</a> and <a href=\"/wiki/Brain_mapping\" title=\"Brain mapping\">mapping</a> a biological brain in detail and copying its state into a computer system or another computational device. The computer runs a <a href=\"/wiki/Computer_simulation\" title=\"Computer simulation\">simulation</a> model so faithful to the original that it will behave in essentially the same way as the original brain, or for all practical purposes, indistinguishably.<sup class=\"reference\" id=\"cite_ref-Roadmap_44-0\"><a href=\"#cite_note-Roadmap-44\">[44]</a></sup> Whole brain emulation is discussed in <a href=\"/wiki/Computational_neuroscience\" title=\"Computational neuroscience\">computational neuroscience</a> and <a href=\"/wiki/Neuroinformatics\" title=\"Neuroinformatics\">neuroinformatics</a>, in the context of <a href=\"/wiki/Brain_simulation\" title=\"Brain simulation\">brain simulation</a> for medical research purposes. It is discussed in <a href=\"/wiki/Artificial_intelligence\" title=\"Artificial intelligence\">artificial intelligence</a> research<sup class=\"reference\" id=\"cite_ref-FOOTNOTEGoertzel2007_37-1\"><a href=\"#cite_note-FOOTNOTEGoertzel2007-37\">[37]</a></sup> as an approach to strong AI. <a href=\"/wiki/Neuroimaging\" title=\"Neuroimaging\">Neuroimaging</a> technologies that could deliver the necessary detailed understanding are improving rapidly, and <a href=\"/wiki/Futurist\" title=\"Futurist\">futurist</a> Ray Kurzweil in the book <i>The Singularity Is Near</i><sup class=\"reference\" id=\"cite_ref-K_1-3\"><a href=\"#cite_note-K-1\">[1]</a></sup> predicts that a map of sufficient quality will become available on a similar timescale to the required computing power.\n</p>\n<h3><span class=\"mw-headline\" id=\"Early_estimates\">Early estimates</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=10\" title=\"Edit section: Early estimates\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<div class=\"thumb tright\"><div class=\"thumbinner\" style=\"width:402px;\"><a class=\"image\" href=\"/wiki/File:Estimations_of_Human_Brain_Emulation_Required_Performance.svg\"><img alt=\"\" class=\"thumbimage\" data-file-height=\"600\" data-file-width=\"800\" decoding=\"async\" height=\"300\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/1/1e/Estimations_of_Human_Brain_Emulation_Required_Performance.svg/400px-Estimations_of_Human_Brain_Emulation_Required_Performance.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/1/1e/Estimations_of_Human_Brain_Emulation_Required_Performance.svg/600px-Estimations_of_Human_Brain_Emulation_Required_Performance.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/1/1e/Estimations_of_Human_Brain_Emulation_Required_Performance.svg/800px-Estimations_of_Human_Brain_Emulation_Required_Performance.svg.png 2x\" width=\"400\"/></a> <div class=\"thumbcaption\"><div class=\"magnify\"><a class=\"internal\" href=\"/wiki/File:Estimations_of_Human_Brain_Emulation_Required_Performance.svg\" title=\"Enlarge\"></a></div>Estimates of how much processing power is needed to emulate a human brain at various levels (from Ray Kurzweil, and <a href=\"/wiki/Anders_Sandberg\" title=\"Anders Sandberg\">Anders Sandberg</a> and <a href=\"/wiki/Nick_Bostrom\" title=\"Nick Bostrom\">Nick Bostrom</a>), along with the fastest supercomputer from <a href=\"/wiki/TOP500\" title=\"TOP500\">TOP500</a> mapped by year. Note the logarithmic scale and exponential trendline, which assumes the computational capacity doubles every 1.1 years. Kurzweil believes that mind uploading will be possible at neural simulation, while the Sandberg, Bostrom report is less certain about where <a href=\"/wiki/Consciousness\" title=\"Consciousness\">consciousness</a> arises.<sup class=\"reference\" id=\"cite_ref-FOOTNOTESandbergBoström2008_45-0\"><a href=\"#cite_note-FOOTNOTESandbergBoström2008-45\">[45]</a></sup></div></div></div><p> For low-level brain simulation, an extremely powerful computer would be required. The <a href=\"/wiki/Human_brain\" title=\"Human brain\">human brain</a> has a huge number of <a class=\"mw-redirect\" href=\"/wiki/Synapses\" title=\"Synapses\">synapses</a>. Each of the 10<sup>11</sup> (one hundred billion) <a class=\"mw-redirect\" href=\"/wiki/Neurons\" title=\"Neurons\">neurons</a> has on average 7,000 synaptic connections to other neurons. It has been estimated that the brain of a three-year-old child has about 10<sup>15</sup> synapses (1 quadrillion). This number declines with age, stabilizing by adulthood. Estimates vary for an adult, ranging from 10<sup>14</sup> to 5×10<sup>14</sup> synapses (100 to 500 trillion).<sup class=\"reference\" id=\"cite_ref-FOOTNOTEDrachman2005_46-0\"><a href=\"#cite_note-FOOTNOTEDrachman2005-46\">[46]</a></sup> An estimate of the brain's processing power, based on a simple switch model for neuron activity, is around 10<sup>14</sup> (100 trillion) synaptic updates per second (<a href=\"/wiki/SUPS\" title=\"SUPS\">SUPS</a>).<sup class=\"reference\" id=\"cite_ref-FOOTNOTERussellNorvig2003_47-0\"><a href=\"#cite_note-FOOTNOTERussellNorvig2003-47\">[47]</a></sup> In 1997 Kurzweil looked at various estimates for the hardware required to equal the human brain and adopted a figure of 10<sup>16</sup> computations per second (cps).<sup class=\"reference\" id=\"cite_ref-48\"><a href=\"#cite_note-48\">[48]</a></sup> (For comparison, if a \"computation\" was equivalent to one \"<a href=\"/wiki/FLOPS\" title=\"FLOPS\">floating point operation</a>\" –  a measure used to rate current <a href=\"/wiki/Supercomputer\" title=\"Supercomputer\">supercomputers</a> – then 10<sup>16</sup> \"computations\" would be equivalent to 10 <a href=\"/wiki/Peta-\" title=\"Peta-\">petaFLOPS</a>, <a href=\"/wiki/FLOPS#Records\" title=\"FLOPS\">achieved in 2011</a>). He used this figure to predict the necessary hardware would be available sometime between 2015 and 2025, if the exponential growth in computer power at the time of writing continued.\n</p><h3><span class=\"mw-headline\" id=\"Modelling_the_neurons_in_more_detail\">Modelling the neurons in more detail</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=11\" title=\"Edit section: Modelling the neurons in more detail\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>The <a href=\"/wiki/Artificial_neuron\" title=\"Artificial neuron\">artificial neuron</a> model assumed by Kurzweil and used in many current <a href=\"/wiki/Artificial_neural_network\" title=\"Artificial neural network\">artificial neural network</a> implementations is simple compared with <a href=\"/wiki/Biological_neuron_model\" title=\"Biological neuron model\">biological neurons</a>. A brain simulation would likely have to capture the detailed cellular behaviour of biological <a class=\"mw-redirect\" href=\"/wiki/Neurons\" title=\"Neurons\">neurons</a>, presently only understood in the broadest of outlines. The overhead introduced by full modeling of the biological, chemical, and physical details of neural behaviour (especially on a molecular scale) would require computational powers several orders of magnitude larger than Kurzweil's estimate.  In addition the estimates do not account for <a class=\"mw-redirect\" href=\"/wiki/Glial_cells\" title=\"Glial cells\">glial cells</a>, which are at least as numerous as neurons, and which may outnumber neurons by as much as 10:1, and are now known to play a role in cognitive processes.<sup class=\"reference\" id=\"cite_ref-Discover2011JanFeb_49-0\"><a href=\"#cite_note-Discover2011JanFeb-49\">[49]</a></sup>\n</p>\n<h3><span class=\"mw-headline\" id=\"Current_research\">Current research</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=12\" title=\"Edit section: Current research\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>There are some research projects that are investigating brain simulation using more sophisticated neural models, implemented on conventional computing architectures. The <a href=\"/wiki/Artificial_Intelligence_System\" title=\"Artificial Intelligence System\">Artificial Intelligence System</a> project implemented non-real time simulations of a \"brain\" (with 10<sup>11</sup> neurons) in 2005. It took 50 days on a cluster of 27 processors to simulate 1 second of a model.<sup class=\"reference\" id=\"cite_ref-50\"><a href=\"#cite_note-50\">[50]</a></sup> The <a class=\"mw-redirect\" href=\"/wiki/Blue_Brain\" title=\"Blue Brain\">Blue Brain</a> project used one of the fastest supercomputer architectures in the world, <a href=\"/wiki/IBM\" title=\"IBM\">IBM</a>'s <a class=\"mw-redirect\" href=\"/wiki/Blue_Gene\" title=\"Blue Gene\">Blue Gene</a> platform, to create a real time simulation of a single rat <a href=\"/wiki/Neocortex\" title=\"Neocortex\">neocortical column</a> consisting of approximately 10,000 neurons and 10<sup>8</sup> synapses in 2006.<sup class=\"reference\" id=\"cite_ref-51\"><a href=\"#cite_note-51\">[51]</a></sup> A longer term goal is to build a detailed, functional simulation of the physiological processes in the human brain: \"It is not impossible to build a human brain and we can do it in 10 years,\" <a href=\"/wiki/Henry_Markram\" title=\"Henry Markram\">Henry Markram</a>, director of the Blue Brain Project said in 2009 at the <a href=\"/wiki/TED_(conference)\" title=\"TED (conference)\">TED conference</a> in Oxford.<sup class=\"reference\" id=\"cite_ref-52\"><a href=\"#cite_note-52\">[52]</a></sup> There have also been controversial claims to have simulated a <a href=\"/wiki/Cat_intelligence#Computer_simulation_of_the_cat_brain\" title=\"Cat intelligence\">cat brain</a>. Neuro-silicon interfaces have been proposed as an alternative implementation strategy that may scale better.<sup class=\"reference\" id=\"cite_ref-53\"><a href=\"#cite_note-53\">[53]</a></sup>\n</p><p><a href=\"/wiki/Hans_Moravec\" title=\"Hans Moravec\">Hans Moravec</a> addressed the above arguments (\"brains are more complicated\", \"neurons have to be modeled in more detail\") in his 1997 paper \"When will computer hardware match the human brain?\".<sup class=\"reference\" id=\"cite_ref-54\"><a href=\"#cite_note-54\">[54]</a></sup>  He measured the ability of existing software to simulate the functionality of neural tissue, specifically the retina.  His results do not depend on the number of glial cells, nor on what kinds of processing neurons perform where.\n</p><p>The actual complexity of modeling biological neurons has been explored in <a href=\"/wiki/OpenWorm\" title=\"OpenWorm\">OpenWorm project</a>  that was aimed on complete simulation of a worm that only has 302 neurons in its neural network (among about 1000 cells in total). The animal's neural network has been well documented prior start of the project. However the task seemed simple at the beginning, models based on generic neural network didn't work. Currently the efforts are focused on precise emulation of the biological neurons (partly on molecular level), but the result can't be called a total success yet. Even if the number of issues to be solved in a human-brain-scale model is not proportional to the number of neurons, the amount of work along this path is obvious.\n</p>\n<h3><span id=\"Complications_of_and_criticisms_to_AI_approaches.2C_based_on_simulation\"></span><span class=\"mw-headline\" id=\"Complications_of_and_criticisms_to_AI_approaches,_based_on_simulation\">Complications of and criticisms to AI approaches, based on simulation</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=13\" title=\"Edit section: Complications of and criticisms to AI approaches, based on simulation\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>A fundamental criticism of the simulated brain approach derives from <a href=\"/wiki/Embodied_cognition\" title=\"Embodied cognition\">embodied cognition</a> where human embodiment is taken as an essential aspect of human intelligence. Many researchers believe that embodiment is necessary to ground meaning.<sup class=\"reference\" id=\"cite_ref-55\"><a href=\"#cite_note-55\">[55]</a></sup> If this view is correct, any fully functional brain model will need to encompass more than just the neurons (i.e., a robotic body). Goertzel<sup class=\"reference\" id=\"cite_ref-FOOTNOTEGoertzel2007_37-2\"><a href=\"#cite_note-FOOTNOTEGoertzel2007-37\">[37]</a></sup> proposes virtual embodiment (like <a href=\"/wiki/Second_Life\" title=\"Second Life\">Second Life</a>), but it is not yet known whether this would be sufficient.\n</p><p>Desktop computers using microprocessors capable of more than 10<sup>9</sup> cps (Kurzweil's non-standard unit \"computations per second\", see above) have been available since 2005. According to the brain power estimates used by Kurzweil (and Moravec), this computer should be capable of supporting a simulation of a bee brain, but despite some interest<sup class=\"reference\" id=\"cite_ref-56\"><a href=\"#cite_note-56\">[56]</a></sup> no such simulation exists<sup class=\"noprint Inline-Template Template-Fact\" style=\"white-space:nowrap;\">[<i><a href=\"/wiki/Wikipedia:Citation_needed\" title=\"Wikipedia:Citation needed\"><span title=\"This claim needs references to reliable sources. (April 2011)\">citation needed</span></a></i>]</sup>. There are at least three reasons for this:\n</p>\n<ul><li>Firstly, the neuron model seems to be oversimplified (see next section).</li>\n<li>Secondly, there is insufficient understanding of higher cognitive processes<sup class=\"reference\" id=\"cite_ref-57\"><a href=\"#cite_note-57\">[57]</a></sup> to establish accurately what the brain's neural activity, observed using techniques such as <a href=\"/wiki/Neuroimaging#Functional_magnetic_resonance_imaging\" title=\"Neuroimaging\">functional magnetic resonance imaging</a>, correlates with.</li>\n<li>Thirdly, even if our understanding of cognition advances sufficiently, early simulation programs are likely to be very inefficient and will, therefore, need considerably more hardware.</li>\n<li>Fourthly, the brain of an organism, while critical, may not be an appropriate boundary for a cognitive model.  To simulate a bee brain, it may be necessary to simulate the body, and the environment. <a href=\"/wiki/The_Extended_Mind\" title=\"The Extended Mind\">The Extended Mind</a> thesis formalizes the philosophical concept, and research into <a class=\"mw-redirect\" href=\"/wiki/Cephalopoda\" title=\"Cephalopoda\">cephalopods</a> has demonstrated clear examples of a decentralized system.<sup class=\"reference\" id=\"cite_ref-58\"><a href=\"#cite_note-58\">[58]</a></sup></li></ul>\n<p>In addition, the scale of the human brain is not currently well-constrained. One estimate puts the human brain at about 100 billion neurons and 100 trillion synapses.<sup class=\"reference\" id=\"cite_ref-59\"><a href=\"#cite_note-59\">[59]</a></sup><sup class=\"reference\" id=\"cite_ref-60\"><a href=\"#cite_note-60\">[60]</a></sup> Another estimate is 86 billion neurons of which 16.3 billion are in the <a href=\"/wiki/Cerebral_cortex\" title=\"Cerebral cortex\">cerebral cortex</a> and 69 billion in the <a href=\"/wiki/Cerebellum\" title=\"Cerebellum\">cerebellum</a>.<sup class=\"reference\" id=\"cite_ref-FOOTNOTEAzevedo_et_al.2009_61-0\"><a href=\"#cite_note-FOOTNOTEAzevedo_et_al.2009-61\">[61]</a></sup> <a class=\"mw-redirect\" href=\"/wiki/Glial_cell\" title=\"Glial cell\">Glial cell</a> synapses are currently unquantified but are known to be extremely numerous.\n</p>\n<h2><span class=\"mw-headline\" id=\"Artificial_consciousness_research\">Artificial consciousness research</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=14\" title=\"Edit section: Artificial consciousness research\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<div class=\"hatnote navigation-not-searchable\" role=\"note\">Main article: <a href=\"/wiki/Artificial_consciousness\" title=\"Artificial consciousness\">Artificial consciousness</a></div>\n<p>Although the role of consciousness in strong AI/AGI is debatable, many AGI researchers<sup class=\"reference\" id=\"cite_ref-FOOTNOTEYudkowsky2006_62-0\"><a href=\"#cite_note-FOOTNOTEYudkowsky2006-62\">[62]</a></sup> regard research that investigates possibilities for implementing consciousness as vital. In an early effort <a href=\"/wiki/Igor_Aleksander\" title=\"Igor Aleksander\">Igor Aleksander</a><sup class=\"reference\" id=\"cite_ref-FOOTNOTEAleksander1996_63-0\"><a href=\"#cite_note-FOOTNOTEAleksander1996-63\">[63]</a></sup> argued that the principles for creating a conscious machine already existed but that it would take forty years to train such a machine to understand <a href=\"/wiki/Language\" title=\"Language\">language</a>.\n</p>\n<h2><span id=\"Relationship_to_.22strong_AI.22\"></span><span class=\"mw-headline\" id='Relationship_to_\"strong_AI\"'>Relationship to \"strong AI\"</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=15\" title='Edit section: Relationship to \"strong AI\"'>edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<div class=\"hatnote navigation-not-searchable\" role=\"note\">See also: <a href=\"/wiki/Philosophy_of_artificial_intelligence\" title=\"Philosophy of artificial intelligence\">philosophy of artificial intelligence</a> and <a href=\"/wiki/Chinese_room\" title=\"Chinese room\">Chinese room</a></div>\n<p>In 1980, philosopher <a href=\"/wiki/John_Searle\" title=\"John Searle\">John Searle</a> coined the term \"strong AI\" as part of his <a href=\"/wiki/Chinese_room\" title=\"Chinese room\">Chinese room</a> argument.<sup class=\"reference\" id=\"cite_ref-64\"><a href=\"#cite_note-64\">[64]</a></sup> He wanted to distinguish between two different hypotheses about artificial intelligence:<sup class=\"reference\" id=\"cite_ref-65\"><a href=\"#cite_note-65\">[65]</a></sup>\n</p>\n<ul><li>An artificial intelligence system can <i>think</i> and have a <i>mind</i>.  (The word \"mind\" has a specific meaning for philosophers, as used in \"the <a class=\"mw-redirect\" href=\"/wiki/Mind_body_problem\" title=\"Mind body problem\">mind body problem</a>\" or \"the <a href=\"/wiki/Philosophy_of_mind\" title=\"Philosophy of mind\">philosophy of mind</a>\".)</li>\n<li>An artificial intelligence system can (only) <i>act like</i> it thinks and has a mind.</li></ul>\n<p>The first one is called \"the <i>strong</i> AI hypothesis\" and the second is \"the <i>weak</i> AI hypothesis\" because the first one makes the <i>stronger</i> statement: it assumes something special has happened to the machine that goes beyond all its abilities that we can test. Searle referred to the \"strong AI hypothesis\" as \"strong AI\". This usage is also common in academic AI research and textbooks.<sup class=\"reference\" id=\"cite_ref-66\"><a href=\"#cite_note-66\">[66]</a></sup>\n</p><p>The weak AI hypothesis is equivalent to the hypothesis that artificial general intelligence is possible. According to <a href=\"/wiki/Stuart_J._Russell\" title=\"Stuart J. Russell\">Russell</a> and <a href=\"/wiki/Peter_Norvig\" title=\"Peter Norvig\">Norvig</a>, \"Most AI researchers take the weak AI hypothesis for granted, and don't care about the strong AI hypothesis.\"<sup class=\"reference\" id=\"cite_ref-FOOTNOTERussellNorvig2003947_67-0\"><a href=\"#cite_note-FOOTNOTERussellNorvig2003947-67\">[67]</a></sup>\n</p><p>In contrast to Searle, Kurzweil uses the term \"strong AI\" to describe any artificial intelligence system that acts like it has a mind,<sup class=\"reference\" id=\"cite_ref-K_1-4\"><a href=\"#cite_note-K-1\">[1]</a></sup> regardless of whether a philosopher would be able to determine if it <i>actually</i> has a mind or not.\n</p>\n<h2><span class=\"mw-headline\" id=\"Possible_explanations_for_the_slow_progress_of_AI_research\">Possible explanations for the slow progress of AI research</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=16\" title=\"Edit section: Possible explanations for the slow progress of AI research\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<div class=\"hatnote navigation-not-searchable\" role=\"note\">See also: <a href=\"/wiki/History_of_artificial_intelligence#The_problems\" title=\"History of artificial intelligence\">History of artificial intelligence § The problems</a></div>\n<p>Since the launch of AI research in 1956, the growth of this field has slowed down over time and has stalled the aims of creating machines skilled with intelligent action at the human level.<sup class=\"reference\" id=\"cite_ref-FOOTNOTEClocksin2003_68-0\"><a href=\"#cite_note-FOOTNOTEClocksin2003-68\">[68]</a></sup> A possible explanation for this delay is that computers lack a sufficient scope of memory or processing power.<sup class=\"reference\" id=\"cite_ref-FOOTNOTEClocksin2003_68-1\"><a href=\"#cite_note-FOOTNOTEClocksin2003-68\">[68]</a></sup> In addition, the level of complexity that connects to the process of AI research may also limit the progress of AI research.<sup class=\"reference\" id=\"cite_ref-FOOTNOTEClocksin2003_68-2\"><a href=\"#cite_note-FOOTNOTEClocksin2003-68\">[68]</a></sup>\n</p><p>While most AI researchers believe strong AI can be achieved in the future, there are some individuals like <a href=\"/wiki/Hubert_Dreyfus\" title=\"Hubert Dreyfus\">Hubert Dreyfus</a> and <a href=\"/wiki/Roger_Penrose\" title=\"Roger Penrose\">Roger Penrose</a> who deny the possibility of achieving strong AI.<sup class=\"reference\" id=\"cite_ref-FOOTNOTEClocksin2003_68-3\"><a href=\"#cite_note-FOOTNOTEClocksin2003-68\">[68]</a></sup> <a href=\"/wiki/John_McCarthy_(computer_scientist)\" title=\"John McCarthy (computer scientist)\">John McCarthy</a> was one of various computer scientists who believe human-level AI will be accomplished, but a date cannot accurately be predicted.<sup class=\"reference\" id=\"cite_ref-FOOTNOTEMcCarthy2003_69-0\"><a href=\"#cite_note-FOOTNOTEMcCarthy2003-69\">[69]</a></sup>\n</p><p>Conceptual limitations are another possible reason for the slowness in AI research.<sup class=\"reference\" id=\"cite_ref-FOOTNOTEClocksin2003_68-4\"><a href=\"#cite_note-FOOTNOTEClocksin2003-68\">[68]</a></sup> AI researchers may need to modify the conceptual framework of their discipline in order to provide a stronger base and contribution to the quest of achieving strong AI. As William Clocksin wrote in 2003: \"the framework starts from Weizenbaum’s observation that intelligence manifests itself only relative to specific social and cultural contexts\".<sup class=\"reference\" id=\"cite_ref-FOOTNOTEClocksin2003_68-5\"><a href=\"#cite_note-FOOTNOTEClocksin2003-68\">[68]</a></sup>\n</p><p>Furthermore, AI researchers have been able to create computers that can perform jobs that are complicated for people to do, but conversely they have struggled to develop a computer that is capable of carrying out tasks that are simple for humans to do<sup class=\"noprint Inline-Template\" style=\"white-space:nowrap;\">[<i><a class=\"mw-redirect\" href=\"/wiki/Wikipedia:AUDIENCE\" title=\"Wikipedia:AUDIENCE\"><span title=\"An editor has requested that an example be provided. (September 2017)\">example  needed</span></a></i>]</sup>.<sup class=\"reference\" id=\"cite_ref-FOOTNOTEClocksin2003_68-6\"><a href=\"#cite_note-FOOTNOTEClocksin2003-68\">[68]</a></sup> A problem described by David Gelernter is that some people assume thinking and reasoning are equivalent.<sup class=\"reference\" id=\"cite_ref-FOOTNOTEGelernter2010_70-0\"><a href=\"#cite_note-FOOTNOTEGelernter2010-70\">[70]</a></sup> However, the idea of whether thoughts and the creator of those thoughts are isolated individually has intrigued AI researchers.<sup class=\"reference\" id=\"cite_ref-FOOTNOTEGelernter2010_70-1\"><a href=\"#cite_note-FOOTNOTEGelernter2010-70\">[70]</a></sup>\n</p><p>The problems that have been encountered in AI research over the past decades have further impeded the progress of AI. The failed predictions that have been promised by AI researchers and the lack of a complete understanding of human behaviors have helped diminish the primary idea of human-level AI.<sup class=\"reference\" id=\"cite_ref-FOOTNOTEGoertzel2007_37-3\"><a href=\"#cite_note-FOOTNOTEGoertzel2007-37\">[37]</a></sup> Although the progress of AI research has brought both improvement and disappointment, most investigators have established optimism about potentially achieving the goal of AI in the 21st century.<sup class=\"reference\" id=\"cite_ref-FOOTNOTEGoertzel2007_37-4\"><a href=\"#cite_note-FOOTNOTEGoertzel2007-37\">[37]</a></sup>\n</p><p>Other possible reasons have been proposed for the lengthy research in the progress of strong AI. The intricacy of scientific problems and the need to fully understand the human brain through psychology and neurophysiology have limited many researchers from emulating the function of the human brain into a computer hardware.<sup class=\"reference\" id=\"cite_ref-FOOTNOTEMcCarthy2007_71-0\"><a href=\"#cite_note-FOOTNOTEMcCarthy2007-71\">[71]</a></sup> Many researchers tend to underestimate any doubt that is involved with future predictions of AI, but without taking those issues seriously can people then overlook solutions to problematic questions.<sup class=\"reference\" id=\"cite_ref-FOOTNOTEGoertzel2007_37-5\"><a href=\"#cite_note-FOOTNOTEGoertzel2007-37\">[37]</a></sup>\n</p><p>Clocksin says that a conceptual limitation that may impede the progress of AI research is that people may be using the wrong techniques for computer programs and implementation of equipment.<sup class=\"reference\" id=\"cite_ref-FOOTNOTEClocksin2003_68-7\"><a href=\"#cite_note-FOOTNOTEClocksin2003-68\">[68]</a></sup> When AI researchers first began to aim for the goal of artificial intelligence, a main interest was human reasoning.<sup class=\"reference\" id=\"cite_ref-FOOTNOTEHolteChoueiry2003_72-0\"><a href=\"#cite_note-FOOTNOTEHolteChoueiry2003-72\">[72]</a></sup> Researchers hoped to establish computational models of human knowledge through reasoning and to find out how to design a computer with a specific cognitive task.<sup class=\"reference\" id=\"cite_ref-FOOTNOTEHolteChoueiry2003_72-1\"><a href=\"#cite_note-FOOTNOTEHolteChoueiry2003-72\">[72]</a></sup>\n</p><p>The practice of abstraction, which people tend to redefine when working with a particular context in research, provides researchers with a concentration on just a few concepts.<sup class=\"reference\" id=\"cite_ref-FOOTNOTEHolteChoueiry2003_72-2\"><a href=\"#cite_note-FOOTNOTEHolteChoueiry2003-72\">[72]</a></sup> The most productive use of abstraction in AI research comes from planning and problem solving.<sup class=\"reference\" id=\"cite_ref-FOOTNOTEHolteChoueiry2003_72-3\"><a href=\"#cite_note-FOOTNOTEHolteChoueiry2003-72\">[72]</a></sup> Although the aim is to increase the speed of a computation, the role of abstraction has posed questions about the involvement of abstraction operators.<sup class=\"reference\" id=\"cite_ref-FOOTNOTEZucker2003_73-0\"><a href=\"#cite_note-FOOTNOTEZucker2003-73\">[73]</a></sup>\n</p><p>A possible reason for the slowness in AI relates to the acknowledgement by many AI researchers that heuristics is a section that contains a significant breach between computer performance and human performance.<sup class=\"reference\" id=\"cite_ref-FOOTNOTEMcCarthy2007_71-1\"><a href=\"#cite_note-FOOTNOTEMcCarthy2007-71\">[71]</a></sup> The specific functions that are programmed to a computer may be able to account for many of the requirements that allow it to match human intelligence. These explanations are not necessarily guaranteed to be the fundamental causes for the delay in achieving strong AI, but they are widely agreed by numerous researchers.\n</p><p>There have been many AI researchers that debate over the idea whether <a href=\"/wiki/Affective_computing\" title=\"Affective computing\">machines should be created with emotions</a>. There are no emotions in typical models of AI and some researchers say programming emotions into machines allows them to have a mind of their own.<sup class=\"reference\" id=\"cite_ref-FOOTNOTEClocksin2003_68-8\"><a href=\"#cite_note-FOOTNOTEClocksin2003-68\">[68]</a></sup> Emotion sums up the experiences of humans because it allows them to remember those experiences.<sup class=\"reference\" id=\"cite_ref-FOOTNOTEGelernter2010_70-2\"><a href=\"#cite_note-FOOTNOTEGelernter2010-70\">[70]</a></sup>  David Gelernter writes, \"No computer will be creative unless it can simulate all the nuances of human emotion.\"<sup class=\"reference\" id=\"cite_ref-FOOTNOTEGelernter2010_70-3\"><a href=\"#cite_note-FOOTNOTEGelernter2010-70\">[70]</a></sup> This concern about emotion has posed problems for AI researchers and it connects to the concept of strong AI as its research progresses into the future.\n</p>\n<h2><span class=\"mw-headline\" id=\"Consciousness\">Consciousness</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=17\" title=\"Edit section: Consciousness\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>There are other aspects of the human mind besides intelligence that are relevant to the concept of strong AI which play a major role in <a href=\"/wiki/Science_fiction\" title=\"Science fiction\">science fiction</a> and the <a href=\"/wiki/Ethics_of_artificial_intelligence\" title=\"Ethics of artificial intelligence\">ethics of artificial intelligence</a>:\n</p>\n<ul><li><a href=\"/wiki/Consciousness\" title=\"Consciousness\">consciousness</a>: To have <a href=\"/wiki/Qualia\" title=\"Qualia\">subjective experience</a> and <a href=\"/wiki/Thought\" title=\"Thought\">thought</a>.<sup class=\"reference\" id=\"cite_ref-74\"><a href=\"#cite_note-74\">[74]</a></sup></li>\n<li><a href=\"/wiki/Self-awareness\" title=\"Self-awareness\">self-awareness</a>: To be aware of oneself as a separate individual, especially to be aware of one's own thoughts.</li>\n<li><a href=\"/wiki/Sentience\" title=\"Sentience\">sentience</a>: The ability to \"feel\" perceptions or emotions subjectively.</li>\n<li><a class=\"mw-redirect\" href=\"/wiki/Sapience\" title=\"Sapience\">sapience</a>: The capacity for wisdom.</li></ul>\n<p>These traits have a moral dimension, because a machine with this form of strong AI may have legal rights, analogous to the <a href=\"/wiki/Animal_rights\" title=\"Animal rights\">rights of non-human animals</a>. Also, <a href=\"/wiki/Bill_Joy\" title=\"Bill Joy\">Bill Joy</a>, among others, argues a machine with these traits may be a threat to human life or dignity.<sup class=\"reference\" id=\"cite_ref-75\"><a href=\"#cite_note-75\">[75]</a></sup> It remains to be shown whether any of these traits are <a class=\"mw-redirect\" href=\"/wiki/Necessary_and_sufficient_condition\" title=\"Necessary and sufficient condition\">necessary</a> for strong AI. The role of <a href=\"/wiki/Consciousness\" title=\"Consciousness\">consciousness</a> is not clear, and currently there is no agreed test for its presence. If a machine is built with a device that simulates the <a href=\"/wiki/Neural_correlates_of_consciousness\" title=\"Neural correlates of consciousness\">neural correlates of consciousness</a>, would it automatically have self-awareness? It is also possible that some of these properties, such as sentience, <a href=\"/wiki/Emergence\" title=\"Emergence\">naturally emerge</a> from a fully intelligent machine, or that it becomes natural to <i>ascribe</i> these properties to machines once they begin to act in a way that is clearly intelligent. For example, intelligent action may be sufficient for sentience, rather than the other way around.\n</p><p>In science fiction, AGI is associated with traits such as <a href=\"/wiki/Consciousness\" title=\"Consciousness\">consciousness</a>, <a href=\"/wiki/Sentience\" title=\"Sentience\">sentience</a>, <a class=\"mw-redirect\" href=\"/wiki/Sapience\" title=\"Sapience\">sapience</a>, and <a href=\"/wiki/Self-awareness\" title=\"Self-awareness\">self-awareness</a> observed in living beings. However, according to philosopher <a href=\"/wiki/John_Searle\" title=\"John Searle\">John Searle</a>, it is an open question whether general intelligence is sufficient for consciousness. \"Strong AI\" (as defined above by <a href=\"/wiki/Ray_Kurzweil\" title=\"Ray Kurzweil\">Ray Kurzweil</a>) should not be confused with Searle's \"<a class=\"mw-redirect\" href=\"/wiki/Strong_AI_hypothesis\" title=\"Strong AI hypothesis\">strong AI hypothesis</a>.\" The strong AI hypothesis is the claim that a computer which behaves as intelligently as a person must also necessarily have a <a href=\"/wiki/Mind\" title=\"Mind\">mind</a> and <a href=\"/wiki/Consciousness\" title=\"Consciousness\">consciousness</a>. AGI refers only to the amount of intelligence that the machine displays, with or without a mind.\n</p>\n<h2><span class=\"mw-headline\" id=\"Controversies_and_dangers\">Controversies and dangers</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=18\" title=\"Edit section: Controversies and dangers\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<h3><span class=\"mw-headline\" id=\"Feasibility\">Feasibility</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=19\" title=\"Edit section: Feasibility\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<table class=\"box-Expand_section plainlinks metadata ambox mbox-small-left ambox-content\" role=\"presentation\"><tbody><tr><td class=\"mbox-image\"><a class=\"image\" href=\"/wiki/File:Wiki_letter_w_cropped.svg\"><img alt=\"[icon]\" data-file-height=\"31\" data-file-width=\"44\" decoding=\"async\" height=\"14\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Wiki_letter_w_cropped.svg/20px-Wiki_letter_w_cropped.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Wiki_letter_w_cropped.svg/30px-Wiki_letter_w_cropped.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Wiki_letter_w_cropped.svg/40px-Wiki_letter_w_cropped.svg.png 2x\" width=\"20\"/></a></td><td class=\"mbox-text\"><div class=\"mbox-text-span\">This section <b>needs expansion</b>. <small>You can help by <a class=\"external text\" href=\"//en.wikipedia.org/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=\">adding to it</a>.</small> <small class=\"date-container\"><i>(<span class=\"date\">February 2016</span>)</i></small></div></td></tr></tbody></table>\n<p>Opinions vary both on <i>whether</i> and <i>when</i> artificial general intelligence will arrive. At one extreme, AI pioneer <a href=\"/wiki/Herbert_A._Simon\" title=\"Herbert A. Simon\">Herbert A. Simon</a> wrote in 1965: \"machines will be capable, within twenty years, of doing any work a man can do\". However, this prediction failed to come true. Microsoft co-founder <a href=\"/wiki/Paul_Allen\" title=\"Paul Allen\">Paul Allen</a> believed that such intelligence is unlikely in the 21st century because it would require \"unforeseeable and fundamentally unpredictable breakthroughs\" and a \"scientifically deep understanding of cognition\".<sup class=\"reference\" id=\"cite_ref-76\"><a href=\"#cite_note-76\">[76]</a></sup> Writing in <a href=\"/wiki/The_Guardian\" title=\"The Guardian\">The Guardian</a>, roboticist Alan Winfield claimed the gulf between modern computing and human-level artificial intelligence is as wide as the gulf between current space flight and practical faster-than-light spaceflight.<sup class=\"reference\" id=\"cite_ref-77\"><a href=\"#cite_note-77\">[77]</a></sup> AI experts' views on the feasibility of AGI wax and wane, and may have seen a resurgence in the 2010s. Four polls conducted in 2012 and 2013 suggested that the median guess among experts for when they'd be 50% confident AGI would arrive was 2040 to 2050, depending on the poll, with the mean being 2081. It is also interesting to note 16.5% of the experts answered with \"never\" when asked the same question but with a 90% confidence instead.<sup class=\"reference\" id=\"cite_ref-new_yorker_doomsday_78-0\"><a href=\"#cite_note-new_yorker_doomsday-78\">[78]</a></sup><sup class=\"reference\" id=\"cite_ref-79\"><a href=\"#cite_note-79\">[79]</a></sup>\nFurther current AGI progress considerations could found below <a href=\"#Tests_for_confirming_human-level_AGI\">#Tests_for_confirming_human-level_AGI</a> or <a href=\"#IQ-Tests_AGI\">#IQ-Tests_AGI</a>. \n</p>\n<h3><span class=\"mw-headline\" id=\"Potential_threat_to_human_existence\">Potential threat to human existence<span id=\"Risk_of_human_extinction\"></span></span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=20\" title=\"Edit section: Potential threat to human existence\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<div class=\"hatnote navigation-not-searchable\" role=\"note\">Main article: <a href=\"/wiki/Existential_risk_from_artificial_general_intelligence\" title=\"Existential risk from artificial general intelligence\">Existential risk from artificial general intelligence</a></div>\n<div class=\"hatnote navigation-not-searchable\" role=\"note\">See also: <a href=\"/wiki/Technological_singularity\" title=\"Technological singularity\">Technological singularity</a></div>\n<p>The creation of artificial general intelligence may have repercussions so great and so complex that it may not be possible to forecast what will come afterwards.  Thus the event in the hypothetical future of achieving strong AI is called the <a href=\"/wiki/Technological_singularity\" title=\"Technological singularity\">technological singularity</a>, because theoretically one cannot see past it.  But this has not stopped philosophers and researchers from guessing what the smart computers or robots of the future may do, including forming a utopia by <a href=\"/wiki/Friendly_artificial_intelligence\" title=\"Friendly artificial intelligence\">being our friends</a> or overwhelming us in an <a href=\"/wiki/AI_takeover\" title=\"AI takeover\">AI takeover</a>. The latter potentiality is particularly disturbing as it poses an <a class=\"mw-redirect\" href=\"/wiki/Existential_risk_from_advanced_artificial_intelligence\" title=\"Existential risk from advanced artificial intelligence\">existential risk for mankind</a>.\n</p>\n<h4><span class=\"mw-headline\" id=\"Self-replicating_machines\">Self-replicating machines</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=21\" title=\"Edit section: Self-replicating machines\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h4>\n<p>Smart computers or robots would be able to design and produce improved versions of themselves. <sup class=\"reference\" id=\"cite_ref-80\"><a href=\"#cite_note-80\">[80]</a></sup> A growing population of intelligent robots could conceivably out-compete inferior humans in job markets, in business, in science, in politics (pursuing <a class=\"mw-redirect\" href=\"/wiki/Robot_rights\" title=\"Robot rights\">robot rights</a>), and technologically, sociologically (<a href=\"/wiki/Group_mind_(science_fiction)\" title=\"Group mind (science fiction)\">by acting as one</a>), and militarily. Even nowadays, many jobs have already been taken by intelligent machines. For example, robots for homes, health care, hotels, and restaurants have automated many parts of our lives: virtual bots turn customer service into self-service, big data AI applications are used to replace portfolio managers, and social robots such as <a href=\"/wiki/Pepper_(robot)\" title=\"Pepper (robot)\">Pepper</a> are used to replace human greeters for customer service purpose<sup class=\"reference\" id=\"cite_ref-81\"><a href=\"#cite_note-81\">[81]</a></sup>\n</p>\n<h4><span class=\"mw-headline\" id=\"Emergent_superintelligence\">Emergent superintelligence</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=22\" title=\"Edit section: Emergent superintelligence\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h4>\n<p>If research into strong AI produced sufficiently intelligent software, it would be able to reprogram and improve itself – a feature called \"recursive self-improvement\". It would then be even better at improving itself, and would probably continue doing so in a rapidly increasing cycle, leading to an <a class=\"mw-redirect\" href=\"/wiki/Intelligence_explosion\" title=\"Intelligence explosion\">intelligence explosion</a> and the emergence of <a href=\"/wiki/Superintelligence\" title=\"Superintelligence\">superintelligence</a>.  Such an intelligence would not have the limitations of human intellect, and might be able to invent or discover almost anything.\n</p><p>Hyper-intelligent software might not necessarily decide to support the continued existence of mankind, and might be extremely difficult to stop.<sup class=\"reference\" id=\"cite_ref-82\"><a href=\"#cite_note-82\">[82]</a></sup> This topic has also recently begun to be discussed in academic publications as a real source of <a class=\"mw-redirect\" href=\"/wiki/Risks_to_civilization,_humans,_and_planet_Earth\" title=\"Risks to civilization, humans, and planet Earth\">risks to civilization, humans, and planet Earth</a>.\n</p><p>One proposal to deal with this is to make sure that the first generally intelligent AI is a <a class=\"mw-redirect\" href=\"/wiki/Friendly_AI\" title=\"Friendly AI\">friendly AI</a> that would then endeavor to ensure that subsequently developed AIs were also nice to us. But friendly AI is harder to create than plain AGI, and therefore it is likely, in a race between the two, that non-friendly AI would be developed first. Also, there is no guarantee that friendly AI would remain friendly, or that its progeny would also all be good.<sup class=\"reference\" id=\"cite_ref-83\"><a href=\"#cite_note-83\">[83]</a></sup>\n</p>\n<h2><span class=\"mw-headline\" id=\"See_also\">See also</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=23\" title=\"Edit section: See also\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<div class=\"div-col columns column-width\" style=\"-moz-column-width: 30em; -webkit-column-width: 30em; column-width: 30em;\">\n<ul><li><a href=\"/wiki/Automated_machine_learning\" title=\"Automated machine learning\">Automated machine learning</a></li>\n<li><a href=\"/wiki/Machine_ethics\" title=\"Machine ethics\">Machine ethics</a></li>\n<li><a href=\"/wiki/Multi-task_learning\" title=\"Multi-task learning\">Multi-task learning</a></li>\n<li><a href=\"/wiki/Superintelligence:_Paths,_Dangers,_Strategies\" title=\"Superintelligence: Paths, Dangers, Strategies\">Superintelligence</a></li>\n<li><a href=\"/wiki/Nick_Bostrom\" title=\"Nick Bostrom\">Nick Bostrom</a></li>\n<li><a href=\"/wiki/Future_of_Humanity_Institute\" title=\"Future of Humanity Institute\">Future of Humanity Institute</a></li>\n<li><a href=\"/wiki/Outline_of_artificial_intelligence\" title=\"Outline of artificial intelligence\">Outline of artificial intelligence</a></li>\n<li><a href=\"/wiki/Artificial_brain\" title=\"Artificial brain\">Artificial brain</a></li>\n<li><a href=\"/wiki/Transfer_learning\" title=\"Transfer learning\">Transfer learning</a></li>\n<li><a href=\"/wiki/Outline_of_transhumanism\" title=\"Outline of transhumanism\">Outline of transhumanism</a></li>\n<li><a href=\"/wiki/General_game_playing\" title=\"General game playing\">General game playing</a></li>\n<li><a href=\"/wiki/Synthetic_intelligence\" title=\"Synthetic intelligence\">Synthetic intelligence</a></li>\n<li><a href=\"/wiki/Intelligence_amplification\" title=\"Intelligence amplification\">Intelligence amplification</a> (IA), the use of information technology in augmenting human intelligence instead of creating an external autonomous \"AGI\"</li></ul>\n</div>\n<h2><span class=\"mw-headline\" id=\"Notes\">Notes</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=24\" title=\"Edit section: Notes\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<div class=\"reflist columns references-column-width\" style=\"-moz-column-width: 30em; -webkit-column-width: 30em; column-width: 30em; list-style-type: decimal;\">\n<ol class=\"references\">\n<li id=\"cite_note-K-1\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-K_1-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-K_1-1\"><sup><i><b>b</b></i></sup></a> <a href=\"#cite_ref-K_1-2\"><sup><i><b>c</b></i></sup></a> <a href=\"#cite_ref-K_1-3\"><sup><i><b>d</b></i></sup></a> <a href=\"#cite_ref-K_1-4\"><sup><i><b>e</b></i></sup></a></span> <span class=\"reference-text\">(<a href=\"#CITEREFKurzweil2005\">Kurzweil 2005</a>, p. 260) or see <a class=\"external text\" href=\"http://crnano.typepad.com/crnblog/2005/08/advanced_human_.html\" rel=\"nofollow\">Advanced Human Intelligence</a> where he defines strong AI as \"machine intelligence with the full range of human intelligence.\"</span>\n</li>\n<li id=\"cite_note-2\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-2\">^</a></b></span> <span class=\"reference-text\"><a class=\"external text\" href=\"http://tedxtalks.ted.com/video/The-Age-of-Artificial-Intellige\" rel=\"nofollow\">The Age of Artificial Intelligence: George John at TEDxLondonBusinessSchool 2013</a></span>\n</li>\n<li id=\"cite_note-3\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-3\">^</a></b></span> <span class=\"reference-text\"><a href=\"#CITEREFNewellSimon1976\">Newell &amp; Simon 1976</a>. This is the term they use for \"human-level\" intelligence in the <a href=\"/wiki/Physical_symbol_system\" title=\"Physical symbol system\">physical symbol system</a> hypothesis.</span>\n</li>\n<li id=\"cite_note-4\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-4\">^</a></b></span> <span class=\"reference-text\">Encyclopædia Britannica <a class=\"external text\" href=\"http://www.britannica.com/eb/article-219086/artificial-intelligence\" rel=\"nofollow\">Strong AI, applied AI, and cognitive simulation</a> or Jack Copeland <a class=\"external text\" href=\"http://www.cs.usfca.edu/www.AlanTuring.net/turing_archive/pages/Reference%20Articles/what_is_AI/What%20is%20AI02.html\" rel=\"nofollow\">What is artificial intelligence?</a> on AlanTuring.net</span>\n</li>\n<li id=\"cite_note-5\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-5\">^</a></b></span> <span class=\"reference-text\"><a class=\"external text\" href=\"http://www.open2.net/nextbigthing/ai/ai_in_depth/in_depth.htm\" rel=\"nofollow\">The Open University on Strong and Weak AI</a></span>\n</li>\n<li id=\"cite_note-baum-6\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-baum_6-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-baum_6-1\"><sup><i><b>b</b></i></sup></a></span> <span class=\"reference-text\">Baum, Seth. \"A Survey of Artificial General Intelligence Projects for Ethics, Risk, and Policy.\" (2017)</span>\n</li>\n<li id=\"cite_note-7\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-7\">^</a></b></span> <span class=\"reference-text\">AI founder <a href=\"/wiki/John_McCarthy_(computer_scientist)\" title=\"John McCarthy (computer scientist)\">John McCarthy</a> writes: \"we cannot yet characterize in general what kinds of computational procedures we want to call intelligent.\" <cite class=\"citation web\"><a href=\"/wiki/John_McCarthy_(computer_scientist)\" title=\"John McCarthy (computer scientist)\">McCarthy, John</a> (2007). <a class=\"external text\" href=\"http://www-formal.stanford.edu/jmc/whatisai/node1.html\" rel=\"nofollow\">\"Basic Questions\"</a>. <a href=\"/wiki/Stanford_University\" title=\"Stanford University\">Stanford University</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Basic+Questions&amp;rft.pub=Stanford+University&amp;rft.date=2007&amp;rft.aulast=McCarthy&amp;rft.aufirst=John&amp;rft_id=http%3A%2F%2Fwww-formal.stanford.edu%2Fjmc%2Fwhatisai%2Fnode1.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><style data-mw-deduplicate=\"TemplateStyles:r879151008\">.mw-parser-output cite.citation{font-style:inherit}.mw-parser-output .citation q{quotes:\"\\\"\"\"\\\"\"\"'\"\"'\"}.mw-parser-output .citation .cs1-lock-free a{background:url(\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png\")no-repeat;background-position:right .1em center}.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:url(\"//upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Lock-gray-alt-2.svg/9px-Lock-gray-alt-2.svg.png\")no-repeat;background-position:right .1em center}.mw-parser-output .citation .cs1-lock-subscription a{background:url(\"//upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Lock-red-alt-2.svg/9px-Lock-red-alt-2.svg.png\")no-repeat;background-position:right .1em center}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration{color:#555}.mw-parser-output .cs1-subscription span,.mw-parser-output .cs1-registration span{border-bottom:1px dotted;cursor:help}.mw-parser-output .cs1-ws-icon a{background:url(\"//upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Wikisource-logo.svg/12px-Wikisource-logo.svg.png\")no-repeat;background-position:right .1em center}.mw-parser-output code.cs1-code{color:inherit;background:inherit;border:inherit;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;font-size:100%}.mw-parser-output .cs1-visible-error{font-size:100%}.mw-parser-output .cs1-maint{display:none;color:#33aa33;margin-left:0.3em}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration,.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left,.mw-parser-output .cs1-kern-wl-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right,.mw-parser-output .cs1-kern-wl-right{padding-right:0.2em}</style> (For a discussion of some definitions of intelligence used by <a href=\"/wiki/Artificial_intelligence\" title=\"Artificial intelligence\">artificial intelligence</a> researchers, see <a href=\"/wiki/Philosophy_of_artificial_intelligence\" title=\"Philosophy of artificial intelligence\">philosophy of artificial intelligence</a>.)</span>\n</li>\n<li id=\"cite_note-8\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-8\">^</a></b></span> <span class=\"reference-text\">\nThis list of intelligent traits is based on the topics covered by major AI textbooks, including:\n<a href=\"#CITEREFRussellNorvig2003\">Russell &amp; Norvig 2003</a>,\n<a href=\"#CITEREFLugerStubblefield2004\">Luger &amp; Stubblefield 2004</a>,\n<a href=\"#CITEREFPooleMackworthGoebel1998\">Poole, Mackworth &amp; Goebel 1998</a> and\n<a href=\"#CITEREFNilsson1998\">Nilsson 1998</a>.</span>\n</li>\n<li id=\"cite_note-9\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-9\">^</a></b></span> <span class=\"reference-text\">Pfeifer, R. and Bongard J. C., How the body shapes the way we think: a new view of intelligence (The MIT Press, 2007). <link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/><a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a> <a href=\"/wiki/Special:BookSources/0-262-16239-3\" title=\"Special:BookSources/0-262-16239-3\">0-262-16239-3</a></span>\n</li>\n<li id=\"cite_note-10\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-10\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">White, R. W. (1959). \"Motivation reconsidered: The concept of competence\". <i>Psychological Review</i>. <b>66</b> (5): 297–333. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a class=\"external text\" href=\"//doi.org/10.1037%2Fh0040934\" rel=\"nofollow\">10.1037/h0040934</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Psychological+Review&amp;rft.atitle=Motivation+reconsidered%3A+The+concept+of+competence&amp;rft.volume=66&amp;rft.issue=5&amp;rft.pages=297-333&amp;rft.date=1959&amp;rft_id=info%3Adoi%2F10.1037%2Fh0040934&amp;rft.aulast=White&amp;rft.aufirst=R.+W.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></span>\n</li>\n<li id=\"cite_note-11\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-11\">^</a></b></span> <span class=\"reference-text\"><a href=\"#CITEREFJohnson1987\">Johnson 1987</a></span>\n</li>\n<li id=\"cite_note-12\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-12\">^</a></b></span> <span class=\"reference-text\">deCharms, R. (1968). Personal causation. New York: Academic Press.</span>\n</li>\n<li id=\"cite_note-13\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-13\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation web\">Muehlhauser, Luke (2013-08-11). <a class=\"external text\" href=\"http://intelligence.org/2013/08/11/what-is-agi/\" rel=\"nofollow\">\"What is AGI?\"</a>. Machine Intelligence Research Institute<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">1 May</span> 2014</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=What+is+AGI%3F&amp;rft.pub=Machine+Intelligence+Research+Institute&amp;rft.date=2013-08-11&amp;rft.aulast=Muehlhauser&amp;rft.aufirst=Luke&amp;rft_id=http%3A%2F%2Fintelligence.org%2F2013%2F08%2F11%2Fwhat-is-agi%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></span>\n</li>\n<li id=\"cite_note-14\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-14\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Liu, Feng; Shi, Yong; Liu, Ying (2017). \"Intelligence Quotient and Intelligence Grade of Artificial Intelligence\". <i>Annals of Data Science</i>. <b>4</b> (2): 179–191. <a href=\"/wiki/ArXiv\" title=\"ArXiv\">arXiv</a>:<span class=\"cs1-lock-free\" title=\"Freely accessible\"><a class=\"external text\" href=\"//arxiv.org/abs/1709.10242\" rel=\"nofollow\">1709.10242</a></span>. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a class=\"external text\" href=\"//doi.org/10.1007%2Fs40745-017-0109-0\" rel=\"nofollow\">10.1007/s40745-017-0109-0</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Annals+of+Data+Science&amp;rft.atitle=Intelligence+Quotient+and+Intelligence+Grade+of+Artificial+Intelligence&amp;rft.volume=4&amp;rft.issue=2&amp;rft.pages=179-191&amp;rft.date=2017&amp;rft_id=info%3Aarxiv%2F1709.10242&amp;rft_id=info%3Adoi%2F10.1007%2Fs40745-017-0109-0&amp;rft.aulast=Liu&amp;rft.aufirst=Feng&amp;rft.au=Shi%2C+Yong&amp;rft.au=Liu%2C+Ying&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></span>\n</li>\n<li id=\"cite_note-15\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-15\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation web\"><a class=\"external text\" href=\"https://t3n.de/news/iq-kind-schlauer-google-ki-siri-864003\" rel=\"nofollow\">\"Google-KI doppelt so schlau wie Siri\"</a><span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2 January</span> 2019</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Google-KI+doppelt+so+schlau+wie+Siri&amp;rft_id=https%3A%2F%2Ft3n.de%2Fnews%2Fiq-kind-schlauer-google-ki-siri-864003&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></span>\n</li>\n<li id=\"cite_note-Shapiro92-16\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-Shapiro92_16-0\">^</a></b></span> <span class=\"reference-text\">Shapiro, Stuart C. (1992). <a class=\"external text\" href=\"http://www.cse.buffalo.edu/~shapiro/Papers/ai.pdf\" rel=\"nofollow\">Artificial Intelligence</a> In Stuart C. Shapiro (Ed.), <i>Encyclopedia of Artificial Intelligence</i> (Second Edition, pp. 54–57). New York: John Wiley. (Section 4 is on \"AI-Complete Tasks\".)</span>\n</li>\n<li id=\"cite_note-17\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-17\">^</a></b></span> <span class=\"reference-text\">Roman V. Yampolskiy. Turing Test as a Defining Feature of AI-Completeness. In Artificial Intelligence, Evolutionary Computation and Metaheuristics (AIECM) --In the footsteps of Alan Turing. Xin-She Yang (Ed.). pp. 3–17. (Chapter 1). Springer, London. 2013. <a class=\"external free\" href=\"http://cecs.louisville.edu/ry/TuringTestasaDefiningFeature04270003.pdf\" rel=\"nofollow\">http://cecs.louisville.edu/ry/TuringTestasaDefiningFeature04270003.pdf</a></span>\n</li>\n<li id=\"cite_note-18\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-18\">^</a></b></span> <span class=\"reference-text\">Luis von Ahn, Manuel Blum, Nicholas Hopper, and John Langford. <a class=\"external text\" href=\"http://www.captcha.net/captcha_crypt.pdf\" rel=\"nofollow\">CAPTCHA: Using Hard AI Problems for Security</a>. In Proceedings of Eurocrypt, Vol. 2656 (2003), pp. 294–311.</span>\n</li>\n<li id=\"cite_note-19\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-19\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Bergmair, Richard (January 7, 2006). \"Natural Language Steganography and an \"AI-complete\" Security Primitive\". <a href=\"/wiki/CiteSeerX\" title=\"CiteSeerX\">CiteSeerX</a> <span class=\"cs1-lock-free\" title=\"Freely accessible\"><a class=\"external text\" href=\"//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.105.129\" rel=\"nofollow\">10.1.1.105.129</a></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Natural+Language+Steganography+and+an+%22AI-complete%22+Security+Primitive&amp;rft.date=2006-01-07&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.105.129&amp;rft.aulast=Bergmair&amp;rft.aufirst=Richard&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/> (unpublished?)</span>\n</li>\n<li id=\"cite_note-20\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-20\">^</a></b></span> <span class=\"reference-text\"><a href=\"#CITEREFCrevier1993\">Crevier 1993</a>, pp. 48–50</span>\n</li>\n<li id=\"cite_note-21\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-21\">^</a></b></span> <span class=\"reference-text\"><a href=\"#CITEREFSimon1965\">Simon 1965</a>, p. 96 quoted in <a href=\"#CITEREFCrevier1993\">Crevier 1993</a>, p. 109</span>\n</li>\n<li id=\"cite_note-22\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-22\">^</a></b></span> <span class=\"reference-text\"><a class=\"external text\" href=\"http://mitpress.mit.edu/e-books/Hal/chap2/two1.html\" rel=\"nofollow\">Scientist on the Set: An Interview with Marvin Minsky</a></span>\n</li>\n<li id=\"cite_note-23\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-23\">^</a></b></span> <span class=\"reference-text\">Marvin Minsky to <a href=\"#CITEREFDarrach1970\">Darrach (1970)</a>, quoted in <a href=\"#CITEREFCrevier1993\">Crevier (1993</a>, p. 109).</span>\n</li>\n<li id=\"cite_note-24\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-24\">^</a></b></span> <span class=\"reference-text\">The <a href=\"/wiki/Lighthill_report\" title=\"Lighthill report\">Lighthill report</a> specifically criticized AI's \"grandiose objectives\" and led the dismantling of AI research in England. (<a href=\"#CITEREFLighthill1973\">Lighthill 1973</a>; <a href=\"#CITEREFHowe1994\">Howe 1994</a>) In the U.S., <a href=\"/wiki/DARPA\" title=\"DARPA\">DARPA</a> became determined to fund only \"mission-oriented direct research, rather than basic undirected research\". See (<a href=\"#CITEREFNRC1999\">NRC 1999</a>) under \"Shift to Applied Research Increases Investment\". See also (<a href=\"#CITEREFCrevier1993\">Crevier 1993</a>, pp. 115–117) and (<a href=\"#CITEREFRussellNorvig2003\">Russell &amp; Norvig 2003</a>, pp. 21–22)</span>\n</li>\n<li id=\"cite_note-25\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-25\">^</a></b></span> <span class=\"reference-text\"><a href=\"#CITEREFCrevier1993\">Crevier 1993</a>, pp. 211, <a href=\"#CITEREFRussellNorvig2003\">Russell &amp; Norvig 2003</a>, p. 24 and see also <a href=\"#CITEREFFeigenbaumMcCorduck1983\">Feigenbaum &amp; McCorduck 1983</a></span>\n</li>\n<li id=\"cite_note-26\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-26\">^</a></b></span> <span class=\"reference-text\"><a href=\"#CITEREFCrevier1993\">Crevier 1993</a>, pp. 161–162,197–203,240; <a href=\"#CITEREFRussellNorvig2003\">Russell &amp; Norvig 2003</a>, p. 25; <a href=\"#CITEREFNRC1999\">NRC 1999</a>, under \"Shift to Applied Research Increases Investment\"</span>\n</li>\n<li id=\"cite_note-27\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-27\">^</a></b></span> <span class=\"reference-text\"><a href=\"#CITEREFCrevier1993\">Crevier 1993</a>, pp. 209–212</span>\n</li>\n<li id=\"cite_note-28\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-28\">^</a></b></span> <span class=\"reference-text\">As AI founder <a href=\"/wiki/John_McCarthy_(computer_scientist)\" title=\"John McCarthy (computer scientist)\">John McCarthy</a> writes \"it would be a great relief to the rest of the workers in AI if the inventors of new general formalisms would express their hopes in a more guarded form than has sometimes been the case.\" <cite class=\"citation web\"><a href=\"/wiki/John_McCarthy_(computer_scientist)\" title=\"John McCarthy (computer scientist)\">McCarthy, John</a> (2000). <a class=\"external text\" href=\"http://www-formal.stanford.edu/jmc/reviews/lighthill/lighthill.html\" rel=\"nofollow\">\"Reply to Lighthill\"</a>. Stanford University.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Reply+to+Lighthill&amp;rft.pub=Stanford+University&amp;rft.date=2000&amp;rft.aulast=McCarthy&amp;rft.aufirst=John&amp;rft_id=http%3A%2F%2Fwww-formal.stanford.edu%2Fjmc%2Freviews%2Flighthill%2Flighthill.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></span>\n</li>\n<li id=\"cite_note-29\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-29\">^</a></b></span> <span class=\"reference-text\">\"At its low point, some computer scientists and software engineers avoided the term artificial intelligence for fear of being viewed as wild-eyed dreamers.\"<cite class=\"citation news\">Markoff, John (2005-10-14). <a class=\"external text\" href=\"https://www.nytimes.com/2005/10/14/technology/14artificial.html?ei=5070&amp;en=11ab55edb7cead5e&amp;ex=1185940800&amp;adxnnl=1&amp;adxnnlx=1185805173-o7WsfW7qaP0x5/NUs1cQCQ\" rel=\"nofollow\">\"Behind Artificial Intelligence, a Squadron of Bright Real People\"</a>. The New York Times<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2007-07-30</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Behind+Artificial+Intelligence%2C+a+Squadron+of+Bright+Real+People&amp;rft.date=2005-10-14&amp;rft.aulast=Markoff&amp;rft.aufirst=John&amp;rft_id=https%3A%2F%2Fwww.nytimes.com%2F2005%2F10%2F14%2Ftechnology%2F14artificial.html%3Fei%3D5070%26en%3D11ab55edb7cead5e%26ex%3D1185940800%26adxnnl%3D1%26adxnnlx%3D1185805173-o7WsfW7qaP0x5%2FNUs1cQCQ&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></span>\n</li>\n<li id=\"cite_note-30\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-30\">^</a></b></span> <span class=\"reference-text\"><a href=\"#CITEREFRussellNorvig2003\">Russell &amp; Norvig 2003</a>, pp. 25–26</span>\n</li>\n<li id=\"cite_note-31\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-31\">^</a></b></span> <span class=\"reference-text\"><a href=\"#CITEREFMoravec1988\">Moravec 1988</a>, p. 20</span>\n</li>\n<li id=\"cite_note-32\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-32\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Harnad, S (1990). \"The Symbol Grounding Problem\". <i>Physica D</i>. <b>42</b> (1–3): 335–346. <a href=\"/wiki/ArXiv\" title=\"ArXiv\">arXiv</a>:<span class=\"cs1-lock-free\" title=\"Freely accessible\"><a class=\"external text\" href=\"//arxiv.org/abs/cs/9906002\" rel=\"nofollow\">cs/9906002</a></span>. <a href=\"/wiki/Bibcode\" title=\"Bibcode\">Bibcode</a>:<a class=\"external text\" href=\"http://adsabs.harvard.edu/abs/1990PhyD...42..335H\" rel=\"nofollow\">1990PhyD...42..335H</a>. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a class=\"external text\" href=\"//doi.org/10.1016%2F0167-2789%2890%2990087-6\" rel=\"nofollow\">10.1016/0167-2789(90)90087-6</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Physica+D&amp;rft.atitle=The+Symbol+Grounding+Problem&amp;rft.volume=42&amp;rft.issue=1%E2%80%933&amp;rft.pages=335-346&amp;rft.date=1990&amp;rft_id=info%3Aarxiv%2Fcs%2F9906002&amp;rft_id=info%3Adoi%2F10.1016%2F0167-2789%2890%2990087-6&amp;rft_id=info%3Abibcode%2F1990PhyD...42..335H&amp;rft.aulast=Harnad&amp;rft.aufirst=S&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></span>\n</li>\n<li id=\"cite_note-FOOTNOTEGoertzelPennachin2006-33\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-FOOTNOTEGoertzelPennachin2006_33-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-FOOTNOTEGoertzelPennachin2006_33-1\"><sup><i><b>b</b></i></sup></a></span> <span class=\"reference-text\"><a href=\"#CITEREFGoertzelPennachin2006\">Goertzel &amp; Pennachin 2006</a>.</span>\n</li>\n<li id=\"cite_note-34\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-34\">^</a></b></span> <span class=\"reference-text\"><a href=\"#CITEREFGubrud1997\">Gubrud 1997</a></span>\n</li>\n<li id=\"cite_note-35\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-35\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation web\"><a class=\"external text\" href=\"http://goertzel.org/who-coined-the-term-agi/\" rel=\"nofollow\">\"Who coined the term \"AGI\"? » goertzel.org\"</a><span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2018-12-28</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Who+coined+the+term+%22AGI%22%3F+%C2%BB+goertzel.org&amp;rft_id=http%3A%2F%2Fgoertzel.org%2Fwho-coined-the-term-agi%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/>, via <a href=\"/wiki/Life_3.0\" title=\"Life 3.0\">Life 3.0</a>: 'The term \"AGI\" was popularized by... Shane Legg, Mark Gubrud and Ben Goertzel'</span>\n</li>\n<li id=\"cite_note-36\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-36\">^</a></b></span> <span class=\"reference-text\"><a href=\"#CITEREFGoertzelWang2006\">Goertzel &amp; Wang 2006</a>. See also <a href=\"#CITEREFWang2006\">Wang (2006)</a> with an up-to-date summary and lots of links.</span>\n</li>\n<li id=\"cite_note-FOOTNOTEGoertzel2007-37\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-FOOTNOTEGoertzel2007_37-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-FOOTNOTEGoertzel2007_37-1\"><sup><i><b>b</b></i></sup></a> <a href=\"#cite_ref-FOOTNOTEGoertzel2007_37-2\"><sup><i><b>c</b></i></sup></a> <a href=\"#cite_ref-FOOTNOTEGoertzel2007_37-3\"><sup><i><b>d</b></i></sup></a> <a href=\"#cite_ref-FOOTNOTEGoertzel2007_37-4\"><sup><i><b>e</b></i></sup></a> <a href=\"#cite_ref-FOOTNOTEGoertzel2007_37-5\"><sup><i><b>f</b></i></sup></a></span> <span class=\"reference-text\"><a href=\"#CITEREFGoertzel2007\">Goertzel 2007</a>.</span>\n</li>\n<li id=\"cite_note-38\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-38\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation news\">Markoff, John (27 November 2016). <a class=\"external text\" href=\"https://www.nytimes.com/2016/11/27/technology/artificial-intelligence-pioneer-jurgen-schmidhuber-overlooked.html\" rel=\"nofollow\">\"When A.I. Matures, It May Call Jürgen Schmidhuber 'Dad<span class=\"cs1-kern-right\">'</span>\"</a>. <i>The New York Times</i><span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">26 December</span> 2017</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+New+York+Times&amp;rft.atitle=When+A.I.+Matures%2C+It+May+Call+J%C3%BCrgen+Schmidhuber+%27Dad%27&amp;rft.date=2016-11-27&amp;rft.aulast=Markoff&amp;rft.aufirst=John&amp;rft_id=https%3A%2F%2Fwww.nytimes.com%2F2016%2F11%2F27%2Ftechnology%2Fartificial-intelligence-pioneer-jurgen-schmidhuber-overlooked.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></span>\n</li>\n<li id=\"cite_note-39\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-39\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation book\"><a href=\"/wiki/James_Barrat\" title=\"James Barrat\">James Barrat</a> (2013). \"Chapter 11: A Hard Takeoff\". <a href=\"/wiki/Our_Final_Invention\" title=\"Our Final Invention\"><i>Our Final Invention: Artificial Intelligence and the End of the Human Era</i></a> (First ed.). New York: St. Martin's Press. <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a> <a href=\"/wiki/Special:BookSources/9780312622374\" title=\"Special:BookSources/9780312622374\">9780312622374</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Chapter+11%3A+A+Hard+Takeoff&amp;rft.btitle=Our+Final+Invention%3A+Artificial+Intelligence+and+the+End+of+the+Human+Era&amp;rft.place=New+York&amp;rft.edition=First&amp;rft.pub=St.+Martin%27s+Press&amp;rft.date=2013&amp;rft.isbn=9780312622374&amp;rft.au=James+Barrat&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></span>\n</li>\n<li id=\"cite_note-40\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-40\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation web\"><a class=\"external text\" href=\"https://intelligence.org/about/\" rel=\"nofollow\">\"About the Machine Intelligence Research Institute\"</a>. <i>Machine Intelligence Research Institute</i><span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">26 December</span> 2017</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Machine+Intelligence+Research+Institute&amp;rft.atitle=About+the+Machine+Intelligence+Research+Institute&amp;rft_id=https%3A%2F%2Fintelligence.org%2Fabout%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></span>\n</li>\n<li id=\"cite_note-41\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-41\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation news\"><a class=\"external text\" href=\"https://openai.com/about/\" rel=\"nofollow\">\"About OpenAI\"</a>. <i><a href=\"/wiki/OpenAI\" title=\"OpenAI\">OpenAI</a></i><span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">26 December</span> 2017</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=OpenAI&amp;rft.atitle=About+OpenAI&amp;rft_id=https%3A%2F%2Fopenai.com%2Fabout%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></span>\n</li>\n<li id=\"cite_note-42\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-42\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation news\">Theil, Stefan. <a class=\"external text\" href=\"https://www.scientificamerican.com/article/why-the-human-brain-project-went-wrong-and-how-to-fix-it/\" rel=\"nofollow\">\"Trouble in Mind\"</a>. <i>Scientific American</i>. pp. 36–42. <a href=\"/wiki/Bibcode\" title=\"Bibcode\">Bibcode</a>:<a class=\"external text\" href=\"http://adsabs.harvard.edu/abs/2015SciAm.313d..36T\" rel=\"nofollow\">2015SciAm.313d..36T</a>. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a class=\"external text\" href=\"//doi.org/10.1038%2Fscientificamerican1015-36\" rel=\"nofollow\">10.1038/scientificamerican1015-36</a><span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">26 December</span> 2017</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Scientific+American&amp;rft.atitle=Trouble+in+Mind&amp;rft.pages=36-42&amp;rft_id=info%3Adoi%2F10.1038%2Fscientificamerican1015-36&amp;rft_id=info%3Abibcode%2F2015SciAm.313d..36T&amp;rft.aulast=Theil&amp;rft.aufirst=Stefan&amp;rft_id=https%3A%2F%2Fwww.scientificamerican.com%2Farticle%2Fwhy-the-human-brain-project-went-wrong-and-how-to-fix-it%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></span>\n</li>\n<li id=\"cite_note-43\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-43\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Baum, Seth (2017-11-12). <a class=\"external text\" href=\"https://ssrn.com/abstract=3070741\" rel=\"nofollow\">\"Baum, Seth, A Survey of Artificial General Intelligence Projects for Ethics, Risk, and Policy (November 12, 2017). Global Catastrophic Risk Institute Working Paper 17-1\"</a><span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">3 January</span> 2019</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Baum%2C+Seth%2C+A+Survey+of+Artificial+General+Intelligence+Projects+for+Ethics%2C+Risk%2C+and+Policy+%28November+12%2C+2017%29.+Global+Catastrophic+Risk+Institute+Working+Paper+17-1&amp;rft.date=2017-11-12&amp;rft.aulast=Baum&amp;rft.aufirst=Seth&amp;rft_id=https%3A%2F%2Fssrn.com%2Fabstract%3D3070741&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></span>\n</li>\n<li id=\"cite_note-Roadmap-44\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-Roadmap_44-0\">^</a></b></span> <span class=\"reference-text\">\n<a href=\"#CITEREFSandbergBoström2008\">Sandberg &amp; Boström 2008</a>. \"The basic idea is to take a particular brain, scan its structure in detail, and construct a software model of it that is so faithful to the original that, when run on appropriate hardware, it will behave in essentially the same way as the original brain.\"</span>\n</li>\n<li id=\"cite_note-FOOTNOTESandbergBoström2008-45\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-FOOTNOTESandbergBoström2008_45-0\">^</a></b></span> <span class=\"reference-text\"><a href=\"#CITEREFSandbergBoström2008\">Sandberg &amp; Boström 2008</a>.</span>\n</li>\n<li id=\"cite_note-FOOTNOTEDrachman2005-46\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-FOOTNOTEDrachman2005_46-0\">^</a></b></span> <span class=\"reference-text\"><a href=\"#CITEREFDrachman2005\">Drachman 2005</a>.</span>\n</li>\n<li id=\"cite_note-FOOTNOTERussellNorvig2003-47\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-FOOTNOTERussellNorvig2003_47-0\">^</a></b></span> <span class=\"reference-text\"><a href=\"#CITEREFRussellNorvig2003\">Russell &amp; Norvig 2003</a>.</span>\n</li>\n<li id=\"cite_note-48\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-48\">^</a></b></span> <span class=\"reference-text\">In \"Mind Children\" <a href=\"#CITEREFMoravec1988\">Moravec 1988</a>, p. 61 10<sup>15</sup> cps is used. More recently, in 1997, &lt;<cite class=\"citation web\"><a class=\"external text\" href=\"https://web.archive.org/web/20060615031852/http://transhumanist.com/volume1/moravec.htm\" rel=\"nofollow\">\"Archived copy\"</a>. Archived from <a class=\"external text\" href=\"http://www.transhumanist.com/volume1/moravec.htm\" rel=\"nofollow\">the original</a> on 15 June 2006<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2006-06-23</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Archived+copy&amp;rft_id=http%3A%2F%2Fwww.transhumanist.com%2Fvolume1%2Fmoravec.htm&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><span class=\"cs1-maint citation-comment\">CS1 maint: Archived copy as title (<a href=\"/wiki/Category:CS1_maint:_Archived_copy_as_title\" title=\"Category:CS1 maint: Archived copy as title\">link</a>)</span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/>&gt; Moravec argued for 10<sup>8</sup> MIPS which would roughly correspond to 10<sup>14</sup> cps.  Moravec talks in terms of MIPS, not \"cps\", which is a non-standard term Kurzweil introduced.</span>\n</li>\n<li id=\"cite_note-Discover2011JanFeb-49\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-Discover2011JanFeb_49-0\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Swaminathan, Nikhil (Jan–Feb 2011). <a class=\"external text\" href=\"http://discovermagazine.com/2011/jan-feb/62\" rel=\"nofollow\">\"Glia—the other brain cells\"</a>. <i>Discover</i>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Discover&amp;rft.atitle=Glia%E2%80%94the+other+brain+cells&amp;rft.date=2011-01%2F2011-02&amp;rft.au=Swaminathan%2C+Nikhil&amp;rft_id=http%3A%2F%2Fdiscovermagazine.com%2F2011%2Fjan-feb%2F62&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></span>\n</li>\n<li id=\"cite_note-50\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-50\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Izhikevich, Eugene M.; Edelman, Gerald M. (March 4, 2008). <a class=\"external text\" href=\"https://web.archive.org/web/20090612095651/http://vesicle.nsi.edu/users/izhikevich/publications/large-scale_model_of_human_brain.pdf\" rel=\"nofollow\">\"Large-scale model of mammalian thalamocortical systems\"</a> <span class=\"cs1-format\">(PDF)</span>. <i>PNAS</i>. <b>105</b> (9): 3593–3598. <a href=\"/wiki/Bibcode\" title=\"Bibcode\">Bibcode</a>:<a class=\"external text\" href=\"http://adsabs.harvard.edu/abs/2008PNAS..105.3593I\" rel=\"nofollow\">2008PNAS..105.3593I</a>. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a class=\"external text\" href=\"//doi.org/10.1073%2Fpnas.0712231105\" rel=\"nofollow\">10.1073/pnas.0712231105</a>. <a href=\"/wiki/PubMed_Central\" title=\"PubMed Central\">PMC</a> <span class=\"cs1-lock-free\" title=\"Freely accessible\"><a class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC2265160\" rel=\"nofollow\">2265160</a></span>. <a class=\"mw-redirect\" href=\"/wiki/PubMed_Identifier\" title=\"PubMed Identifier\">PMID</a> <a class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/18292226\" rel=\"nofollow\">18292226</a>. Archived from <a class=\"external text\" href=\"http://vesicle.nsi.edu/users/izhikevich/publications/large-scale_model_of_human_brain.pdf\" rel=\"nofollow\">the original</a> <span class=\"cs1-format\">(PDF)</span> on 12 June 2009<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">23 June</span> 2015</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=PNAS&amp;rft.atitle=Large-scale+model+of+mammalian+thalamocortical+systems&amp;rft.volume=105&amp;rft.issue=9&amp;rft.pages=3593-3598&amp;rft.date=2008-03-04&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC2265160&amp;rft_id=info%3Apmid%2F18292226&amp;rft_id=info%3Adoi%2F10.1073%2Fpnas.0712231105&amp;rft_id=info%3Abibcode%2F2008PNAS..105.3593I&amp;rft.aulast=Izhikevich&amp;rft.aufirst=Eugene+M.&amp;rft.au=Edelman%2C+Gerald+M.&amp;rft_id=http%3A%2F%2Fvesicle.nsi.edu%2Fusers%2Fizhikevich%2Fpublications%2Flarge-scale_model_of_human_brain.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></span>\n</li>\n<li id=\"cite_note-51\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-51\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation web\"><a class=\"external text\" href=\"http://bluebrain.epfl.ch/Jahia/site/bluebrain/op/edit/pid/19085\" rel=\"nofollow\">\"Project Milestones\"</a>. <i>Blue Brain</i><span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2008-08-11</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Blue+Brain&amp;rft.atitle=Project+Milestones&amp;rft_id=http%3A%2F%2Fbluebrain.epfl.ch%2FJahia%2Fsite%2Fbluebrain%2Fop%2Fedit%2Fpid%2F19085&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></span>\n</li>\n<li id=\"cite_note-52\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-52\">^</a></b></span> <span class=\"reference-text\"><a class=\"external text\" href=\"http://news.bbc.co.uk/1/hi/technology/8164060.stm\" rel=\"nofollow\">Artificial brain '10 years away' 2009 BBC news</a></span>\n</li>\n<li id=\"cite_note-53\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-53\">^</a></b></span> <span class=\"reference-text\"><a class=\"external text\" href=\"http://gauntlet.ucalgary.ca/story/10343\" rel=\"nofollow\">University of Calgary news</a>, <a class=\"external text\" href=\"http://msnbc.msn.com/id/12037941/\" rel=\"nofollow\">MSNBC news</a></span>\n</li>\n<li id=\"cite_note-54\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-54\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation web\"><a class=\"external text\" href=\"https://web.archive.org/web/20060615031852/http://transhumanist.com/volume1/moravec.htm\" rel=\"nofollow\">\"Archived copy\"</a>. Archived from <a class=\"external text\" href=\"http://www.transhumanist.com/volume1/moravec.htm\" rel=\"nofollow\">the original</a> on 15 June 2006<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2006-06-23</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Archived+copy&amp;rft_id=http%3A%2F%2Fwww.transhumanist.com%2Fvolume1%2Fmoravec.htm&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><span class=\"cs1-maint citation-comment\">CS1 maint: Archived copy as title (<a href=\"/wiki/Category:CS1_maint:_Archived_copy_as_title\" title=\"Category:CS1 maint: Archived copy as title\">link</a>)</span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></span>\n</li>\n<li id=\"cite_note-55\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-55\">^</a></b></span> <span class=\"reference-text\"><a href=\"#CITEREFde_VegaGlenbergGraesser2008\">de Vega, Glenberg &amp; Graesser 2008</a>. A wide range of views in current research, all of which require grounding to some degree</span>\n</li>\n<li id=\"cite_note-56\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-56\">^</a></b></span> <span class=\"reference-text\"><a class=\"external text\" href=\"http://www.setiai.com/archives/cat_honey_bee_brain.html\" rel=\"nofollow\">some links to bee brain studies</a></span>\n</li>\n<li id=\"cite_note-57\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-57\">^</a></b></span> <span class=\"reference-text\">In Goertzels' AGI book (<a href=\"#CITEREFYudkowsky2006\">Yudkowsky 2006</a>), Yudkowsky proposes 5 levels of organisation that must be understood – code/data, sensory modality, concept &amp; category, thought, and deliberation (consciousness) – in order to use the available hardware</span>\n</li>\n<li id=\"cite_note-58\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-58\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Yekutieli, Y; Sagiv-Zohar, R; Aharonov, R; Engel, Y; Hochner, B; Flash, T (August 2005). \"Dynamic model of the octopus arm. I. Biomechanics of the octopus reaching movement\". <i>J. Neurophysiol</i>. <b>94</b> (2): 1443–58. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a class=\"external text\" href=\"//doi.org/10.1152%2Fjn.00684.2004\" rel=\"nofollow\">10.1152/jn.00684.2004</a>. <a class=\"mw-redirect\" href=\"/wiki/PubMed_Identifier\" title=\"PubMed Identifier\">PMID</a> <a class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/15829594\" rel=\"nofollow\">15829594</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=J.+Neurophysiol.&amp;rft.atitle=Dynamic+model+of+the+octopus+arm.+I.+Biomechanics+of+the+octopus+reaching+movement&amp;rft.volume=94&amp;rft.issue=2&amp;rft.pages=1443-58&amp;rft.date=2005-08&amp;rft_id=info%3Adoi%2F10.1152%2Fjn.00684.2004&amp;rft_id=info%3Apmid%2F15829594&amp;rft.aulast=Yekutieli&amp;rft.aufirst=Y&amp;rft.au=Sagiv-Zohar%2C+R&amp;rft.au=Aharonov%2C+R&amp;rft.au=Engel%2C+Y&amp;rft.au=Hochner%2C+B&amp;rft.au=Flash%2C+T&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></span>\n</li>\n<li id=\"cite_note-59\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-59\">^</a></b></span> <span class=\"reference-text\"><a href=\"#CITEREFWilliamsHerrup1988\">Williams &amp; Herrup 1988</a></span>\n</li>\n<li id=\"cite_note-60\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-60\">^</a></b></span> <span class=\"reference-text\"><a class=\"external text\" href=\"http://search.eb.com/eb/article-75525\" rel=\"nofollow\">\"nervous system, human.\"</a> <i><a href=\"/wiki/Encyclop%C3%A6dia_Britannica\" title=\"Encyclopædia Britannica\">Encyclopædia Britannica</a></i>. 9 January 2007</span>\n</li>\n<li id=\"cite_note-FOOTNOTEAzevedo_et_al.2009-61\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-FOOTNOTEAzevedo_et_al.2009_61-0\">^</a></b></span> <span class=\"reference-text\"><a href=\"#CITEREFAzevedo_et_al.2009\">Azevedo et al. 2009</a>.</span>\n</li>\n<li id=\"cite_note-FOOTNOTEYudkowsky2006-62\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-FOOTNOTEYudkowsky2006_62-0\">^</a></b></span> <span class=\"reference-text\"><a href=\"#CITEREFYudkowsky2006\">Yudkowsky 2006</a>.</span>\n</li>\n<li id=\"cite_note-FOOTNOTEAleksander1996-63\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-FOOTNOTEAleksander1996_63-0\">^</a></b></span> <span class=\"reference-text\"><a href=\"#CITEREFAleksander1996\">Aleksander 1996</a>.</span>\n</li>\n<li id=\"cite_note-64\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-64\">^</a></b></span> <span class=\"reference-text\"><a href=\"#CITEREFSearle1980\">Searle 1980</a></span>\n</li>\n<li id=\"cite_note-65\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-65\">^</a></b></span> <span class=\"reference-text\">As defined in a standard AI textbook: \"The assertion that machines could possibly act intelligently (or, perhaps better, act as if they were intelligent) is called the 'weak AI' hypothesis by philosophers, and the assertion that machines that do so are actually thinking (as opposed to simulating thinking) is called the 'strong AI' hypothesis.\" (<a href=\"#CITEREFRussellNorvig2003\">Russell &amp; Norvig 2003</a>)</span>\n</li>\n<li id=\"cite_note-66\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-66\">^</a></b></span> <span class=\"reference-text\">For example:\n<ul><li><a href=\"#CITEREFRussellNorvig2003\">Russell &amp; Norvig 2003</a>,</li>\n<li><a class=\"external text\" href=\"http://www.encyclopedia.com/doc/1O87-strongAI.html\" rel=\"nofollow\">Oxford University Press Dictionary of Psychology</a> (quoted in \"High Beam Encyclopedia\"),</li>\n<li><a class=\"external text\" href=\"http://www.aaai.org/AITopics/html/phil.html\" rel=\"nofollow\">MIT Encyclopedia of Cognitive Science</a> (quoted in \"AITopics\")</li>\n<li><a class=\"external text\" href=\"http://planetmath.org/encyclopedia/StrongAIThesis.html\" rel=\"nofollow\">Planet Math</a></li>\n<li><a class=\"external text\" href=\"http://www.cbhd.org/resources/biotech/tongen_2003-11-07.htm\" rel=\"nofollow\">Will Biological Computers Enable Artificially Intelligent Machines to Become Persons?</a> Anthony Tongen</li></ul>\n</span></li>\n<li id=\"cite_note-FOOTNOTERussellNorvig2003947-67\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-FOOTNOTERussellNorvig2003947_67-0\">^</a></b></span> <span class=\"reference-text\"><a href=\"#CITEREFRussellNorvig2003\">Russell &amp; Norvig 2003</a>, p. 947.</span>\n</li>\n<li id=\"cite_note-FOOTNOTEClocksin2003-68\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-FOOTNOTEClocksin2003_68-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-FOOTNOTEClocksin2003_68-1\"><sup><i><b>b</b></i></sup></a> <a href=\"#cite_ref-FOOTNOTEClocksin2003_68-2\"><sup><i><b>c</b></i></sup></a> <a href=\"#cite_ref-FOOTNOTEClocksin2003_68-3\"><sup><i><b>d</b></i></sup></a> <a href=\"#cite_ref-FOOTNOTEClocksin2003_68-4\"><sup><i><b>e</b></i></sup></a> <a href=\"#cite_ref-FOOTNOTEClocksin2003_68-5\"><sup><i><b>f</b></i></sup></a> <a href=\"#cite_ref-FOOTNOTEClocksin2003_68-6\"><sup><i><b>g</b></i></sup></a> <a href=\"#cite_ref-FOOTNOTEClocksin2003_68-7\"><sup><i><b>h</b></i></sup></a> <a href=\"#cite_ref-FOOTNOTEClocksin2003_68-8\"><sup><i><b>i</b></i></sup></a></span> <span class=\"reference-text\"><a href=\"#CITEREFClocksin2003\">Clocksin 2003</a>.</span>\n</li>\n<li id=\"cite_note-FOOTNOTEMcCarthy2003-69\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-FOOTNOTEMcCarthy2003_69-0\">^</a></b></span> <span class=\"reference-text\"><a href=\"#CITEREFMcCarthy2003\">McCarthy 2003</a>.</span>\n</li>\n<li id=\"cite_note-FOOTNOTEGelernter2010-70\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-FOOTNOTEGelernter2010_70-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-FOOTNOTEGelernter2010_70-1\"><sup><i><b>b</b></i></sup></a> <a href=\"#cite_ref-FOOTNOTEGelernter2010_70-2\"><sup><i><b>c</b></i></sup></a> <a href=\"#cite_ref-FOOTNOTEGelernter2010_70-3\"><sup><i><b>d</b></i></sup></a></span> <span class=\"reference-text\"><a href=\"#CITEREFGelernter2010\">Gelernter 2010</a>.</span>\n</li>\n<li id=\"cite_note-FOOTNOTEMcCarthy2007-71\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-FOOTNOTEMcCarthy2007_71-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-FOOTNOTEMcCarthy2007_71-1\"><sup><i><b>b</b></i></sup></a></span> <span class=\"reference-text\"><a href=\"#CITEREFMcCarthy2007\">McCarthy 2007</a>.</span>\n</li>\n<li id=\"cite_note-FOOTNOTEHolteChoueiry2003-72\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-FOOTNOTEHolteChoueiry2003_72-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-FOOTNOTEHolteChoueiry2003_72-1\"><sup><i><b>b</b></i></sup></a> <a href=\"#cite_ref-FOOTNOTEHolteChoueiry2003_72-2\"><sup><i><b>c</b></i></sup></a> <a href=\"#cite_ref-FOOTNOTEHolteChoueiry2003_72-3\"><sup><i><b>d</b></i></sup></a></span> <span class=\"reference-text\"><a href=\"#CITEREFHolteChoueiry2003\">Holte &amp; Choueiry 2003</a>.</span>\n</li>\n<li id=\"cite_note-FOOTNOTEZucker2003-73\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-FOOTNOTEZucker2003_73-0\">^</a></b></span> <span class=\"reference-text\"><a href=\"#CITEREFZucker2003\">Zucker 2003</a>.</span>\n</li>\n<li id=\"cite_note-74\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-74\">^</a></b></span> <span class=\"reference-text\">Note that <a href=\"/wiki/Consciousness\" title=\"Consciousness\">consciousness</a> is difficult to define. A popular definition, due to <a href=\"/wiki/Thomas_Nagel\" title=\"Thomas Nagel\">Thomas Nagel</a>, is that it \"feels like\" something to be conscious. If we are not conscious, then it doesn't feel like anything. Nagel uses the example of a bat: we can sensibly ask \"what does it feel like to be a bat?\" However, we are unlikely to ask \"what does it feel like to be a toaster?\" Nagel concludes that a bat appears to be conscious (i.e. has consciousness) but a toaster does not. See (<a href=\"#CITEREFNagel1974\">Nagel 1974</a>)</span>\n</li>\n<li id=\"cite_note-75\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-75\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\"><a href=\"/wiki/Bill_Joy\" title=\"Bill Joy\">Joy, Bill</a> (April 2000). \"Why the future doesn't need us\". <i>Wired</i>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Wired&amp;rft.atitle=Why+the+future+doesn%27t+need+us&amp;rft.date=2000-04&amp;rft.aulast=Joy&amp;rft.aufirst=Bill&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></span>\n</li>\n<li id=\"cite_note-76\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-76\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation news\">Allen, Paul. <a class=\"external text\" href=\"http://www.technologyreview.com/view/425733/paul-allen-the-singularity-isnt-near/\" rel=\"nofollow\">\"The Singularity Isn't Near\"</a>. <i><a href=\"/wiki/MIT_Technology_Review\" title=\"MIT Technology Review\">MIT Technology Review</a></i><span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">17 September</span> 2014</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=MIT+Technology+Review&amp;rft.atitle=The+Singularity+Isn%27t+Near&amp;rft.aulast=Allen&amp;rft.aufirst=Paul&amp;rft_id=http%3A%2F%2Fwww.technologyreview.com%2Fview%2F425733%2Fpaul-allen-the-singularity-isnt-near%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></span>\n</li>\n<li id=\"cite_note-77\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-77\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation news\">Winfield, Alan. <a class=\"external text\" href=\"https://www.theguardian.com/technology/2014/aug/10/artificial-intelligence-will-not-become-a-frankensteins-monster-ian-winfield\" rel=\"nofollow\">\"Artificial intelligence will not turn into a Frankenstein's monster\"</a>. <i><a href=\"/wiki/The_Guardian\" title=\"The Guardian\">The Guardian</a></i><span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">17 September</span> 2014</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+Guardian&amp;rft.atitle=Artificial+intelligence+will+not+turn+into+a+Frankenstein%27s+monster&amp;rft.aulast=Winfield&amp;rft.aufirst=Alan&amp;rft_id=https%3A%2F%2Fwww.theguardian.com%2Ftechnology%2F2014%2Faug%2F10%2Fartificial-intelligence-will-not-become-a-frankensteins-monster-ian-winfield&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></span>\n</li>\n<li id=\"cite_note-new_yorker_doomsday-78\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-new_yorker_doomsday_78-0\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation news\">Raffi Khatchadourian (23 November 2015). <a class=\"external text\" href=\"http://www.newyorker.com/magazine/2015/11/23/doomsday-invention-artificial-intelligence-nick-bostrom\" rel=\"nofollow\">\"The Doomsday Invention: Will artificial intelligence bring us utopia or destruction?\"</a>. <i><a class=\"mw-redirect\" href=\"/wiki/The_New_Yorker_(magazine)\" title=\"The New Yorker (magazine)\">The New Yorker</a></i><span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">7 February</span> 2016</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+New+Yorker&amp;rft.atitle=The+Doomsday+Invention%3A+Will+artificial+intelligence+bring+us+utopia+or+destruction%3F&amp;rft.date=2015-11-23&amp;rft.au=Raffi+Khatchadourian&amp;rft_id=http%3A%2F%2Fwww.newyorker.com%2Fmagazine%2F2015%2F11%2F23%2Fdoomsday-invention-artificial-intelligence-nick-bostrom&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></span>\n</li>\n<li id=\"cite_note-79\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-79\">^</a></b></span> <span class=\"reference-text\">Müller, V. C., &amp; Bostrom, N. (2016). Future progress in artificial intelligence: A survey of expert opinion. In Fundamental issues of artificial intelligence (pp. 555-572). Springer, Cham.</span>\n</li>\n<li id=\"cite_note-80\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-80\">^</a></b></span> <span class=\"reference-text\">Hein, Andreas Makoto, and Hélène Condat. <a class=\"external text\" href=\"https://arxiv.org/abs/1806.02091\" rel=\"nofollow\">\"Can Machines Design? An Artificial General Intelligence Approach.\"</a> arXiv preprint arXiv:1806.02091 (2018).</span>\n</li>\n<li id=\"cite_note-81\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-81\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation web\">Choudhury, Saheli Roy (2016-05-24). <a class=\"external text\" href=\"https://www.cnbc.com/2016/05/24/mastercard-teamed-up-with-pizza-hut-restaurants-asia-to-bring-robots-into-the-pizza-industry.html\" rel=\"nofollow\">\"MasterCard teamed up with Pizza Hut Restaurants Asia to bring robots into the pizza industry\"</a>. <i>www.cnbc.com</i><span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2019-02-25</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=www.cnbc.com&amp;rft.atitle=MasterCard+teamed+up+with+Pizza+Hut+Restaurants+Asia+to+bring+robots+into+the+pizza+industry&amp;rft.date=2016-05-24&amp;rft.aulast=Choudhury&amp;rft.aufirst=Saheli+Roy&amp;rft_id=https%3A%2F%2Fwww.cnbc.com%2F2016%2F05%2F24%2Fmastercard-teamed-up-with-pizza-hut-restaurants-asia-to-bring-robots-into-the-pizza-industry.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></span>\n</li>\n<li id=\"cite_note-82\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-82\">^</a></b></span> <span class=\"reference-text\"><a href=\"#CITEREFYudkowsky,_Eliezer2008\">Yudkowsky, Eliezer (2008)</a></span>\n</li>\n<li id=\"cite_note-83\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-83\">^</a></b></span> <span class=\"reference-text\"><a href=\"#CITEREFBerglas2008\">Berglas (2008)</a></span>\n</li>\n</ol></div>\n<h2><span class=\"mw-headline\" id=\"References\">References</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=25\" title=\"Edit section: References\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<style data-mw-deduplicate=\"TemplateStyles:r853264625\">.mw-parser-output .refbegin{font-size:90%;margin-bottom:0.5em}.mw-parser-output .refbegin-hanging-indents>ul{list-style-type:none;margin-left:0}.mw-parser-output .refbegin-hanging-indents>ul>li,.mw-parser-output .refbegin-hanging-indents>dl>dd{margin-left:0;padding-left:3.2em;text-indent:-3.2em;list-style:none}.mw-parser-output .refbegin-100{font-size:100%}</style><div class=\"refbegin columns references-column-count references-column-count-2\" style=\"-moz-column-count: 2; -webkit-column-count: 2; column-count: 2;\">\n<ul><li><cite class=\"citation web\">Halal, William E. <a class=\"external text\" href=\"https://web.archive.org/web/20130606101835/http://www.techcast.org/Upload/PDFs/633615794236495345_TCTheAutomationofThought.pdf\" rel=\"nofollow\">\"TechCast Article Series: The Automation of Thought\"</a> <span class=\"cs1-format\">(PDF)</span>. Archived from <a class=\"external text\" href=\"http://www.techcast.org/Upload/PDFs/633615794236495345_TCTheAutomationofThought.pdf\" rel=\"nofollow\">the original</a> <span class=\"cs1-format\">(PDF)</span> on 6 June 2013.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=TechCast+Article+Series%3A+The+Automation+of+Thought&amp;rft.aulast=Halal&amp;rft.aufirst=William+E.&amp;rft_id=http%3A%2F%2Fwww.techcast.org%2FUpload%2FPDFs%2F633615794236495345_TCTheAutomationofThought.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFAleksander1996\"><a href=\"/wiki/Igor_Aleksander\" title=\"Igor Aleksander\">Aleksander, Igor</a> (1996), <i>Impossible Minds</i>, World Scientific Publishing Company, <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a> <a href=\"/wiki/Special:BookSources/978-1-86094-036-1\" title=\"Special:BookSources/978-1-86094-036-1\">978-1-86094-036-1</a></cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Impossible+Minds&amp;rft.pub=World+Scientific+Publishing+Company&amp;rft.date=1996&amp;rft.isbn=978-1-86094-036-1&amp;rft.aulast=Aleksander&amp;rft.aufirst=Igor&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFOmohundro2008\"><a href=\"/wiki/Steve_Omohundro\" title=\"Steve Omohundro\">Omohundro, Steve</a> (2008), <i>The Nature of Self-Improving Artificial Intelligence</i>, presented and distributed at the 2007 Singularity Summit, San Francisco, CA.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Nature+of+Self-Improving+Artificial+Intelligence&amp;rft.pub=presented+and+distributed+at+the+2007+Singularity+Summit%2C+San+Francisco%2C+CA.&amp;rft.date=2008&amp;rft.aulast=Omohundro&amp;rft.aufirst=Steve&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFSandbergBoström2008\">Sandberg, Anders; Boström, Nick (2008), <a class=\"external text\" href=\"http://www.fhi.ox.ac.uk/Reports/2008-3.pdf\" rel=\"nofollow\"><i>Whole Brain Emulation: A Roadmap</i></a> <span class=\"cs1-format\">(PDF)</span>, Technical Report #2008‐3, Future of Humanity Institute, Oxford University<span class=\"reference-accessdate\">, retrieved <span class=\"nowrap\">5 April</span> 2009</span></cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Whole+Brain+Emulation%3A+A+Roadmap&amp;rft.series=Technical+Report+%232008%E2%80%903&amp;rft.pub=Future+of+Humanity+Institute%2C+Oxford+University&amp;rft.date=2008&amp;rft.aulast=Sandberg&amp;rft.aufirst=Anders&amp;rft.au=Bostr%C3%B6m%2C+Nick&amp;rft_id=http%3A%2F%2Fwww.fhi.ox.ac.uk%2FReports%2F2008-3.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFAzevedo_et_al.2009\">Azevedo FA, Carvalho LR, Grinberg LT,  et al. (April 2009), <a class=\"external text\" href=\"https://www.researchgate.net/publication/24024444\" rel=\"nofollow\">\"Equal numbers of neuronal and nonneuronal cells make the human brain an isometrically scaled-up primate brain\"</a>, <i>The Journal of Comparative Neurology</i>, <b>513</b> (5): 532–41, <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a class=\"external text\" href=\"//doi.org/10.1002%2Fcne.21974\" rel=\"nofollow\">10.1002/cne.21974</a>, <a class=\"mw-redirect\" href=\"/wiki/PubMed_Identifier\" title=\"PubMed Identifier\">PMID</a> <a class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/19226510\" rel=\"nofollow\">19226510</a><span class=\"reference-accessdate\">, retrieved <span class=\"nowrap\">2013-09-04</span></span></cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+Journal+of+Comparative+Neurology&amp;rft.atitle=Equal+numbers+of+neuronal+and+nonneuronal+cells+make+the+human+brain+an+isometrically+scaled-up+primate+brain&amp;rft.volume=513&amp;rft.issue=5&amp;rft.pages=532-41&amp;rft.date=2009-04&amp;rft_id=info%3Adoi%2F10.1002%2Fcne.21974&amp;rft_id=info%3Apmid%2F19226510&amp;rft.aulast=Azevedo&amp;rft.aufirst=FA&amp;rft.au=Carvalho%2C+LR&amp;rft.au=Grinberg%2C+LT&amp;rft_id=https%3A%2F%2Fwww.researchgate.net%2Fpublication%2F24024444&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFBerglas2008\">Berglas, Anthony (2008), <a class=\"external text\" href=\"http://berglas.org/Articles/AIKillGrandchildren/AIKillGrandchildren.html\" rel=\"nofollow\"><i>Artificial Intelligence will Kill our Grandchildren</i></a><span class=\"reference-accessdate\">, retrieved <span class=\"nowrap\">2008-06-13</span></span></cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Artificial+Intelligence+will+Kill+our+Grandchildren&amp;rft.date=2008&amp;rft.aulast=Berglas&amp;rft.aufirst=Anthony&amp;rft_id=http%3A%2F%2Fberglas.org%2FArticles%2FAIKillGrandchildren%2FAIKillGrandchildren.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFChalmers1996\"><a href=\"/wiki/David_Chalmers\" title=\"David Chalmers\">Chalmers, David</a> (1996), <i>The Conscious Mind</i>, Oxford University Press.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Conscious+Mind&amp;rft.pub=Oxford+University+Press.&amp;rft.date=1996&amp;rft.aulast=Chalmers&amp;rft.aufirst=David&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFClocksin2003\">Clocksin, William (Aug 2003), \"Artificial intelligence and the future\", <i><a href=\"/wiki/Philosophical_Transactions_of_the_Royal_Society_A\" title=\"Philosophical Transactions of the Royal Society A\">Philosophical Transactions of the Royal Society A</a></i>, <b>361</b> (1809): 1721–1748, <a href=\"/wiki/Bibcode\" title=\"Bibcode\">Bibcode</a>:<a class=\"external text\" href=\"http://adsabs.harvard.edu/abs/2003RSPTA.361.1721C\" rel=\"nofollow\">2003RSPTA.361.1721C</a>, <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a class=\"external text\" href=\"//doi.org/10.1098%2Frsta.2003.1232\" rel=\"nofollow\">10.1098/rsta.2003.1232</a>, <a class=\"mw-redirect\" href=\"/wiki/PubMed_Identifier\" title=\"PubMed Identifier\">PMID</a> <a class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/12952683\" rel=\"nofollow\">12952683</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Philosophical+Transactions+of+the+Royal+Society+A&amp;rft.atitle=Artificial+intelligence+and+the+future&amp;rft.volume=361&amp;rft.issue=1809&amp;rft.pages=1721-1748&amp;rft.date=2003-08&amp;rft_id=info%3Apmid%2F12952683&amp;rft_id=info%3Adoi%2F10.1098%2Frsta.2003.1232&amp;rft_id=info%3Abibcode%2F2003RSPTA.361.1721C&amp;rft.aulast=Clocksin&amp;rft.aufirst=William&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFCrevier1993\"><a href=\"/wiki/Daniel_Crevier\" title=\"Daniel Crevier\">Crevier, Daniel</a> (1993), <i>AI: The Tumultuous Search for Artificial Intelligence</i>, New York, NY: BasicBooks, <link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/><a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a> <a href=\"/wiki/Special:BookSources/0-465-02997-3\" title=\"Special:BookSources/0-465-02997-3\">0-465-02997-3</a></cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=AI%3A+The+Tumultuous+Search+for+Artificial+Intelligence&amp;rft.place=New+York%2C+NY&amp;rft.pub=BasicBooks&amp;rft.date=1993&amp;rft.aulast=Crevier&amp;rft.aufirst=Daniel&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFDarrach1970\">Darrach, Brad (20 November 1970), \"Meet Shakey, the First Electronic Person\", <i><a class=\"mw-redirect\" href=\"/wiki/Life_Magazine\" title=\"Life Magazine\">Life Magazine</a></i>, pp. 58–68</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Life+Magazine&amp;rft.atitle=Meet+Shakey%2C+the+First+Electronic+Person&amp;rft.pages=58-68&amp;rft.date=1970-11-20&amp;rft.aulast=Darrach&amp;rft.aufirst=Brad&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/>.</li>\n<li><cite class=\"citation\" id=\"CITEREFDrachman2005\">Drachman, D (2005), \"Do we have brain to spare?\", <i>Neurology</i>, <b>64</b> (12): 2004–5, <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a class=\"external text\" href=\"//doi.org/10.1212%2F01.WNL.0000166914.38327.BB\" rel=\"nofollow\">10.1212/01.WNL.0000166914.38327.BB</a>, <a class=\"mw-redirect\" href=\"/wiki/PubMed_Identifier\" title=\"PubMed Identifier\">PMID</a> <a class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/15985565\" rel=\"nofollow\">15985565</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Neurology&amp;rft.atitle=Do+we+have+brain+to+spare%3F&amp;rft.volume=64&amp;rft.issue=12&amp;rft.pages=2004-5&amp;rft.date=2005&amp;rft_id=info%3Adoi%2F10.1212%2F01.WNL.0000166914.38327.BB&amp;rft_id=info%3Apmid%2F15985565&amp;rft.aulast=Drachman&amp;rft.aufirst=D&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFFeigenbaumMcCorduck1983\"><a href=\"/wiki/Edward_Feigenbaum\" title=\"Edward Feigenbaum\">Feigenbaum, Edward A.</a>; <a href=\"/wiki/Pamela_McCorduck\" title=\"Pamela McCorduck\">McCorduck, Pamela</a> (1983), <i>The Fifth Generation: Artificial Intelligence and Japan's Computer Challenge to the World</i>, Michael Joseph, <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a> <a href=\"/wiki/Special:BookSources/978-0-7181-2401-4\" title=\"Special:BookSources/978-0-7181-2401-4\">978-0-7181-2401-4</a></cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Fifth+Generation%3A+Artificial+Intelligence+and+Japan%27s+Computer+Challenge+to+the+World&amp;rft.pub=Michael+Joseph&amp;rft.date=1983&amp;rft.isbn=978-0-7181-2401-4&amp;rft.aulast=Feigenbaum&amp;rft.aufirst=Edward+A.&amp;rft.au=McCorduck%2C+Pamela&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFGelernter2010\">Gelernter, David (2010), <a class=\"external text\" href=\"http://www.edge.org/3rd_culture/gelernter10.1/gelernter10.1_index.html\" rel=\"nofollow\"><i>Dream-logic, the Internet and Artificial Thought</i></a><span class=\"reference-accessdate\">, retrieved <span class=\"nowrap\">25 July</span> 2010</span></cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Dream-logic%2C+the+Internet+and+Artificial+Thought&amp;rft.date=2010&amp;rft.aulast=Gelernter&amp;rft.aufirst=David&amp;rft_id=http%3A%2F%2Fwww.edge.org%2F3rd_culture%2Fgelernter10.1%2Fgelernter10.1_index.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFGoertzelPennachin2006\">Goertzel, Ben; Pennachin, Cassio, eds. (2006), <a class=\"external text\" href=\"https://web.archive.org/web/20130320184603/http://people.inf.elte.hu/csizsekp/ai/books/artificial-general-intelligence-cognitive-technologies.9783540237334.27156.pdf\" rel=\"nofollow\"><i>Artificial General Intelligence</i></a> <span class=\"cs1-format\">(PDF)</span>, Springer, <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a> <a href=\"/wiki/Special:BookSources/978-3-540-23733-4\" title=\"Special:BookSources/978-3-540-23733-4\">978-3-540-23733-4</a>, archived from <a class=\"external text\" href=\"http://people.inf.elte.hu/csizsekp/ai/books/artificial-general-intelligence-cognitive-technologies.9783540237334.27156.pdf\" rel=\"nofollow\">the original</a> <span class=\"cs1-format\">(PDF)</span> on 20 March 2013</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Artificial+General+Intelligence&amp;rft.pub=Springer&amp;rft.date=2006&amp;rft.isbn=978-3-540-23733-4&amp;rft_id=http%3A%2F%2Fpeople.inf.elte.hu%2Fcsizsekp%2Fai%2Fbooks%2Fartificial-general-intelligence-cognitive-technologies.9783540237334.27156.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFGoertzelWang2006\"><a href=\"/wiki/Ben_Goertzel\" title=\"Ben Goertzel\">Goertzel, Ben</a>; Wang, Pei (2006), <a class=\"external text\" href=\"http://sites.google.com/site/narswang/publications/wang-goertzel.AGI_Aspects.pdf?attredirects=1\" rel=\"nofollow\"><i>Introduction: Aspects of Artificial General Intelligence</i></a> <span class=\"cs1-format\">(PDF)</span></cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Introduction%3A+Aspects+of+Artificial+General+Intelligence&amp;rft.date=2006&amp;rft.aulast=Goertzel&amp;rft.aufirst=Ben&amp;rft.au=Wang%2C+Pei&amp;rft_id=http%3A%2F%2Fsites.google.com%2Fsite%2Fnarswang%2Fpublications%2Fwang-goertzel.AGI_Aspects.pdf%3Fattredirects%3D1&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFGoertzel2007\"><a href=\"/wiki/Ben_Goertzel\" title=\"Ben Goertzel\">Goertzel, Ben</a> (Dec 2007), <a class=\"external text\" href=\"https://scholar.google.com/scholar?hl=sv&amp;lr=&amp;cluster=15189798216526465792\" rel=\"nofollow\">\"Human-level artificial general intelligence and the possibility of a technological singularity: a reaction to Ray Kurzweil's The Singularity Is Near, and McDermott's critique of Kurzweil\"</a>, <i>Artificial Intelligence</i>, <b>171</b> (18, Special Review Issue): 1161–1173, <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a class=\"external text\" href=\"//doi.org/10.1016%2Fj.artint.2007.10.011\" rel=\"nofollow\">10.1016/j.artint.2007.10.011</a><span class=\"reference-accessdate\">, retrieved <span class=\"nowrap\">1 April</span> 2009</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Artificial+Intelligence&amp;rft.atitle=Human-level+artificial+general+intelligence+and+the+possibility+of+a+technological+singularity%3A+a+reaction+to+Ray+Kurzweil%27s+The+Singularity+Is+Near%2C+and+McDermott%27s+critique+of+Kurzweil&amp;rft.volume=171&amp;rft.issue=18%2C+Special+Review+Issue&amp;rft.pages=1161-1173&amp;rft.date=2007-12&amp;rft_id=info%3Adoi%2F10.1016%2Fj.artint.2007.10.011&amp;rft.aulast=Goertzel&amp;rft.aufirst=Ben&amp;rft_id=https%3A%2F%2Fscholar.google.com%2Fscholar%3Fhl%3Dsv%26lr%3D%26cluster%3D15189798216526465792&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFGubrud1997\">Gubrud, Mark (November 1997), <a class=\"external text\" href=\"http://www.foresight.org/Conferences/MNT05/Papers/Gubrud/\" rel=\"nofollow\">\"Nanotechnology and International Security\"</a>, <i>Fifth Foresight Conference on Molecular Nanotechnology</i><span class=\"reference-accessdate\">, retrieved <span class=\"nowrap\">7 May</span> 2011</span></cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Fifth+Foresight+Conference+on+Molecular+Nanotechnology&amp;rft.atitle=Nanotechnology+and+International+Security&amp;rft.date=1997-11&amp;rft.aulast=Gubrud&amp;rft.aufirst=Mark&amp;rft_id=http%3A%2F%2Fwww.foresight.org%2FConferences%2FMNT05%2FPapers%2FGubrud%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFHolteChoueiry2003\">Holte, RC; Choueiry, BY (2003), \"Abstraction and reformulation in artificial intelligence\", <i><a href=\"/wiki/Philosophical_Transactions_of_the_Royal_Society_B\" title=\"Philosophical Transactions of the Royal Society B\">Philosophical Transactions of the Royal Society B</a></i>, <b>358</b> (1435): 1197–1204, <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a class=\"external text\" href=\"//doi.org/10.1098%2Frstb.2003.1317\" rel=\"nofollow\">10.1098/rstb.2003.1317</a>, <a href=\"/wiki/PubMed_Central\" title=\"PubMed Central\">PMC</a> <span class=\"cs1-lock-free\" title=\"Freely accessible\"><a class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC1693218\" rel=\"nofollow\">1693218</a></span>, <a class=\"mw-redirect\" href=\"/wiki/PubMed_Identifier\" title=\"PubMed Identifier\">PMID</a> <a class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/12903653\" rel=\"nofollow\">12903653</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Philosophical+Transactions+of+the+Royal+Society+B&amp;rft.atitle=Abstraction+and+reformulation+in+artificial+intelligence&amp;rft.volume=358&amp;rft.issue=1435&amp;rft.pages=1197-1204&amp;rft.date=2003&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC1693218&amp;rft_id=info%3Apmid%2F12903653&amp;rft_id=info%3Adoi%2F10.1098%2Frstb.2003.1317&amp;rft.aulast=Holte&amp;rft.aufirst=RC&amp;rft.au=Choueiry%2C+BY&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFHowe1994\">Howe, J. (November 1994), <a class=\"external text\" href=\"http://www.dai.ed.ac.uk/AI_at_Edinburgh_perspective.html\" rel=\"nofollow\"><i>Artificial Intelligence at Edinburgh University : a Perspective</i></a><span class=\"reference-accessdate\">, retrieved <span class=\"nowrap\">30 August</span> 2007</span></cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Artificial+Intelligence+at+Edinburgh+University+%3A+a+Perspective&amp;rft.date=1994-11&amp;rft.aulast=Howe&amp;rft.aufirst=J.&amp;rft_id=http%3A%2F%2Fwww.dai.ed.ac.uk%2FAI_at_Edinburgh_perspective.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFJohnson1987\">Johnson, Mark (1987), <i>The body in the mind</i>, Chicago, <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a> <a href=\"/wiki/Special:BookSources/978-0-226-40317-5\" title=\"Special:BookSources/978-0-226-40317-5\">978-0-226-40317-5</a></cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+body+in+the+mind&amp;rft.pub=Chicago&amp;rft.date=1987&amp;rft.isbn=978-0-226-40317-5&amp;rft.aulast=Johnson&amp;rft.aufirst=Mark&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFKurzweil2005\"><a href=\"/wiki/Ray_Kurzweil\" title=\"Ray Kurzweil\">Kurzweil, Ray</a> (2005), <a class=\"mw-redirect\" href=\"/wiki/The_Singularity_is_Near\" title=\"The Singularity is Near\"><i>The Singularity is Near</i></a>, Viking Press</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Singularity+is+Near&amp;rft.pub=Viking+Press&amp;rft.date=2005&amp;rft.aulast=Kurzweil&amp;rft.aufirst=Ray&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFLighthill1973\"><a href=\"/wiki/James_Lighthill\" title=\"James Lighthill\">Lighthill, Professor Sir James</a> (1973), \"Artificial Intelligence: A General Survey\", <i>Artificial Intelligence: a paper symposium</i>, Science Research Council</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Artificial+Intelligence%3A+A+General+Survey&amp;rft.btitle=Artificial+Intelligence%3A+a+paper+symposium&amp;rft.pub=Science+Research+Council&amp;rft.date=1973&amp;rft.aulast=Lighthill&amp;rft.aufirst=Professor+Sir+James&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFLugerStubblefield2004\">Luger, George; Stubblefield, William (2004), <a class=\"external text\" href=\"http://www.cs.unm.edu/~luger/ai-final/tocfull.html\" rel=\"nofollow\"><i>Artificial Intelligence: Structures and Strategies for Complex Problem Solving</i></a> (5th ed.), The Benjamin/Cummings Publishing Company, Inc., p. 720, <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a> <a href=\"/wiki/Special:BookSources/978-0-8053-4780-7\" title=\"Special:BookSources/978-0-8053-4780-7\">978-0-8053-4780-7</a></cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Artificial+Intelligence%3A+Structures+and+Strategies+for+Complex+Problem+Solving&amp;rft.pages=720&amp;rft.edition=5th&amp;rft.pub=The+Benjamin%2FCummings+Publishing+Company%2C+Inc.&amp;rft.date=2004&amp;rft.isbn=978-0-8053-4780-7&amp;rft.aulast=Luger&amp;rft.aufirst=George&amp;rft.au=Stubblefield%2C+William&amp;rft_id=http%3A%2F%2Fwww.cs.unm.edu%2F~luger%2Fai-final%2Ftocfull.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFMcCarthy2007\"><a href=\"/wiki/John_McCarthy_(computer_scientist)\" title=\"John McCarthy (computer scientist)\">McCarthy, John</a> (Oct 2007), \"From here to human-level AI\", <i>Artificial Intelligence</i>, <b>171</b> (18): 1174–1182, <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a class=\"external text\" href=\"//doi.org/10.1016%2Fj.artint.2007.10.009\" rel=\"nofollow\">10.1016/j.artint.2007.10.009</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Artificial+Intelligence&amp;rft.atitle=From+here+to+human-level+AI&amp;rft.volume=171&amp;rft.issue=18&amp;rft.pages=1174-1182&amp;rft.date=2007-10&amp;rft_id=info%3Adoi%2F10.1016%2Fj.artint.2007.10.009&amp;rft.aulast=McCarthy&amp;rft.aufirst=John&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFMcCorduck2004\"><a href=\"/wiki/Pamela_McCorduck\" title=\"Pamela McCorduck\">McCorduck, Pamela</a> (2004), <a class=\"external text\" href=\"http://www.pamelamc.com/html/machines_who_think.html\" rel=\"nofollow\"><i>Machines Who Think</i></a> (2nd ed.), Natick, MA: A. K. Peters, Ltd., <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a> <a href=\"/wiki/Special:BookSources/1-56881-205-1\" title=\"Special:BookSources/1-56881-205-1\">1-56881-205-1</a></cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Machines+Who+Think&amp;rft.place=Natick%2C+MA&amp;rft.edition=2nd&amp;rft.pub=A.+K.+Peters%2C+Ltd.&amp;rft.date=2004&amp;rft.isbn=1-56881-205-1&amp;rft.aulast=McCorduck&amp;rft.aufirst=Pamela&amp;rft_id=http%3A%2F%2Fwww.pamelamc.com%2Fhtml%2Fmachines_who_think.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFMoravec1976\"><a href=\"/wiki/Hans_Moravec\" title=\"Hans Moravec\">Moravec, Hans</a> (1976), <a class=\"external text\" href=\"http://www.frc.ri.cmu.edu/users/hpm/project.archive/general.articles/1975/Raw.Power.html\" rel=\"nofollow\"><i>The Role of Raw Power in Intelligence</i></a></cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Role+of+Raw+Power+in+Intelligence&amp;rft.date=1976&amp;rft.aulast=Moravec&amp;rft.aufirst=Hans&amp;rft_id=http%3A%2F%2Fwww.frc.ri.cmu.edu%2Fusers%2Fhpm%2Fproject.archive%2Fgeneral.articles%2F1975%2FRaw.Power.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFMoravec1988\"><a href=\"/wiki/Hans_Moravec\" title=\"Hans Moravec\">Moravec, Hans</a> (1988), <i>Mind Children</i>, Harvard University Press</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Mind+Children&amp;rft.pub=Harvard+University+Press&amp;rft.date=1988&amp;rft.aulast=Moravec&amp;rft.aufirst=Hans&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFNagel1974\">Nagel (1974), <a class=\"external text\" href=\"http://organizations.utep.edu/Portals/1475/nagel_bat.pdf\" rel=\"nofollow\">\"What Is it Like to Be a Bat\"</a> <span class=\"cs1-format\">(PDF)</span>, <i>Philosophical Review</i>, <b>83</b> (4): 435–50, <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a class=\"external text\" href=\"//doi.org/10.2307%2F2183914\" rel=\"nofollow\">10.2307/2183914</a>, <a href=\"/wiki/JSTOR\" title=\"JSTOR\">JSTOR</a> <a class=\"external text\" href=\"//www.jstor.org/stable/2183914\" rel=\"nofollow\">2183914</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Philosophical+Review&amp;rft.atitle=What+Is+it+Like+to+Be+a+Bat&amp;rft.volume=83&amp;rft.issue=4&amp;rft.pages=435-50&amp;rft.date=1974&amp;rft_id=info%3Adoi%2F10.2307%2F2183914&amp;rft_id=%2F%2Fwww.jstor.org%2Fstable%2F2183914&amp;rft.au=Nagel&amp;rft_id=http%3A%2F%2Forganizations.utep.edu%2FPortals%2F1475%2Fnagel_bat.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFNewellSimon1963\"><a href=\"/wiki/Allen_Newell\" title=\"Allen Newell\">Newell, Allen</a>; <a href=\"/wiki/Herbert_A._Simon\" title=\"Herbert A. Simon\">Simon, H. A.</a> (1963), \"GPS: A Program that Simulates Human Thought\",  in Feigenbaum, E.A.; Feldman, J., <i>Computers and Thought</i>, New York: McGraw-Hill</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=GPS%3A+A+Program+that+Simulates+Human+Thought&amp;rft.btitle=Computers+and+Thought&amp;rft.place=New+York&amp;rft.pub=McGraw-Hill&amp;rft.date=1963&amp;rft.aulast=Newell&amp;rft.aufirst=Allen&amp;rft.au=Simon%2C+H.+A.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation journal\"><a href=\"/wiki/Allen_Newell\" title=\"Allen Newell\">Newell, Allen</a>; <a href=\"/wiki/Herbert_A._Simon\" title=\"Herbert A. Simon\">Simon, H. A.</a> (1976). \"Computer Science as Empirical Inquiry: Symbols and Search\". <i>Communications of the ACM</i>. <b>19</b> (3): 113–126. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a class=\"external text\" href=\"//doi.org/10.1145%2F360018.360022\" rel=\"nofollow\">10.1145/360018.360022</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Communications+of+the+ACM&amp;rft.atitle=Computer+Science+as+Empirical+Inquiry%3A+Symbols+and+Search&amp;rft.volume=19&amp;rft.issue=3&amp;rft.pages=113-126&amp;rft.date=1976&amp;rft_id=info%3Adoi%2F10.1145%2F360018.360022&amp;rft.aulast=Newell&amp;rft.aufirst=Allen&amp;rft.au=Simon%2C+H.+A.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFNilsson1998\"><a class=\"mw-redirect\" href=\"/wiki/Nils_Nilsson_(researcher)\" title=\"Nils Nilsson (researcher)\">Nilsson, Nils</a> (1998), <i>Artificial Intelligence: A New Synthesis</i>, Morgan Kaufmann Publishers, <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a> <a href=\"/wiki/Special:BookSources/978-1-55860-467-4\" title=\"Special:BookSources/978-1-55860-467-4\">978-1-55860-467-4</a></cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Artificial+Intelligence%3A+A+New+Synthesis&amp;rft.pub=Morgan+Kaufmann+Publishers&amp;rft.date=1998&amp;rft.isbn=978-1-55860-467-4&amp;rft.aulast=Nilsson&amp;rft.aufirst=Nils&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFRussellNorvig2003\"><a href=\"/wiki/Stuart_J._Russell\" title=\"Stuart J. Russell\">Russell, Stuart J.</a>; <a href=\"/wiki/Peter_Norvig\" title=\"Peter Norvig\">Norvig, Peter</a> (2003), <a class=\"external text\" href=\"http://aima.cs.berkeley.edu/\" rel=\"nofollow\"><i>Artificial Intelligence: A Modern Approach</i></a> (2nd ed.), Upper Saddle River, New Jersey: Prentice Hall, <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a> <a href=\"/wiki/Special:BookSources/0-13-790395-2\" title=\"Special:BookSources/0-13-790395-2\">0-13-790395-2</a></cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Artificial+Intelligence%3A+A+Modern+Approach&amp;rft.place=Upper+Saddle+River%2C+New+Jersey&amp;rft.edition=2nd&amp;rft.pub=Prentice+Hall&amp;rft.date=2003&amp;rft.isbn=0-13-790395-2&amp;rft.aulast=Russell&amp;rft.aufirst=Stuart+J.&amp;rft.au=Norvig%2C+Peter&amp;rft_id=http%3A%2F%2Faima.cs.berkeley.edu%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFNRC1999\"><a class=\"mw-redirect\" href=\"/wiki/United_States_National_Research_Council\" title=\"United States National Research Council\">NRC</a> (1999), <a class=\"external text\" href=\"http://www.nap.edu/readingroom/books/far/ch9.html\" rel=\"nofollow\">\"Developments in Artificial Intelligence\"</a>, <i>Funding a Revolution: Government Support for Computing Research</i>, National Academy Press</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Developments+in+Artificial+Intelligence&amp;rft.btitle=Funding+a+Revolution%3A+Government+Support+for+Computing+Research&amp;rft.pub=National+Academy+Press&amp;rft.date=1999&amp;rft.au=NRC&amp;rft_id=http%3A%2F%2Fwww.nap.edu%2Freadingroom%2Fbooks%2Ffar%2Fch9.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFPooleMackworthGoebel1998\"><a class=\"new\" href=\"/w/index.php?title=David_Poole_(researcher)&amp;action=edit&amp;redlink=1\" title=\"David Poole (researcher) (page does not exist)\">Poole, David</a>; Mackworth, Alan; Goebel, Randy (1998), <a class=\"external text\" href=\"http://www.cs.ubc.ca/spider/poole/ci.html\" rel=\"nofollow\"><i>Computational Intelligence: A Logical Approach</i></a>, New York: Oxford University Press</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Computational+Intelligence%3A+A+Logical+Approach&amp;rft.place=New+York&amp;rft.pub=Oxford+University+Press&amp;rft.date=1998&amp;rft.aulast=Poole&amp;rft.aufirst=David&amp;rft.au=Mackworth%2C+Alan&amp;rft.au=Goebel%2C+Randy&amp;rft_id=http%3A%2F%2Fwww.cs.ubc.ca%2Fspider%2Fpoole%2Fci.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFSearle1980\"><a href=\"/wiki/John_Searle\" title=\"John Searle\">Searle, John</a> (1980), <a class=\"external text\" href=\"https://web.archive.org/web/20100118120034/http://www.bbsonline.org/documents/a/00/00/04/84/bbs00000484-00/bbs.searle2.html\" rel=\"nofollow\">\"Minds, Brains and Programs\"</a>, <i>Behavioral and Brain Sciences</i>, <b>3</b> (3): 417–457, <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a class=\"external text\" href=\"//doi.org/10.1017%2FS0140525X00005756\" rel=\"nofollow\">10.1017/S0140525X00005756</a>, archived from <a class=\"external text\" href=\"http://www.bbsonline.org/documents/a/00/00/04/84/bbs00000484-00/bbs.searle2.html\" rel=\"nofollow\">the original</a> on 18 January 2010</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Behavioral+and+Brain+Sciences&amp;rft.atitle=Minds%2C+Brains+and+Programs&amp;rft.volume=3&amp;rft.issue=3&amp;rft.pages=417-457&amp;rft.date=1980&amp;rft_id=info%3Adoi%2F10.1017%2FS0140525X00005756&amp;rft.aulast=Searle&amp;rft.aufirst=John&amp;rft_id=http%3A%2F%2Fwww.bbsonline.org%2Fdocuments%2Fa%2F00%2F00%2F04%2F84%2Fbbs00000484-00%2Fbbs.searle2.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFSimon1965\"><a href=\"/wiki/Herbert_A._Simon\" title=\"Herbert A. Simon\">Simon, H. A.</a> (1965), <i>The Shape of Automation for Men and Management</i>, New York: Harper &amp; Row</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Shape+of+Automation+for+Men+and+Management&amp;rft.place=New+York&amp;rft.pub=Harper+%26+Row&amp;rft.date=1965&amp;rft.aulast=Simon&amp;rft.aufirst=H.+A.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFSutherland1990\">Sutherland, J.G. (1990), \"Holographic Model of Memory, Learning, and Expression\", <i>International Journal of Neural Systems</i>, <b>1–3</b>: 256–267.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=International+Journal+of+Neural+Systems&amp;rft.atitle=Holographic+Model+of+Memory%2C+Learning%2C+and+Expression&amp;rft.volume=1%E2%80%933&amp;rft.pages=256-267&amp;rft.date=1990&amp;rft.aulast=Sutherland&amp;rft.aufirst=J.G.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFWilliamsHerrup1988\">Williams RW, Herrup K (1988), \"The control of neuron number\", <i>Annual Review of Neuroscience</i>, <b>11</b>: 423–53, <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a class=\"external text\" href=\"//doi.org/10.1146%2Fannurev.ne.11.030188.002231\" rel=\"nofollow\">10.1146/annurev.ne.11.030188.002231</a>, <a class=\"mw-redirect\" href=\"/wiki/PubMed_Identifier\" title=\"PubMed Identifier\">PMID</a> <a class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/3284447\" rel=\"nofollow\">3284447</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Annual+Review+of+Neuroscience&amp;rft.atitle=The+control+of+neuron+number&amp;rft.volume=11&amp;rft.pages=423-53&amp;rft.date=1988&amp;rft_id=info%3Adoi%2F10.1146%2Fannurev.ne.11.030188.002231&amp;rft_id=info%3Apmid%2F3284447&amp;rft.aulast=Williams&amp;rft.aufirst=RW&amp;rft.au=Herrup%2C+K&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFde_VegaGlenbergGraesser2008\">de Vega, Manuel; Glenberg, Arthur; Graesser, Arthur, eds. (2008), <i>Symbols and Embodiment: Debates on meaning and cognition</i>, Oxford University Press, <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a> <a href=\"/wiki/Special:BookSources/978-0-19-921727-4\" title=\"Special:BookSources/978-0-19-921727-4\">978-0-19-921727-4</a></cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Symbols+and+Embodiment%3A+Debates+on+meaning+and+cognition&amp;rft.pub=Oxford+University+Press&amp;rft.date=2008&amp;rft.isbn=978-0-19-921727-4&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFYudkowsky2006\"><a href=\"/wiki/Eliezer_Yudkowsky\" title=\"Eliezer Yudkowsky\">Yudkowsky, Eliezer</a> (2006),  Goertzel, Ben; Pennachin, Cassio, eds., <a class=\"external text\" href=\"https://web.archive.org/web/20090411050423/http://www.singinst.org/upload/LOGI/LOGI.pdf\" rel=\"nofollow\">\"Artificial General Intelligence\"</a> <span class=\"cs1-format\">(PDF)</span>, <i>Annual Review of Psychology</i>, Springer, <b>49</b>: 585–612, <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a class=\"external text\" href=\"//doi.org/10.1146%2Fannurev.psych.49.1.585\" rel=\"nofollow\">10.1146/annurev.psych.49.1.585</a>, <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a> <a href=\"/wiki/Special:BookSources/978-3-540-23733-4\" title=\"Special:BookSources/978-3-540-23733-4\">978-3-540-23733-4</a>, <a class=\"mw-redirect\" href=\"/wiki/PubMed_Identifier\" title=\"PubMed Identifier\">PMID</a> <a class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/9496632\" rel=\"nofollow\">9496632</a>, archived from <a class=\"external text\" href=\"http://www.singinst.org/upload/LOGI//LOGI.pdf\" rel=\"nofollow\">the original</a> <span class=\"cs1-format\">(PDF)</span> on 11 April 2009</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Annual+Review+of+Psychology&amp;rft.atitle=Artificial+General+Intelligence&amp;rft.volume=49&amp;rft.pages=585-612&amp;rft.date=2006&amp;rft_id=info%3Apmid%2F9496632&amp;rft_id=info%3Adoi%2F10.1146%2Fannurev.psych.49.1.585&amp;rft.isbn=978-3-540-23733-4&amp;rft.aulast=Yudkowsky&amp;rft.aufirst=Eliezer&amp;rft_id=http%3A%2F%2Fwww.singinst.org%2Fupload%2FLOGI%2F%2FLOGI.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFZucker2003\">Zucker, Jean-Daniel (July 2003), \"A grounded theory of abstraction in artificial intelligence\", <i><a href=\"/wiki/Philosophical_Transactions_of_the_Royal_Society_B\" title=\"Philosophical Transactions of the Royal Society B\">Philosophical Transactions of the Royal Society B</a></i>, <b>358</b> (1435): 1293–1309, <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a class=\"external text\" href=\"//doi.org/10.1098%2Frstb.2003.1308\" rel=\"nofollow\">10.1098/rstb.2003.1308</a>, <a href=\"/wiki/PubMed_Central\" title=\"PubMed Central\">PMC</a> <span class=\"cs1-lock-free\" title=\"Freely accessible\"><a class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC1693211\" rel=\"nofollow\">1693211</a></span>, <a class=\"mw-redirect\" href=\"/wiki/PubMed_Identifier\" title=\"PubMed Identifier\">PMID</a> <a class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/12903672\" rel=\"nofollow\">12903672</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Philosophical+Transactions+of+the+Royal+Society+B&amp;rft.atitle=A+grounded+theory+of+abstraction+in+artificial+intelligence&amp;rft.volume=358&amp;rft.issue=1435&amp;rft.pages=1293-1309&amp;rft.date=2003-07&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC1693211&amp;rft_id=info%3Apmid%2F12903672&amp;rft_id=info%3Adoi%2F10.1098%2Frstb.2003.1308&amp;rft.aulast=Zucker&amp;rft.aufirst=Jean-Daniel&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFYudkowsky2008\"><a href=\"/wiki/Eliezer_Yudkowsky\" title=\"Eliezer Yudkowsky\">Yudkowsky, Eliezer</a> (2008), \"Artificial Intelligence as a Positive and Negative Factor in Global Risk\", <i>Global Catastrophic Risks</i>, <a href=\"/wiki/Bibcode\" title=\"Bibcode\">Bibcode</a>:<a class=\"external text\" href=\"http://adsabs.harvard.edu/abs/2008gcr..book..303Y\" rel=\"nofollow\">2008gcr..book..303Y</a></cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Global+Catastrophic+Risks&amp;rft.atitle=Artificial+Intelligence+as+a+Positive+and+Negative+Factor+in+Global+Risk&amp;rft.date=2008&amp;rft_id=info%3Abibcode%2F2008gcr..book..303Y&amp;rft.aulast=Yudkowsky&amp;rft.aufirst=Eliezer&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+general+intelligence\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/>.</li></ul>\n</div>\n<h2><span class=\"mw-headline\" id=\"External_links\">External links</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_general_intelligence&amp;action=edit&amp;section=26\" title=\"Edit section: External links\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<ul><li><a class=\"external text\" href=\"http://sites.google.com/site/narswang/home/agi-introduction\" rel=\"nofollow\">The AGI portal maintained by Pei Wang</a></li>\n<li><a class=\"external text\" href=\"http://genesis.csail.mit.edu/index.html\" rel=\"nofollow\">The Genesis Group at MIT's CSAIL</a> — Modern research on the computations that underlay human intelligence</li>\n<li><a class=\"external text\" href=\"http://www.opencog.org/\" rel=\"nofollow\">OpenCog – open source project to develop a human-level AI</a></li>\n<li><a class=\"external text\" href=\"http://academia.wikia.com/wiki/A_Method_for_Simulating_the_Process_of_Logical_Human_Thought\" rel=\"nofollow\">Simulating logical human thought</a></li>\n<li><a class=\"external text\" href=\"http://www.openphilanthropy.org/focus/global-catastrophic-risks/potential-risks-advanced-artificial-intelligence/ai-timelines\" rel=\"nofollow\">What Do We Know about AI Timelines?</a> — Literature review</li></ul>\n<p class=\"mw-empty-elt\">\n</p>\n<div aria-labelledby=\"Risks_from_artificial_intelligence\" class=\"navbox\" role=\"navigation\" style=\"padding:3px\"><table class=\"nowraplinks collapsible autocollapse navbox-inner\" style=\"border-spacing:0;background:transparent;color:inherit\"><tbody><tr><th class=\"navbox-title\" colspan=\"2\" scope=\"col\"><div class=\"plainlinks hlist navbar mini\"><ul><li class=\"nv-view\"><a href=\"/wiki/Template:Existential_risk_from_artificial_intelligence\" title=\"Template:Existential risk from artificial intelligence\"><abbr style=\";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;\" title=\"View this template\">v</abbr></a></li><li class=\"nv-talk\"><a href=\"/wiki/Template_talk:Existential_risk_from_artificial_intelligence\" title=\"Template talk:Existential risk from artificial intelligence\"><abbr style=\";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;\" title=\"Discuss this template\">t</abbr></a></li><li class=\"nv-edit\"><a class=\"external text\" href=\"//en.wikipedia.org/w/index.php?title=Template:Existential_risk_from_artificial_intelligence&amp;action=edit\"><abbr style=\";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;\" title=\"Edit this template\">e</abbr></a></li></ul></div><div id=\"Risks_from_artificial_intelligence\" style=\"font-size:114%;margin:0 4em\">Risks from <a href=\"/wiki/Artificial_intelligence\" title=\"Artificial intelligence\">artificial intelligence</a></div></th></tr><tr><th class=\"navbox-group\" scope=\"row\" style=\"width:1%\">Concepts</th><td class=\"navbox-list navbox-odd hlist\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/AI_box\" title=\"AI box\">AI box</a></li>\n<li><a href=\"/wiki/AI_takeover\" title=\"AI takeover\">AI takeover</a></li>\n<li><a href=\"/wiki/AI_control_problem\" title=\"AI control problem\">Control problem</a></li>\n<li><a href=\"/wiki/Existential_risk_from_artificial_general_intelligence\" title=\"Existential risk from artificial general intelligence\">Existential risk from artificial general intelligence</a></li>\n<li><a href=\"/wiki/Friendly_artificial_intelligence\" title=\"Friendly artificial intelligence\">Friendly artificial intelligence</a></li>\n<li><a href=\"/wiki/Instrumental_convergence\" title=\"Instrumental convergence\">Instrumental convergence</a></li>\n<li><a class=\"mw-redirect\" href=\"/wiki/Intelligence_explosion\" title=\"Intelligence explosion\">Intelligence explosion</a></li>\n<li><a href=\"/wiki/Machine_ethics\" title=\"Machine ethics\">Machine ethics</a></li>\n<li><a href=\"/wiki/Superintelligence\" title=\"Superintelligence\">Superintelligence</a></li>\n<li><a href=\"/wiki/Technological_singularity\" title=\"Technological singularity\">Technological singularity</a></li></ul>\n</div></td></tr><tr><th class=\"navbox-group\" scope=\"row\" style=\"width:1%\">Organizations</th><td class=\"navbox-list navbox-even hlist\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Allen_Institute_for_Artificial_Intelligence\" title=\"Allen Institute for Artificial Intelligence\">Allen Institute for Artificial Intelligence</a></li>\n<li><a href=\"/wiki/Center_for_Applied_Rationality\" title=\"Center for Applied Rationality\">Center for Applied Rationality</a></li>\n<li><a href=\"/wiki/Centre_for_the_Study_of_Existential_Risk\" title=\"Centre for the Study of Existential Risk\">Centre for the Study of Existential Risk</a></li>\n<li><a href=\"/wiki/DeepMind\" title=\"DeepMind\">DeepMind</a></li>\n<li><a href=\"/wiki/Foundational_Questions_Institute\" title=\"Foundational Questions Institute\">Foundational Questions Institute</a></li>\n<li><a href=\"/wiki/Future_of_Humanity_Institute\" title=\"Future of Humanity Institute\">Future of Humanity Institute</a></li>\n<li><a href=\"/wiki/Future_of_Life_Institute\" title=\"Future of Life Institute\">Future of Life Institute</a></li>\n<li><a href=\"/wiki/Humanity%2B\" title=\"Humanity+\">Humanity+</a></li>\n<li><a href=\"/wiki/Institute_for_Ethics_and_Emerging_Technologies\" title=\"Institute for Ethics and Emerging Technologies\">Institute for Ethics and Emerging Technologies</a></li>\n<li><a href=\"/wiki/Leverhulme_Centre_for_the_Future_of_Intelligence\" title=\"Leverhulme Centre for the Future of Intelligence\">Leverhulme Centre for the Future of Intelligence</a></li>\n<li><a href=\"/wiki/Machine_Intelligence_Research_Institute\" title=\"Machine Intelligence Research Institute\">Machine Intelligence Research Institute</a></li>\n<li><a href=\"/wiki/OpenAI\" title=\"OpenAI\">OpenAI</a></li></ul>\n</div></td></tr><tr><th class=\"navbox-group\" scope=\"row\" style=\"width:1%\">People</th><td class=\"navbox-list navbox-odd hlist\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Nick_Bostrom\" title=\"Nick Bostrom\">Nick Bostrom</a></li>\n<li><a href=\"/wiki/Stephen_Hawking\" title=\"Stephen Hawking\">Stephen Hawking</a></li>\n<li><a href=\"/wiki/Bill_Hibbard\" title=\"Bill Hibbard\">Bill Hibbard</a></li>\n<li><a href=\"/wiki/Bill_Joy\" title=\"Bill Joy\">Bill Joy</a></li>\n<li><a href=\"/wiki/Elon_Musk\" title=\"Elon Musk\">Elon Musk</a></li>\n<li><a href=\"/wiki/Steve_Omohundro\" title=\"Steve Omohundro\">Steve Omohundro</a></li>\n<li><a href=\"/wiki/Huw_Price\" title=\"Huw Price\">Huw Price</a></li>\n<li><a href=\"/wiki/Martin_Rees\" title=\"Martin Rees\">Martin Rees</a></li>\n<li><a href=\"/wiki/Stuart_J._Russell\" title=\"Stuart J. Russell\">Stuart J. Russell</a></li>\n<li><a href=\"/wiki/Jaan_Tallinn\" title=\"Jaan Tallinn\">Jaan Tallinn</a></li>\n<li><a href=\"/wiki/Max_Tegmark\" title=\"Max Tegmark\">Max Tegmark</a></li>\n<li><a href=\"/wiki/Frank_Wilczek\" title=\"Frank Wilczek\">Frank Wilczek</a></li>\n<li><a href=\"/wiki/Roman_Yampolskiy\" title=\"Roman Yampolskiy\">Roman Yampolskiy</a></li>\n<li><a href=\"/wiki/Eliezer_Yudkowsky\" title=\"Eliezer Yudkowsky\">Eliezer Yudkowsky</a></li>\n<li><a href=\"/wiki/Sam_Harris\" title=\"Sam Harris\">Sam Harris</a></li></ul>\n</div></td></tr><tr><th class=\"navbox-group\" scope=\"row\" style=\"width:1%\">Other</th><td class=\"navbox-list navbox-even hlist\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Open_Letter_on_Artificial_Intelligence\" title=\"Open Letter on Artificial Intelligence\">Open Letter on Artificial Intelligence</a></li>\n<li><a href=\"/wiki/Ethics_of_artificial_intelligence\" title=\"Ethics of artificial intelligence\">Ethics of artificial intelligence</a></li>\n<li><a href=\"/wiki/Artificial_general_intelligence#Controversies_and_dangers\" title=\"Artificial general intelligence\">Controversies and dangers of artificial general intelligence</a></li>\n<li><a href=\"/wiki/Global_catastrophic_risk#Artificial_intelligence\" title=\"Global catastrophic risk\">Artificial intelligence as a global catastrophic risk</a></li>\n<li><i><a href=\"/wiki/Superintelligence:_Paths,_Dangers,_Strategies\" title=\"Superintelligence: Paths, Dangers, Strategies\">Superintelligence: Paths, Dangers, Strategies</a></i></li>\n<li><i><a href=\"/wiki/Our_Final_Invention\" title=\"Our Final Invention\">Our Final Invention</a></i></li></ul>\n</div></td></tr></tbody></table></div>\n<!-- \nNewPP limit report\nParsed by mw1249\nCached time: 20190225005509\nCache expiry: 2073600\nDynamic content: false\nCPU time usage: 1.120 seconds\nReal time usage: 1.319 seconds\nPreprocessor visited node count: 5996/1000000\nPreprocessor generated node count: 0/1500000\nPost‐expand include size: 186838/2097152 bytes\nTemplate argument size: 3900/2097152 bytes\nHighest expansion depth: 16/40\nExpensive parser function count: 13/500\nUnstrip recursion depth: 1/20\nUnstrip post‐expand size: 194877/5000000 bytes\nNumber of Wikibase entities loaded: 6/400\nLua time usage: 0.631/10.000 seconds\nLua memory usage: 6.89 MB/50 MB\n-->\n<!--\nTransclusion expansion time report (%,ms,calls,template)\n100.00% 1073.714      1 -total\n 40.18%  431.434      1 Template:Reflist\n 26.21%  281.408     40 Template:Citation\n 12.07%  129.638     11 Template:Cite_web\n  9.57%  102.781     10 Template:Cite_journal\n  8.00%   85.878      4 Template:Citation_needed\n  7.91%   84.941      5 Template:Fix\n  6.01%   64.496     36 Template:Sfn\n  4.29%   46.066      2 Template:ISBN\n  4.17%   44.794      9 Template:Category_handler\n-->\n<!-- Saved in parser cache with key enwiki:pcache:idhash:586357-0!canonical and timestamp 20190225005508 and revision id 884942405\n -->\n</div><noscript><img alt=\"\" height=\"1\" src=\"//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1\" style=\"border: none; position: absolute;\" title=\"\" width=\"1\"/></noscript></div> <div class=\"printfooter\">\n\t\t\t\t\t\tRetrieved from \"<a dir=\"ltr\" href=\"https://en.wikipedia.org/w/index.php?title=Artificial_general_intelligence&amp;oldid=884942405\">https://en.wikipedia.org/w/index.php?title=Artificial_general_intelligence&amp;oldid=884942405</a>\"\t\t\t\t\t</div>\n<div class=\"catlinks\" data-mw=\"interface\" id=\"catlinks\"><div class=\"mw-normal-catlinks\" id=\"mw-normal-catlinks\"><a href=\"/wiki/Help:Category\" title=\"Help:Category\">Categories</a>: <ul><li><a href=\"/wiki/Category:Hypothetical_technology\" title=\"Category:Hypothetical technology\">Hypothetical technology</a></li><li><a href=\"/wiki/Category:Artificial_intelligence\" title=\"Category:Artificial intelligence\">Artificial intelligence</a></li><li><a href=\"/wiki/Category:Computational_neuroscience\" title=\"Category:Computational neuroscience\">Computational neuroscience</a></li></ul></div><div class=\"mw-hidden-catlinks mw-hidden-cats-hidden\" id=\"mw-hidden-catlinks\">Hidden categories: <ul><li><a href=\"/wiki/Category:CS1_maint:_Archived_copy_as_title\" title=\"Category:CS1 maint: Archived copy as title\">CS1 maint: Archived copy as title</a></li><li><a href=\"/wiki/Category:All_articles_with_unsourced_statements\" title=\"Category:All articles with unsourced statements\">All articles with unsourced statements</a></li><li><a href=\"/wiki/Category:Articles_with_unsourced_statements_from_June_2011\" title=\"Category:Articles with unsourced statements from June 2011\">Articles with unsourced statements from June 2011</a></li><li><a href=\"/wiki/Category:Articles_with_unsourced_statements_from_January_2017\" title=\"Category:Articles with unsourced statements from January 2017\">Articles with unsourced statements from January 2017</a></li><li><a href=\"/wiki/Category:Articles_with_unsourced_statements_from_December_2017\" title=\"Category:Articles with unsourced statements from December 2017\">Articles with unsourced statements from December 2017</a></li><li><a href=\"/wiki/Category:Articles_with_unsourced_statements_from_April_2011\" title=\"Category:Articles with unsourced statements from April 2011\">Articles with unsourced statements from April 2011</a></li><li><a href=\"/wiki/Category:All_articles_needing_examples\" title=\"Category:All articles needing examples\">All articles needing examples</a></li><li><a href=\"/wiki/Category:Articles_needing_examples_from_September_2017\" title=\"Category:Articles needing examples from September 2017\">Articles needing examples from September 2017</a></li><li><a href=\"/wiki/Category:Articles_to_be_expanded_from_February_2016\" title=\"Category:Articles to be expanded from February 2016\">Articles to be expanded from February 2016</a></li><li><a href=\"/wiki/Category:All_articles_to_be_expanded\" title=\"Category:All articles to be expanded\">All articles to be expanded</a></li><li><a href=\"/wiki/Category:Articles_using_small_message_boxes\" title=\"Category:Articles using small message boxes\">Articles using small message boxes</a></li><li><a href=\"/wiki/Category:Use_dmy_dates_from_April_2011\" title=\"Category:Use dmy dates from April 2011\">Use dmy dates from April 2011</a></li></ul></div></div> <div class=\"visualClear\"></div>\n</div>\n</div>\n<div id=\"mw-navigation\">\n<h2>Navigation menu</h2>\n<div id=\"mw-head\">\n<div aria-labelledby=\"p-personal-label\" id=\"p-personal\" role=\"navigation\">\n<h3 id=\"p-personal-label\">Personal tools</h3>\n<ul>\n<li id=\"pt-anonuserpage\">Not logged in</li><li id=\"pt-anontalk\"><a accesskey=\"n\" href=\"/wiki/Special:MyTalk\" title=\"Discussion about edits from this IP address [n]\">Talk</a></li><li id=\"pt-anoncontribs\"><a accesskey=\"y\" href=\"/wiki/Special:MyContributions\" title=\"A list of edits made from this IP address [y]\">Contributions</a></li><li id=\"pt-createaccount\"><a href=\"/w/index.php?title=Special:CreateAccount&amp;returnto=Artificial+general+intelligence\" title=\"You are encouraged to create an account and log in; however, it is not mandatory\">Create account</a></li><li id=\"pt-login\"><a accesskey=\"o\" href=\"/w/index.php?title=Special:UserLogin&amp;returnto=Artificial+general+intelligence\" title=\"You're encouraged to log in; however, it's not mandatory. [o]\">Log in</a></li> </ul>\n</div>\n<div id=\"left-navigation\">\n<div aria-labelledby=\"p-namespaces-label\" class=\"vectorTabs\" id=\"p-namespaces\" role=\"navigation\">\n<h3 id=\"p-namespaces-label\">Namespaces</h3>\n<ul>\n<li class=\"selected\" id=\"ca-nstab-main\"><span><a accesskey=\"c\" href=\"/wiki/Artificial_general_intelligence\" title=\"View the content page [c]\">Article</a></span></li><li id=\"ca-talk\"><span><a accesskey=\"t\" href=\"/wiki/Talk:Artificial_general_intelligence\" rel=\"discussion\" title=\"Discussion about the content page [t]\">Talk</a></span></li> </ul>\n</div>\n<div aria-labelledby=\"p-variants-label\" class=\"vectorMenu emptyPortlet\" id=\"p-variants\" role=\"navigation\">\n<input aria-labelledby=\"p-variants-label\" class=\"vectorMenuCheckbox\" type=\"checkbox\"/>\n<h3 id=\"p-variants-label\">\n<span>Variants</span>\n</h3>\n<ul class=\"menu\">\n</ul>\n</div>\n</div>\n<div id=\"right-navigation\">\n<div aria-labelledby=\"p-views-label\" class=\"vectorTabs\" id=\"p-views\" role=\"navigation\">\n<h3 id=\"p-views-label\">Views</h3>\n<ul>\n<li class=\"collapsible selected\" id=\"ca-view\"><span><a href=\"/wiki/Artificial_general_intelligence\">Read</a></span></li><li class=\"collapsible\" id=\"ca-edit\"><span><a accesskey=\"e\" href=\"/w/index.php?title=Artificial_general_intelligence&amp;action=edit\" title=\"Edit this page [e]\">Edit</a></span></li><li class=\"collapsible\" id=\"ca-history\"><span><a accesskey=\"h\" href=\"/w/index.php?title=Artificial_general_intelligence&amp;action=history\" title=\"Past revisions of this page [h]\">View history</a></span></li> </ul>\n</div>\n<div aria-labelledby=\"p-cactions-label\" class=\"vectorMenu emptyPortlet\" id=\"p-cactions\" role=\"navigation\">\n<input aria-labelledby=\"p-cactions-label\" class=\"vectorMenuCheckbox\" type=\"checkbox\"/>\n<h3 id=\"p-cactions-label\"><span>More</span></h3>\n<ul class=\"menu\">\n</ul>\n</div>\n<div id=\"p-search\" role=\"search\">\n<h3>\n<label for=\"searchInput\">Search</label>\n</h3>\n<form action=\"/w/index.php\" id=\"searchform\">\n<div id=\"simpleSearch\">\n<input accesskey=\"f\" id=\"searchInput\" name=\"search\" placeholder=\"Search Wikipedia\" title=\"Search Wikipedia [f]\" type=\"search\"/><input name=\"title\" type=\"hidden\" value=\"Special:Search\"/><input class=\"searchButton mw-fallbackSearchButton\" id=\"mw-searchButton\" name=\"fulltext\" title=\"Search Wikipedia for this text\" type=\"submit\" value=\"Search\"/><input class=\"searchButton\" id=\"searchButton\" name=\"go\" title=\"Go to a page with this exact name if it exists\" type=\"submit\" value=\"Go\"/> </div>\n</form>\n</div>\n</div>\n</div>\n<div id=\"mw-panel\">\n<div id=\"p-logo\" role=\"banner\"><a class=\"mw-wiki-logo\" href=\"/wiki/Main_Page\" title=\"Visit the main page\"></a></div>\n<div aria-labelledby=\"p-navigation-label\" class=\"portal\" id=\"p-navigation\" role=\"navigation\">\n<h3 id=\"p-navigation-label\">Navigation</h3>\n<div class=\"body\">\n<ul>\n<li id=\"n-mainpage-description\"><a accesskey=\"z\" href=\"/wiki/Main_Page\" title=\"Visit the main page [z]\">Main page</a></li><li id=\"n-contents\"><a href=\"/wiki/Portal:Contents\" title=\"Guides to browsing Wikipedia\">Contents</a></li><li id=\"n-featuredcontent\"><a href=\"/wiki/Portal:Featured_content\" title=\"Featured content – the best of Wikipedia\">Featured content</a></li><li id=\"n-currentevents\"><a href=\"/wiki/Portal:Current_events\" title=\"Find background information on current events\">Current events</a></li><li id=\"n-randompage\"><a accesskey=\"x\" href=\"/wiki/Special:Random\" title=\"Load a random article [x]\">Random article</a></li><li id=\"n-sitesupport\"><a href=\"https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_en.wikipedia.org&amp;uselang=en\" title=\"Support us\">Donate to Wikipedia</a></li><li id=\"n-shoplink\"><a href=\"//shop.wikimedia.org\" title=\"Visit the Wikipedia store\">Wikipedia store</a></li> </ul>\n</div>\n</div>\n<div aria-labelledby=\"p-interaction-label\" class=\"portal\" id=\"p-interaction\" role=\"navigation\">\n<h3 id=\"p-interaction-label\">Interaction</h3>\n<div class=\"body\">\n<ul>\n<li id=\"n-help\"><a href=\"/wiki/Help:Contents\" title=\"Guidance on how to use and edit Wikipedia\">Help</a></li><li id=\"n-aboutsite\"><a href=\"/wiki/Wikipedia:About\" title=\"Find out about Wikipedia\">About Wikipedia</a></li><li id=\"n-portal\"><a href=\"/wiki/Wikipedia:Community_portal\" title=\"About the project, what you can do, where to find things\">Community portal</a></li><li id=\"n-recentchanges\"><a accesskey=\"r\" href=\"/wiki/Special:RecentChanges\" title=\"A list of recent changes in the wiki [r]\">Recent changes</a></li><li id=\"n-contactpage\"><a href=\"//en.wikipedia.org/wiki/Wikipedia:Contact_us\" title=\"How to contact Wikipedia\">Contact page</a></li> </ul>\n</div>\n</div>\n<div aria-labelledby=\"p-tb-label\" class=\"portal\" id=\"p-tb\" role=\"navigation\">\n<h3 id=\"p-tb-label\">Tools</h3>\n<div class=\"body\">\n<ul>\n<li id=\"t-whatlinkshere\"><a accesskey=\"j\" href=\"/wiki/Special:WhatLinksHere/Artificial_general_intelligence\" title=\"List of all English Wikipedia pages containing links to this page [j]\">What links here</a></li><li id=\"t-recentchangeslinked\"><a accesskey=\"k\" href=\"/wiki/Special:RecentChangesLinked/Artificial_general_intelligence\" rel=\"nofollow\" title=\"Recent changes in pages linked from this page [k]\">Related changes</a></li><li id=\"t-upload\"><a accesskey=\"u\" href=\"/wiki/Wikipedia:File_Upload_Wizard\" title=\"Upload files [u]\">Upload file</a></li><li id=\"t-specialpages\"><a accesskey=\"q\" href=\"/wiki/Special:SpecialPages\" title=\"A list of all special pages [q]\">Special pages</a></li><li id=\"t-permalink\"><a href=\"/w/index.php?title=Artificial_general_intelligence&amp;oldid=884942405\" title=\"Permanent link to this revision of the page\">Permanent link</a></li><li id=\"t-info\"><a href=\"/w/index.php?title=Artificial_general_intelligence&amp;action=info\" title=\"More information about this page\">Page information</a></li><li id=\"t-wikibase\"><a accesskey=\"g\" href=\"https://www.wikidata.org/wiki/Special:EntityPage/Q2264109\" title=\"Link to connected data repository item [g]\">Wikidata item</a></li><li id=\"t-cite\"><a href=\"/w/index.php?title=Special:CiteThisPage&amp;page=Artificial_general_intelligence&amp;id=884942405\" title=\"Information on how to cite this page\">Cite this page</a></li> </ul>\n</div>\n</div>\n<div aria-labelledby=\"p-coll-print_export-label\" class=\"portal\" id=\"p-coll-print_export\" role=\"navigation\">\n<h3 id=\"p-coll-print_export-label\">Print/export</h3>\n<div class=\"body\">\n<ul>\n<li id=\"coll-create_a_book\"><a href=\"/w/index.php?title=Special:Book&amp;bookcmd=book_creator&amp;referer=Artificial+general+intelligence\">Create a book</a></li><li id=\"coll-download-as-rdf2latex\"><a href=\"/w/index.php?title=Special:ElectronPdf&amp;page=Artificial+general+intelligence&amp;action=show-download-screen\">Download as PDF</a></li><li id=\"t-print\"><a accesskey=\"p\" href=\"/w/index.php?title=Artificial_general_intelligence&amp;printable=yes\" title=\"Printable version of this page [p]\">Printable version</a></li> </ul>\n</div>\n</div>\n<div aria-labelledby=\"p-lang-label\" class=\"portal\" id=\"p-lang\" role=\"navigation\">\n<h3 id=\"p-lang-label\">Languages</h3>\n<div class=\"body\">\n<ul>\n<li class=\"interlanguage-link interwiki-ca\"><a class=\"interlanguage-link-target\" href=\"https://ca.wikipedia.org/wiki/Intel%C2%B7lig%C3%A8ncia_artificial_forta\" hreflang=\"ca\" lang=\"ca\" title=\"Intel·ligència artificial forta – Catalan\">Català</a></li><li class=\"interlanguage-link interwiki-cs\"><a class=\"interlanguage-link-target\" href=\"https://cs.wikipedia.org/wiki/Um%C4%9Bl%C3%A9_byt%C3%AD\" hreflang=\"cs\" lang=\"cs\" title=\"Umělé bytí – Czech\">Čeština</a></li><li class=\"interlanguage-link interwiki-es\"><a class=\"interlanguage-link-target\" href=\"https://es.wikipedia.org/wiki/Inteligencia_artificial_fuerte\" hreflang=\"es\" lang=\"es\" title=\"Inteligencia artificial fuerte – Spanish\">Español</a></li><li class=\"interlanguage-link interwiki-eu\"><a class=\"interlanguage-link-target\" href=\"https://eu.wikipedia.org/wiki/Adimen_artifizial_orokorra\" hreflang=\"eu\" lang=\"eu\" title=\"Adimen artifizial orokorra – Basque\">Euskara</a></li><li class=\"interlanguage-link interwiki-fa\"><a class=\"interlanguage-link-target\" href=\"https://fa.wikipedia.org/wiki/%D9%87%D9%88%D8%B4_%D8%B9%D9%85%D9%88%D9%85%DB%8C_%D9%85%D8%B5%D9%86%D9%88%D8%B9%DB%8C\" hreflang=\"fa\" lang=\"fa\" title=\"هوش عمومی مصنوعی – Persian\">فارسی</a></li><li class=\"interlanguage-link interwiki-fr\"><a class=\"interlanguage-link-target\" href=\"https://fr.wikipedia.org/wiki/Intelligence_artificielle#Intelligence_artificielle_forte\" hreflang=\"fr\" lang=\"fr\" title=\"Intelligence artificielle – French\">Français</a></li><li class=\"interlanguage-link interwiki-ko\"><a class=\"interlanguage-link-target\" href=\"https://ko.wikipedia.org/wiki/%EC%9D%B8%EA%B3%B5_%EC%9D%BC%EB%B0%98_%EC%A7%80%EB%8A%A5\" hreflang=\"ko\" lang=\"ko\" title=\"인공 일반 지능 – Korean\">한국어</a></li><li class=\"interlanguage-link interwiki-id\"><a class=\"interlanguage-link-target\" href=\"https://id.wikipedia.org/wiki/Kecerdasan_umum_buatan\" hreflang=\"id\" lang=\"id\" title=\"Kecerdasan umum buatan – Indonesian\">Bahasa Indonesia</a></li><li class=\"interlanguage-link interwiki-it\"><a class=\"interlanguage-link-target\" href=\"https://it.wikipedia.org/wiki/Intelligenza_artificiale_forte\" hreflang=\"it\" lang=\"it\" title=\"Intelligenza artificiale forte – Italian\">Italiano</a></li><li class=\"interlanguage-link interwiki-he\"><a class=\"interlanguage-link-target\" href=\"https://he.wikipedia.org/wiki/%D7%91%D7%99%D7%A0%D7%94_%D7%9E%D7%9C%D7%90%D7%9B%D7%95%D7%AA%D7%99%D7%AA_%D7%97%D7%96%D7%A7%D7%94\" hreflang=\"he\" lang=\"he\" title=\"בינה מלאכותית חזקה – Hebrew\">עברית</a></li><li class=\"interlanguage-link interwiki-ja\"><a class=\"interlanguage-link-target\" href=\"https://ja.wikipedia.org/wiki/%E5%BC%B7%E3%81%84AI%E3%81%A8%E5%BC%B1%E3%81%84AI\" hreflang=\"ja\" lang=\"ja\" title=\"強いAIと弱いAI – Japanese\">日本語</a></li><li class=\"interlanguage-link interwiki-pl\"><a class=\"interlanguage-link-target\" href=\"https://pl.wikipedia.org/wiki/Silna_sztuczna_inteligencja\" hreflang=\"pl\" lang=\"pl\" title=\"Silna sztuczna inteligencja – Polish\">Polski</a></li><li class=\"interlanguage-link interwiki-ru\"><a class=\"interlanguage-link-target\" href=\"https://ru.wikipedia.org/wiki/%D0%A1%D0%B8%D0%BB%D1%8C%D0%BD%D1%8B%D0%B9_%D0%B8_%D1%81%D0%BB%D0%B0%D0%B1%D1%8B%D0%B9_%D0%B8%D1%81%D0%BA%D1%83%D1%81%D1%81%D1%82%D0%B2%D0%B5%D0%BD%D0%BD%D1%8B%D0%B5_%D0%B8%D0%BD%D1%82%D0%B5%D0%BB%D0%BB%D0%B5%D0%BA%D1%82%D1%8B\" hreflang=\"ru\" lang=\"ru\" title=\"Сильный и слабый искусственные интеллекты – Russian\">Русский</a></li><li class=\"interlanguage-link interwiki-sv\"><a class=\"interlanguage-link-target\" href=\"https://sv.wikipedia.org/wiki/Artificiell_generell_intelligens\" hreflang=\"sv\" lang=\"sv\" title=\"Artificiell generell intelligens – Swedish\">Svenska</a></li><li class=\"interlanguage-link interwiki-th\"><a class=\"interlanguage-link-target\" href=\"https://th.wikipedia.org/wiki/%E0%B8%9B%E0%B8%B1%E0%B8%8D%E0%B8%8D%E0%B8%B2%E0%B8%9B%E0%B8%A3%E0%B8%B0%E0%B8%94%E0%B8%B4%E0%B8%A9%E0%B8%90%E0%B9%8C%E0%B8%97%E0%B8%B1%E0%B9%88%E0%B8%A7%E0%B9%84%E0%B8%9B\" hreflang=\"th\" lang=\"th\" title=\"ปัญญาประดิษฐ์ทั่วไป – Thai\">ไทย</a></li><li class=\"interlanguage-link interwiki-tr\"><a class=\"interlanguage-link-target\" href=\"https://tr.wikipedia.org/wiki/Yapay_genel_zek%C3%A2\" hreflang=\"tr\" lang=\"tr\" title=\"Yapay genel zekâ – Turkish\">Türkçe</a></li><li class=\"interlanguage-link interwiki-uk\"><a class=\"interlanguage-link-target\" href=\"https://uk.wikipedia.org/wiki/%D0%A1%D0%B8%D0%BB%D1%8C%D0%BD%D0%B8%D0%B9_%D1%88%D1%82%D1%83%D1%87%D0%BD%D0%B8%D0%B9_%D1%96%D0%BD%D1%82%D0%B5%D0%BB%D0%B5%D0%BA%D1%82\" hreflang=\"uk\" lang=\"uk\" title=\"Сильний штучний інтелект – Ukrainian\">Українська</a></li><li class=\"interlanguage-link interwiki-zh\"><a class=\"interlanguage-link-target\" href=\"https://zh.wikipedia.org/wiki/%E5%BC%B7%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7\" hreflang=\"zh\" lang=\"zh\" title=\"強人工智慧 – Chinese\">中文</a></li> </ul>\n<div class=\"after-portlet after-portlet-lang\"><span class=\"wb-langlinks-edit wb-langlinks-link\"><a class=\"wbc-editpage\" href=\"https://www.wikidata.org/wiki/Special:EntityPage/Q2264109#sitelinks-wikipedia\" title=\"Edit interlanguage links\">Edit links</a></span></div> </div>\n</div>\n</div>\n</div>\n<div id=\"footer\" role=\"contentinfo\">\n<ul id=\"footer-info\">\n<li id=\"footer-info-lastmod\"> This page was last edited on 25 February 2019, at 00:15<span class=\"anonymous-show\"> (UTC)</span>.</li>\n<li id=\"footer-info-copyright\">Text is available under the <a href=\"//en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License\" rel=\"license\">Creative Commons Attribution-ShareAlike License</a><a href=\"//creativecommons.org/licenses/by-sa/3.0/\" rel=\"license\" style=\"display:none;\"></a>;\nadditional terms may apply.  By using this site, you agree to the <a href=\"//foundation.wikimedia.org/wiki/Terms_of_Use\">Terms of Use</a> and <a href=\"//foundation.wikimedia.org/wiki/Privacy_policy\">Privacy Policy</a>. Wikipedia® is a registered trademark of the <a href=\"//www.wikimediafoundation.org/\">Wikimedia Foundation, Inc.</a>, a non-profit organization.</li>\n</ul>\n<ul id=\"footer-places\">\n<li id=\"footer-places-privacy\"><a class=\"extiw\" href=\"https://foundation.wikimedia.org/wiki/Privacy_policy\" title=\"wmf:Privacy policy\">Privacy policy</a></li>\n<li id=\"footer-places-about\"><a href=\"/wiki/Wikipedia:About\" title=\"Wikipedia:About\">About Wikipedia</a></li>\n<li id=\"footer-places-disclaimer\"><a href=\"/wiki/Wikipedia:General_disclaimer\" title=\"Wikipedia:General disclaimer\">Disclaimers</a></li>\n<li id=\"footer-places-contact\"><a href=\"//en.wikipedia.org/wiki/Wikipedia:Contact_us\">Contact Wikipedia</a></li>\n<li id=\"footer-places-developers\"><a href=\"https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute\">Developers</a></li>\n<li id=\"footer-places-cookiestatement\"><a href=\"https://foundation.wikimedia.org/wiki/Cookie_statement\">Cookie statement</a></li>\n<li id=\"footer-places-mobileview\"><a class=\"noprint stopMobileRedirectToggle\" href=\"//en.m.wikipedia.org/w/index.php?title=Artificial_general_intelligence&amp;mobileaction=toggle_view_mobile\">Mobile view</a></li>\n</ul>\n<ul class=\"noprint\" id=\"footer-icons\">\n<li id=\"footer-copyrightico\">\n<a href=\"https://wikimediafoundation.org/\"><img alt=\"Wikimedia Foundation\" height=\"31\" src=\"/static/images/wikimedia-button.png\" srcset=\"/static/images/wikimedia-button-1.5x.png 1.5x, /static/images/wikimedia-button-2x.png 2x\" width=\"88\"/></a> </li>\n<li id=\"footer-poweredbyico\">\n<a href=\"//www.mediawiki.org/\"><img alt=\"Powered by MediaWiki\" height=\"31\" src=\"/static/images/poweredby_mediawiki_88x31.png\" srcset=\"/static/images/poweredby_mediawiki_132x47.png 1.5x, /static/images/poweredby_mediawiki_176x62.png 2x\" width=\"88\"/></a> </li>\n</ul>\n<div style=\"clear: both;\"></div>\n</div>\n<script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({\"wgPageParseReport\":{\"limitreport\":{\"cputime\":\"1.120\",\"walltime\":\"1.319\",\"ppvisitednodes\":{\"value\":5996,\"limit\":1000000},\"ppgeneratednodes\":{\"value\":0,\"limit\":1500000},\"postexpandincludesize\":{\"value\":186838,\"limit\":2097152},\"templateargumentsize\":{\"value\":3900,\"limit\":2097152},\"expansiondepth\":{\"value\":16,\"limit\":40},\"expensivefunctioncount\":{\"value\":13,\"limit\":500},\"unstrip-depth\":{\"value\":1,\"limit\":20},\"unstrip-size\":{\"value\":194877,\"limit\":5000000},\"entityaccesscount\":{\"value\":6,\"limit\":400},\"timingprofile\":[\"100.00% 1073.714      1 -total\",\" 40.18%  431.434      1 Template:Reflist\",\" 26.21%  281.408     40 Template:Citation\",\" 12.07%  129.638     11 Template:Cite_web\",\"  9.57%  102.781     10 Template:Cite_journal\",\"  8.00%   85.878      4 Template:Citation_needed\",\"  7.91%   84.941      5 Template:Fix\",\"  6.01%   64.496     36 Template:Sfn\",\"  4.29%   46.066      2 Template:ISBN\",\"  4.17%   44.794      9 Template:Category_handler\"]},\"scribunto\":{\"limitreport-timeusage\":{\"value\":\"0.631\",\"limit\":\"10.000\"},\"limitreport-memusage\":{\"value\":7223925,\"limit\":52428800}},\"cachereport\":{\"origin\":\"mw1249\",\"timestamp\":\"20190225005509\",\"ttl\":2073600,\"transientcontent\":false}}});mw.config.set({\"wgBackendResponseTime\":1439,\"wgHostname\":\"mw1249\"});});</script>\n</body>\n</html>\n",
  "table_of_contents": [
    "1 Requirements",
    "1.1 Tests for confirming human-level AGI[13]",
    "1.2 IQ-Tests AGI",
    "2 Problems requiring AGI to solve",
    "3 Classical AI",
    "4 Current narrow AI research",
    "5 Artificial general intelligence research",
    "6 Processing power needed to simulate a brain",
    "6.1 Whole brain emulation",
    "6.2 Early estimates",
    "6.3 Modelling the neurons in more detail",
    "6.4 Current research",
    "6.5 Complications of and criticisms to AI approaches, based on simulation",
    "7 Artificial consciousness research",
    "8 Relationship to \"strong AI\"",
    "9 Possible explanations for the slow progress of AI research",
    "10 Consciousness",
    "11 Controversies and dangers",
    "11.1 Feasibility",
    "11.2 Potential threat to human existence",
    "11.2.1 Self-replicating machines",
    "11.2.2 Emergent superintelligence",
    "12 See also",
    "13 Notes",
    "14 References",
    "15 External links"
  ],
  "graphics": [
    {
      "url": "/wiki/File:Estimations_of_Human_Brain_Emulation_Required_Performance.svg",
      "caption": "Estimates of how much processing power is needed to emulate a human brain at various levels (from Ray Kurzweil, and Anders Sandberg and Nick Bostrom), along with the fastest supercomputer from TOP500 mapped by year. Note the logarithmic scale and exponential trendline, which assumes the computational capacity doubles every 1.1 years. Kurzweil believes that mind uploading will be possible at neural simulation, while the Sandberg, Bostrom report is less certain about where consciousness arises.[45]"
    }
  ],
  "paragraphs": [
    {
      "title": "",
      "text": "Artificial general intelligence (AGI) is the intelligence of a machine that could successfully perform any intellectual task that a human being can. It is a primary goal of some artificial intelligence research and a common topic in science fiction and future studies. Some researchers refer to Artificial general intelligence as \"strong AI\",[1] \"full AI\"[2] or as the ability of a machine to perform \"general intelligent action\"[3]; others reserve \"strong AI\" for machines capable of experiencing consciousness.\n\nSome references emphasize a distinction between strong AI and \"applied AI\"[4] (also called \"narrow AI\"[1] or \"weak AI\"[5]): the use of software to study or accomplish specific problem solving or reasoning tasks. Weak AI, in contrast to strong AI, does not attempt to perform the full range of human cognitive abilities.\n\nAs of 2017, over forty organizations worldwide are doing active research on AGI.[6]\n\n"
    },
    {
      "title": "Requirements",
      "text": "Various criteria for intelligence have been proposed (most famously the Turing test) but to date, there is no definition that satisfies everyone.[7] However, there is wide agreement among artificial intelligence researchers that intelligence is required to do the following:[8]\n\nOther important capabilities include the ability to sense (e.g. see) and the ability to act (e.g. move and manipulate objects) in the world where intelligent behaviour is to be observed.[9] This would include an ability to detect and respond to hazard.[10] Many interdisciplinary approaches to intelligence (e.g. cognitive science, computational intelligence and decision making) tend to emphasise the need to consider additional traits such as imagination (taken as the ability to form mental images and concepts that were not programmed in)[11] and autonomy.[12]\nComputer based systems that exhibit many of these capabilities do exist (e.g. see computational creativity, automated reasoning, decision support system, robot, evolutionary computation, intelligent agent), but not yet at human levels.\n\nChinese researchers Feng Liu, Yong Shi and Ying Liu conducted intelligence tests in the summer of 2017 with public available and freely accessible weak AI such as Google AI or Apple's Siri and others. At the maximum, these AI reached a value of about 47, which corresponds approximately to a six-year-old child in first grade. An adult comes to about 100 on average. In 2014, similar tests were carried out in which the AI reached a maximum value of 27. [14][15].\n\n"
    },
    {
      "title": "Problems requiring AGI to solve",
      "text": "The most difficult problems for computers are informally known as \"AI-complete\" or \"AI-hard\", implying that solving them is equivalent to the general aptitude of human intelligence, or strong AI, beyond the capabilities of a purpose-specific algorithm.[16]\n\nAI-complete problems are hypothesised to include general computer vision, natural language understanding, and dealing with unexpected circumstances while solving any real world problem.[17]\n\nAI-complete problems cannot be solved with current computer technology alone, and also require human computation.  This property can be useful to test for the presence of humans, as with CAPTCHAs, and for computer security to repel brute-force attacks.[18][19]\n\n"
    },
    {
      "title": "Classical AI",
      "text": "Modern AI research began in the mid 1950s.[20] The first generation of AI researchers was convinced that artificial general intelligence was possible and that it would exist in just a few decades. As AI pioneer Herbert A. Simon wrote in 1965: \"machines will be capable, within twenty years, of doing any work a man can do.\"[21] Their predictions were the inspiration for Stanley Kubrick and Arthur C. Clarke's character HAL 9000, who accurately embodied what AI researchers believed they could create by the year 2001. Of note is the fact that AI pioneer Marvin Minsky was a consultant[22] on the project of making HAL 9000 as realistic as possible according to the consensus predictions of the time; Crevier quotes him as having said on the subject in 1967, \"Within a generation ... the problem of creating 'artificial intelligence' will substantially be solved,\"[23] although Minsky states that he was misquoted.[citation needed]\n\nHowever, in the early 1970s, it became obvious that researchers had grossly underestimated the difficulty of the project. Funding agencies became skeptical of AGI and put researchers under increasing pressure to produce useful \"applied AI\".[24] As the 1980s began, Japan's Fifth Generation Computer Project revived interest in AGI, setting out a ten-year timeline that included AGI goals like \"carry on a casual conversation\".[25] In response to this and the success of expert systems, both industry and government pumped money back into the field.[26] However, confidence in AI spectacularly collapsed in the late 1980s, and the goals of the Fifth Generation Computer Project were never fulfilled.[27] For the second time in 20 years, AI researchers who had predicted the imminent achievement of AGI had been shown to be fundamentally mistaken. By the 1990s, AI researchers had gained a reputation for making vain promises. They became reluctant to make predictions at all[28] and to avoid any mention of \"human level\" artificial intelligence for fear of being labeled \"wild-eyed dreamer[s].\"[29]\n\n"
    },
    {
      "title": "Current narrow AI research",
      "text": "In the 1990s and early 21st century, mainstream AI has achieved far greater commercial success and academic respectability by focusing on specific sub-problems where they can produce verifiable results and commercial applications, such as artificial neural networks, computer vision or data mining.[30] These \"applied AI\" systems are now used extensively throughout the technology industry, and research in this vein is very heavily funded in both academia and industry.\n\n\nMost mainstream AI researchers hope that strong AI can be developed by combining the programs that solve various sub-problems using an integrated agent architecture, cognitive architecture or subsumption architecture. Hans Moravec wrote in 1988: \n\nHowever, even this fundamental philosophy has been disputed; for example, Stevan Harnad of Princeton concluded his 1990 paper on the Symbol Grounding Hypothesis by stating: \n"
    },
    {
      "title": "Artificial general intelligence research",
      "text": "Artificial general intelligence[33] (AGI) describes research that aims to create machines capable of general intelligent action. The term was used as early as 1997, by Mark Gubrud[34] in a discussion of the implications of fully automated military production and operations. The term was re-introduced and popularized by Shane Legg and Ben Goertzel around 2002.[35] The research objective is much older, for example Doug Lenat's Cyc project (that began in 1984), and Allen Newell's Soar project are regarded as within the scope of AGI. AGI research activity in 2006 was described by Pei Wang and Ben Goertzel[36] as \"producing publications and preliminary results\". As yet, most AI researchers have devoted little attention to AGI, with some claiming that intelligence is too complex to be completely replicated in the near term. However, a small number of computer scientists are active in AGI research, and many of this group are contributing to a series of AGI conferences. The research is extremely diverse and often pioneering in nature. In the introduction to his book,[33] Goertzel says that estimates of the time needed before a truly flexible AGI is built vary from 10 years to over a century, but the consensus in the AGI research community seems to be that the timeline discussed by Ray Kurzweil in The Singularity is Near[1] (i.e. between 2015 and 2045) is plausible.[37] Most mainstream AI researchers doubt that progress will be this rapid.[citation needed] Organizations explicitly pursuing AGI include the Swiss AI lab IDSIA,[citation needed] Nnaisense,[38] Vicarious, Maluuba,[6] the OpenCog Foundation, Adaptive AI, LIDA, and Numenta and the associated Redwood Neuroscience Institute.[39] In addition, organizations such as the Machine Intelligence Research Institute[40] and OpenAI[41] have been founded to influence the development path of AGI. Finally, projects such as the Human Brain Project[42] have the goal of building a functioning simulation of the human brain. A 2017 survey of AGI categorized forty-five known \"active R&D projects\" that explicitly or implicitly (through published research) research AGI, with the largest three being DeepMind, the Human Brain Project, and OpenAI based article [43].\n\nNamely DeepMind with their success in Human Player Simulation for e.g AlphaGo made use of new concepts:\n\n"
    },
    {
      "title": "Processing power needed to simulate a brain",
      "text": "A popular approach discussed to achieving general intelligent action is whole brain emulation. A low-level brain model is built by scanning and mapping a biological brain in detail and copying its state into a computer system or another computational device. The computer runs a simulation model so faithful to the original that it will behave in essentially the same way as the original brain, or for all practical purposes, indistinguishably.[44] Whole brain emulation is discussed in computational neuroscience and neuroinformatics, in the context of brain simulation for medical research purposes. It is discussed in artificial intelligence research[37] as an approach to strong AI. Neuroimaging technologies that could deliver the necessary detailed understanding are improving rapidly, and futurist Ray Kurzweil in the book The Singularity Is Near[1] predicts that a map of sufficient quality will become available on a similar timescale to the required computing power.\n\n For low-level brain simulation, an extremely powerful computer would be required. The human brain has a huge number of synapses. Each of the 1011 (one hundred billion) neurons has on average 7,000 synaptic connections to other neurons. It has been estimated that the brain of a three-year-old child has about 1015 synapses (1 quadrillion). This number declines with age, stabilizing by adulthood. Estimates vary for an adult, ranging from 1014 to 5×1014 synapses (100 to 500 trillion).[46] An estimate of the brain's processing power, based on a simple switch model for neuron activity, is around 1014 (100 trillion) synaptic updates per second (SUPS).[47] In 1997 Kurzweil looked at various estimates for the hardware required to equal the human brain and adopted a figure of 1016 computations per second (cps).[48] (For comparison, if a \"computation\" was equivalent to one \"floating point operation\" –  a measure used to rate current supercomputers – then 1016 \"computations\" would be equivalent to 10 petaFLOPS, achieved in 2011). He used this figure to predict the necessary hardware would be available sometime between 2015 and 2025, if the exponential growth in computer power at the time of writing continued.\n\nThe artificial neuron model assumed by Kurzweil and used in many current artificial neural network implementations is simple compared with biological neurons. A brain simulation would likely have to capture the detailed cellular behaviour of biological neurons, presently only understood in the broadest of outlines. The overhead introduced by full modeling of the biological, chemical, and physical details of neural behaviour (especially on a molecular scale) would require computational powers several orders of magnitude larger than Kurzweil's estimate.  In addition the estimates do not account for glial cells, which are at least as numerous as neurons, and which may outnumber neurons by as much as 10:1, and are now known to play a role in cognitive processes.[49]\n\nThere are some research projects that are investigating brain simulation using more sophisticated neural models, implemented on conventional computing architectures. The Artificial Intelligence System project implemented non-real time simulations of a \"brain\" (with 1011 neurons) in 2005. It took 50 days on a cluster of 27 processors to simulate 1 second of a model.[50] The Blue Brain project used one of the fastest supercomputer architectures in the world, IBM's Blue Gene platform, to create a real time simulation of a single rat neocortical column consisting of approximately 10,000 neurons and 108 synapses in 2006.[51] A longer term goal is to build a detailed, functional simulation of the physiological processes in the human brain: \"It is not impossible to build a human brain and we can do it in 10 years,\" Henry Markram, director of the Blue Brain Project said in 2009 at the TED conference in Oxford.[52] There have also been controversial claims to have simulated a cat brain. Neuro-silicon interfaces have been proposed as an alternative implementation strategy that may scale better.[53]\n\nHans Moravec addressed the above arguments (\"brains are more complicated\", \"neurons have to be modeled in more detail\") in his 1997 paper \"When will computer hardware match the human brain?\".[54]  He measured the ability of existing software to simulate the functionality of neural tissue, specifically the retina.  His results do not depend on the number of glial cells, nor on what kinds of processing neurons perform where.\n\nThe actual complexity of modeling biological neurons has been explored in OpenWorm project  that was aimed on complete simulation of a worm that only has 302 neurons in its neural network (among about 1000 cells in total). The animal's neural network has been well documented prior start of the project. However the task seemed simple at the beginning, models based on generic neural network didn't work. Currently the efforts are focused on precise emulation of the biological neurons (partly on molecular level), but the result can't be called a total success yet. Even if the number of issues to be solved in a human-brain-scale model is not proportional to the number of neurons, the amount of work along this path is obvious.\n\nA fundamental criticism of the simulated brain approach derives from embodied cognition where human embodiment is taken as an essential aspect of human intelligence. Many researchers believe that embodiment is necessary to ground meaning.[55] If this view is correct, any fully functional brain model will need to encompass more than just the neurons (i.e., a robotic body). Goertzel[37] proposes virtual embodiment (like Second Life), but it is not yet known whether this would be sufficient.\n\nDesktop computers using microprocessors capable of more than 109 cps (Kurzweil's non-standard unit \"computations per second\", see above) have been available since 2005. According to the brain power estimates used by Kurzweil (and Moravec), this computer should be capable of supporting a simulation of a bee brain, but despite some interest[56] no such simulation exists[citation needed]. There are at least three reasons for this:\n\nIn addition, the scale of the human brain is not currently well-constrained. One estimate puts the human brain at about 100 billion neurons and 100 trillion synapses.[59][60] Another estimate is 86 billion neurons of which 16.3 billion are in the cerebral cortex and 69 billion in the cerebellum.[61] Glial cell synapses are currently unquantified but are known to be extremely numerous.\n\n"
    },
    {
      "title": "Artificial consciousness research",
      "text": "Although the role of consciousness in strong AI/AGI is debatable, many AGI researchers[62] regard research that investigates possibilities for implementing consciousness as vital. In an early effort Igor Aleksander[63] argued that the principles for creating a conscious machine already existed but that it would take forty years to train such a machine to understand language.\n\n"
    },
    {
      "title": "",
      "text": "In 1980, philosopher John Searle coined the term \"strong AI\" as part of his Chinese room argument.[64] He wanted to distinguish between two different hypotheses about artificial intelligence:[65]\n\nThe first one is called \"the strong AI hypothesis\" and the second is \"the weak AI hypothesis\" because the first one makes the stronger statement: it assumes something special has happened to the machine that goes beyond all its abilities that we can test. Searle referred to the \"strong AI hypothesis\" as \"strong AI\". This usage is also common in academic AI research and textbooks.[66]\n\nThe weak AI hypothesis is equivalent to the hypothesis that artificial general intelligence is possible. According to Russell and Norvig, \"Most AI researchers take the weak AI hypothesis for granted, and don't care about the strong AI hypothesis.\"[67]\n\nIn contrast to Searle, Kurzweil uses the term \"strong AI\" to describe any artificial intelligence system that acts like it has a mind,[1] regardless of whether a philosopher would be able to determine if it actually has a mind or not.\n\n"
    },
    {
      "title": "Possible explanations for the slow progress of AI research",
      "text": "Since the launch of AI research in 1956, the growth of this field has slowed down over time and has stalled the aims of creating machines skilled with intelligent action at the human level.[68] A possible explanation for this delay is that computers lack a sufficient scope of memory or processing power.[68] In addition, the level of complexity that connects to the process of AI research may also limit the progress of AI research.[68]\n\nWhile most AI researchers believe strong AI can be achieved in the future, there are some individuals like Hubert Dreyfus and Roger Penrose who deny the possibility of achieving strong AI.[68] John McCarthy was one of various computer scientists who believe human-level AI will be accomplished, but a date cannot accurately be predicted.[69]\n\nConceptual limitations are another possible reason for the slowness in AI research.[68] AI researchers may need to modify the conceptual framework of their discipline in order to provide a stronger base and contribution to the quest of achieving strong AI. As William Clocksin wrote in 2003: \"the framework starts from Weizenbaum’s observation that intelligence manifests itself only relative to specific social and cultural contexts\".[68]\n\nFurthermore, AI researchers have been able to create computers that can perform jobs that are complicated for people to do, but conversely they have struggled to develop a computer that is capable of carrying out tasks that are simple for humans to do[example  needed].[68] A problem described by David Gelernter is that some people assume thinking and reasoning are equivalent.[70] However, the idea of whether thoughts and the creator of those thoughts are isolated individually has intrigued AI researchers.[70]\n\nThe problems that have been encountered in AI research over the past decades have further impeded the progress of AI. The failed predictions that have been promised by AI researchers and the lack of a complete understanding of human behaviors have helped diminish the primary idea of human-level AI.[37] Although the progress of AI research has brought both improvement and disappointment, most investigators have established optimism about potentially achieving the goal of AI in the 21st century.[37]\n\nOther possible reasons have been proposed for the lengthy research in the progress of strong AI. The intricacy of scientific problems and the need to fully understand the human brain through psychology and neurophysiology have limited many researchers from emulating the function of the human brain into a computer hardware.[71] Many researchers tend to underestimate any doubt that is involved with future predictions of AI, but without taking those issues seriously can people then overlook solutions to problematic questions.[37]\n\nClocksin says that a conceptual limitation that may impede the progress of AI research is that people may be using the wrong techniques for computer programs and implementation of equipment.[68] When AI researchers first began to aim for the goal of artificial intelligence, a main interest was human reasoning.[72] Researchers hoped to establish computational models of human knowledge through reasoning and to find out how to design a computer with a specific cognitive task.[72]\n\nThe practice of abstraction, which people tend to redefine when working with a particular context in research, provides researchers with a concentration on just a few concepts.[72] The most productive use of abstraction in AI research comes from planning and problem solving.[72] Although the aim is to increase the speed of a computation, the role of abstraction has posed questions about the involvement of abstraction operators.[73]\n\nA possible reason for the slowness in AI relates to the acknowledgement by many AI researchers that heuristics is a section that contains a significant breach between computer performance and human performance.[71] The specific functions that are programmed to a computer may be able to account for many of the requirements that allow it to match human intelligence. These explanations are not necessarily guaranteed to be the fundamental causes for the delay in achieving strong AI, but they are widely agreed by numerous researchers.\n\nThere have been many AI researchers that debate over the idea whether machines should be created with emotions. There are no emotions in typical models of AI and some researchers say programming emotions into machines allows them to have a mind of their own.[68] Emotion sums up the experiences of humans because it allows them to remember those experiences.[70]  David Gelernter writes, \"No computer will be creative unless it can simulate all the nuances of human emotion.\"[70] This concern about emotion has posed problems for AI researchers and it connects to the concept of strong AI as its research progresses into the future.\n\n"
    },
    {
      "title": "Consciousness",
      "text": "There are other aspects of the human mind besides intelligence that are relevant to the concept of strong AI which play a major role in science fiction and the ethics of artificial intelligence:\n\nThese traits have a moral dimension, because a machine with this form of strong AI may have legal rights, analogous to the rights of non-human animals. Also, Bill Joy, among others, argues a machine with these traits may be a threat to human life or dignity.[75] It remains to be shown whether any of these traits are necessary for strong AI. The role of consciousness is not clear, and currently there is no agreed test for its presence. If a machine is built with a device that simulates the neural correlates of consciousness, would it automatically have self-awareness? It is also possible that some of these properties, such as sentience, naturally emerge from a fully intelligent machine, or that it becomes natural to ascribe these properties to machines once they begin to act in a way that is clearly intelligent. For example, intelligent action may be sufficient for sentience, rather than the other way around.\n\nIn science fiction, AGI is associated with traits such as consciousness, sentience, sapience, and self-awareness observed in living beings. However, according to philosopher John Searle, it is an open question whether general intelligence is sufficient for consciousness. \"Strong AI\" (as defined above by Ray Kurzweil) should not be confused with Searle's \"strong AI hypothesis.\" The strong AI hypothesis is the claim that a computer which behaves as intelligently as a person must also necessarily have a mind and consciousness. AGI refers only to the amount of intelligence that the machine displays, with or without a mind.\n\n"
    },
    {
      "title": "Controversies and dangers",
      "text": "Opinions vary both on whether and when artificial general intelligence will arrive. At one extreme, AI pioneer Herbert A. Simon wrote in 1965: \"machines will be capable, within twenty years, of doing any work a man can do\". However, this prediction failed to come true. Microsoft co-founder Paul Allen believed that such intelligence is unlikely in the 21st century because it would require \"unforeseeable and fundamentally unpredictable breakthroughs\" and a \"scientifically deep understanding of cognition\".[76] Writing in The Guardian, roboticist Alan Winfield claimed the gulf between modern computing and human-level artificial intelligence is as wide as the gulf between current space flight and practical faster-than-light spaceflight.[77] AI experts' views on the feasibility of AGI wax and wane, and may have seen a resurgence in the 2010s. Four polls conducted in 2012 and 2013 suggested that the median guess among experts for when they'd be 50% confident AGI would arrive was 2040 to 2050, depending on the poll, with the mean being 2081. It is also interesting to note 16.5% of the experts answered with \"never\" when asked the same question but with a 90% confidence instead.[78][79]\nFurther current AGI progress considerations could found below #Tests_for_confirming_human-level_AGI or #IQ-Tests_AGI. \n\nThe creation of artificial general intelligence may have repercussions so great and so complex that it may not be possible to forecast what will come afterwards.  Thus the event in the hypothetical future of achieving strong AI is called the technological singularity, because theoretically one cannot see past it.  But this has not stopped philosophers and researchers from guessing what the smart computers or robots of the future may do, including forming a utopia by being our friends or overwhelming us in an AI takeover. The latter potentiality is particularly disturbing as it poses an existential risk for mankind.\n\nSmart computers or robots would be able to design and produce improved versions of themselves. [80] A growing population of intelligent robots could conceivably out-compete inferior humans in job markets, in business, in science, in politics (pursuing robot rights), and technologically, sociologically (by acting as one), and militarily. Even nowadays, many jobs have already been taken by intelligent machines. For example, robots for homes, health care, hotels, and restaurants have automated many parts of our lives: virtual bots turn customer service into self-service, big data AI applications are used to replace portfolio managers, and social robots such as Pepper are used to replace human greeters for customer service purpose[81]\n\nIf research into strong AI produced sufficiently intelligent software, it would be able to reprogram and improve itself – a feature called \"recursive self-improvement\". It would then be even better at improving itself, and would probably continue doing so in a rapidly increasing cycle, leading to an intelligence explosion and the emergence of superintelligence.  Such an intelligence would not have the limitations of human intellect, and might be able to invent or discover almost anything.\n\nHyper-intelligent software might not necessarily decide to support the continued existence of mankind, and might be extremely difficult to stop.[82] This topic has also recently begun to be discussed in academic publications as a real source of risks to civilization, humans, and planet Earth.\n\nOne proposal to deal with this is to make sure that the first generally intelligent AI is a friendly AI that would then endeavor to ensure that subsequently developed AIs were also nice to us. But friendly AI is harder to create than plain AGI, and therefore it is likely, in a race between the two, that non-friendly AI would be developed first. Also, there is no guarantee that friendly AI would remain friendly, or that its progeny would also all be good.[83]\n\n"
    }
  ],
  "links": []
}