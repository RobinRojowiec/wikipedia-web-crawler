{
  "url": "https://en.wikipedia.org/wiki/Artificial_consciousness",
  "title": "Artificial consciousness",
  "html": "<!DOCTYPE html>\n<html class=\"client-nojs\" dir=\"ltr\" lang=\"en\">\n<head>\n<meta charset=\"utf-8\"/>\n<title>Artificial consciousness - Wikipedia</title>\n<script>document.documentElement.className = document.documentElement.className.replace( /(^|\\s)client-nojs(\\s|$)/, \"$1client-js$2\" );</script>\n<script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({\"wgCanonicalNamespace\":\"\",\"wgCanonicalSpecialPageName\":false,\"wgNamespaceNumber\":0,\"wgPageName\":\"Artificial_consciousness\",\"wgTitle\":\"Artificial consciousness\",\"wgCurRevisionId\":883911144,\"wgRevisionId\":883911144,\"wgArticleId\":195552,\"wgIsArticle\":true,\"wgIsRedirect\":false,\"wgAction\":\"view\",\"wgUserName\":null,\"wgUserGroups\":[\"*\"],\"wgCategories\":[\"CS1 maint: Uses authors parameter\",\"CS1 maint: BOT: original-url status unknown\",\"Artificial intelligence\",\"Consciousness\",\"Consciousness studies\",\"Computational neuroscience\"],\"wgBreakFrames\":false,\"wgPageContentLanguage\":\"en\",\"wgPageContentModel\":\"wikitext\",\"wgSeparatorTransformTable\":[\"\",\"\"],\"wgDigitTransformTable\":[\"\",\"\"],\"wgDefaultDateFormat\":\"dmy\",\"wgMonthNames\":[\"\",\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"],\"wgMonthNamesShort\":[\"\",\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"],\"wgRelevantPageName\":\"Artificial_consciousness\",\"wgRelevantArticleId\":195552,\"wgRequestId\":\"XHNAqwpAMFUAAD3aMCgAAAAO\",\"wgCSPNonce\":false,\"wgIsProbablyEditable\":true,\"wgRelevantPageIsProbablyEditable\":true,\"wgRestrictionEdit\":[],\"wgRestrictionMove\":[],\"wgFlaggedRevsParams\":{\"tags\":{}},\"wgStableRevisionId\":null,\"wgCategoryTreePageCategoryOptions\":\"{\\\"mode\\\":0,\\\"hideprefix\\\":20,\\\"showcount\\\":true,\\\"namespaces\\\":false}\",\"wgWikiEditorEnabledModules\":[],\"wgBetaFeaturesFeatures\":[],\"wgMediaViewerOnClick\":true,\"wgMediaViewerEnabledByDefault\":true,\"wgPopupsShouldSendModuleToUser\":true,\"wgPopupsConflictsWithNavPopupGadget\":false,\"wgVisualEditor\":{\"pageLanguageCode\":\"en\",\"pageLanguageDir\":\"ltr\",\"pageVariantFallbacks\":\"en\",\"usePageImages\":true,\"usePageDescriptions\":true},\"wgMFIsPageContentModelEditable\":true,\"wgMFEnableFontChanger\":true,\"wgMFDisplayWikibaseDescriptions\":{\"search\":true,\"nearby\":true,\"watchlist\":true,\"tagline\":false},\"wgRelatedArticles\":null,\"wgRelatedArticlesUseCirrusSearch\":true,\"wgRelatedArticlesOnlyUseCirrusSearch\":false,\"wgWMESchemaEditAttemptStepOversample\":false,\"wgPoweredByHHVM\":true,\"wgULSCurrentAutonym\":\"English\",\"wgNoticeProject\":\"wikipedia\",\"wgCentralNoticeCookiesToDelete\":[],\"wgCentralNoticeCategoriesUsingLegacy\":[\"Fundraising\",\"fundraising\"],\"wgWikibaseItemId\":\"Q2993663\",\"wgScoreNoteLanguages\":{\"arabic\":\"العربية\",\"catalan\":\"català\",\"deutsch\":\"Deutsch\",\"english\":\"English\",\"espanol\":\"español\",\"italiano\":\"italiano\",\"nederlands\":\"Nederlands\",\"norsk\":\"norsk\",\"portugues\":\"português\",\"suomi\":\"suomi\",\"svenska\":\"svenska\",\"vlaams\":\"West-Vlams\"},\"wgScoreDefaultNoteLanguage\":\"nederlands\",\"wgCentralAuthMobileDomain\":false,\"wgCodeMirrorEnabled\":true,\"wgVisualEditorToolbarScrollOffset\":0,\"wgVisualEditorUnsupportedEditParams\":[\"undo\",\"undoafter\",\"veswitched\"],\"wgEditSubmitButtonLabelPublish\":true,\"oresWikiId\":\"enwiki\",\"oresBaseUrl\":\"http://ores.discovery.wmnet:8081/\",\"oresApiVersion\":3});mw.loader.state({\"ext.gadget.charinsert-styles\":\"ready\",\"ext.globalCssJs.user.styles\":\"ready\",\"ext.globalCssJs.site.styles\":\"ready\",\"site.styles\":\"ready\",\"noscript\":\"ready\",\"user.styles\":\"ready\",\"ext.globalCssJs.user\":\"ready\",\"ext.globalCssJs.site\":\"ready\",\"user\":\"ready\",\"user.options\":\"ready\",\"user.tokens\":\"loading\",\"ext.cite.styles\":\"ready\",\"mediawiki.legacy.shared\":\"ready\",\"mediawiki.legacy.commonPrint\":\"ready\",\"mediawiki.toc.styles\":\"ready\",\"wikibase.client.init\":\"ready\",\"ext.visualEditor.desktopArticleTarget.noscript\":\"ready\",\"ext.uls.interlanguage\":\"ready\",\"ext.wikimediaBadges\":\"ready\",\"ext.3d.styles\":\"ready\",\"mediawiki.skinning.interface\":\"ready\",\"skins.vector.styles\":\"ready\"});mw.loader.implement(\"user.tokens@0tffind\",function($,jQuery,require,module){/*@nomin*/mw.user.tokens.set({\"editToken\":\"+\\\\\",\"patrolToken\":\"+\\\\\",\"watchToken\":\"+\\\\\",\"csrfToken\":\"+\\\\\"});\n});RLPAGEMODULES=[\"ext.cite.ux-enhancements\",\"site\",\"mediawiki.page.startup\",\"mediawiki.page.ready\",\"mediawiki.toc\",\"mediawiki.searchSuggest\",\"ext.gadget.teahouse\",\"ext.gadget.ReferenceTooltips\",\"ext.gadget.watchlist-notice\",\"ext.gadget.DRN-wizard\",\"ext.gadget.charinsert\",\"ext.gadget.refToolbar\",\"ext.gadget.extra-toolbar-buttons\",\"ext.gadget.switcher\",\"ext.centralauth.centralautologin\",\"ext.popups\",\"ext.visualEditor.desktopArticleTarget.init\",\"ext.visualEditor.targetLoader\",\"ext.eventLogging\",\"ext.wikimediaEvents\",\"ext.navigationTiming\",\"ext.uls.eventlogger\",\"ext.uls.init\",\"ext.uls.compactlinks\",\"ext.uls.interface\",\"ext.quicksurveys.init\",\"ext.centralNotice.geoIP\",\"ext.centralNotice.startUp\",\"skins.vector.js\"];mw.loader.load(RLPAGEMODULES);});</script>\n<link href=\"/w/load.php?debug=false&amp;lang=en&amp;modules=ext.3d.styles%7Cext.cite.styles%7Cext.uls.interlanguage%7Cext.visualEditor.desktopArticleTarget.noscript%7Cext.wikimediaBadges%7Cmediawiki.legacy.commonPrint%2Cshared%7Cmediawiki.skinning.interface%7Cmediawiki.toc.styles%7Cskins.vector.styles%7Cwikibase.client.init&amp;only=styles&amp;skin=vector\" rel=\"stylesheet\"/>\n<script async=\"\" src=\"/w/load.php?debug=false&amp;lang=en&amp;modules=startup&amp;only=scripts&amp;skin=vector\"></script>\n<meta content=\"\" name=\"ResourceLoaderDynamicStyles\"/>\n<link href=\"/w/load.php?debug=false&amp;lang=en&amp;modules=ext.gadget.charinsert-styles&amp;only=styles&amp;skin=vector\" rel=\"stylesheet\"/>\n<link href=\"/w/load.php?debug=false&amp;lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=vector\" rel=\"stylesheet\"/>\n<meta content=\"MediaWiki 1.33.0-wmf.18\" name=\"generator\"/>\n<meta content=\"origin\" name=\"referrer\"/>\n<meta content=\"origin-when-crossorigin\" name=\"referrer\"/>\n<meta content=\"origin-when-cross-origin\" name=\"referrer\"/>\n<link href=\"android-app://org.wikipedia/http/en.m.wikipedia.org/wiki/Artificial_consciousness\" rel=\"alternate\"/>\n<link href=\"/w/index.php?title=Artificial_consciousness&amp;action=edit\" rel=\"alternate\" title=\"Edit this page\" type=\"application/x-wiki\"/>\n<link href=\"/w/index.php?title=Artificial_consciousness&amp;action=edit\" rel=\"edit\" title=\"Edit this page\"/>\n<link href=\"/static/apple-touch/wikipedia.png\" rel=\"apple-touch-icon\"/>\n<link href=\"/static/favicon/wikipedia.ico\" rel=\"shortcut icon\"/>\n<link href=\"/w/opensearch_desc.php\" rel=\"search\" title=\"Wikipedia (en)\" type=\"application/opensearchdescription+xml\"/>\n<link href=\"//en.wikipedia.org/w/api.php?action=rsd\" rel=\"EditURI\" type=\"application/rsd+xml\"/>\n<link href=\"//creativecommons.org/licenses/by-sa/3.0/\" rel=\"license\"/>\n<link href=\"https://en.wikipedia.org/wiki/Artificial_consciousness\" rel=\"canonical\"/>\n<link href=\"//login.wikimedia.org\" rel=\"dns-prefetch\"/>\n<link href=\"//meta.wikimedia.org\" rel=\"dns-prefetch\"/>\n<!--[if lt IE 9]><script src=\"/w/load.php?debug=false&amp;lang=en&amp;modules=html5shiv&amp;only=scripts&amp;skin=vector&amp;sync=1\"></script><![endif]-->\n</head>\n<body class=\"mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject mw-editable page-Artificial_consciousness rootpage-Artificial_consciousness skin-vector action-view\"> <div class=\"noprint\" id=\"mw-page-base\"></div>\n<div class=\"noprint\" id=\"mw-head-base\"></div>\n<div class=\"mw-body\" id=\"content\" role=\"main\">\n<a id=\"top\"></a>\n<div class=\"mw-body-content\" id=\"siteNotice\"><!-- CentralNotice --></div><div class=\"mw-indicators mw-body-content\">\n</div>\n<h1 class=\"firstHeading\" id=\"firstHeading\" lang=\"en\">Artificial consciousness</h1> <div class=\"mw-body-content\" id=\"bodyContent\">\n<div class=\"noprint\" id=\"siteSub\">From Wikipedia, the free encyclopedia</div> <div id=\"contentSub\"></div>\n<div id=\"jump-to-nav\"></div> <a class=\"mw-jump-link\" href=\"#mw-head\">Jump to navigation</a>\n<a class=\"mw-jump-link\" href=\"#p-search\">Jump to search</a>\n<div class=\"mw-content-ltr\" dir=\"ltr\" id=\"mw-content-text\" lang=\"en\"><div class=\"mw-parser-output\"><div class=\"hatnote navigation-not-searchable\" role=\"note\">For other uses, see <a class=\"mw-disambig\" href=\"/wiki/Artificial_consciousness_(disambiguation)\" title=\"Artificial consciousness (disambiguation)\">Artificial consciousness (disambiguation)</a>.</div>\n<p><b>Artificial consciousness</b><sup class=\"reference\" id=\"cite_ref-gunn_1-0\"><a href=\"#cite_note-gunn-1\">[1]</a></sup> (<b>AC</b>), also known as <b>machine consciousness</b> (<b>MC</b>) or <b>synthetic consciousness</b> (<a href=\"#CITEREFGamez2008\">Gamez 2008</a>; <a href=\"#CITEREFReggia2013\">Reggia 2013</a>), is a field related to <a href=\"/wiki/Artificial_intelligence\" title=\"Artificial intelligence\">artificial intelligence</a> and <a href=\"/wiki/Cognitive_robotics\" title=\"Cognitive robotics\">cognitive robotics</a>. The aim of the <a href=\"/wiki/Scientific_theory\" title=\"Scientific theory\">theory</a> of artificial consciousness is to \"Define that which would have to be synthesized were consciousness to be found in an engineered artifact\" (<a href=\"#CITEREFAleksander1995\">Aleksander 1995</a>).\n</p><p><a href=\"/wiki/Neuroscience\" title=\"Neuroscience\">Neuroscience</a> hypothesizes that <a href=\"/wiki/Consciousness\" title=\"Consciousness\">consciousness</a> is generated by the interoperation of various parts of the <a href=\"/wiki/Brain\" title=\"Brain\">brain</a>, called the <a href=\"/wiki/Neural_correlates_of_consciousness\" title=\"Neural correlates of consciousness\">neural correlates of consciousness</a> or NCC, though there are challenges to that perspective. Proponents of AC believe it is possible to construct <a href=\"/wiki/System\" title=\"System\">systems</a> (e.g., <a href=\"/wiki/Computer\" title=\"Computer\">computer</a> systems) that can emulate this NCC interoperation.<sup class=\"reference\" id=\"cite_ref-Graziano_Consciousness_and_the_Social_Brain_2-0\"><a href=\"#cite_note-Graziano_Consciousness_and_the_Social_Brain-2\">[2]</a></sup>\n</p><p>Artificial consciousness concepts are also pondered in the philosophy of <a href=\"/wiki/Artificial_intelligence\" title=\"Artificial intelligence\">artificial intelligence</a> through <a href=\"/wiki/Philosophy_of_artificial_intelligence#Can_a_machine_have_a_mind,_consciousness,_and_mental_states?\" title=\"Philosophy of artificial intelligence\">questions about mind, consciousness, and mental states</a>.<sup class=\"reference\" id=\"cite_ref-3\"><a href=\"#cite_note-3\">[3]</a></sup>\n</p>\n<div class=\"toc\" id=\"toc\"><input class=\"toctogglecheckbox\" id=\"toctogglecheckbox\" role=\"button\" style=\"display:none\" type=\"checkbox\"/><div class=\"toctitle\" dir=\"ltr\" lang=\"en\"><h2>Contents</h2><span class=\"toctogglespan\"><label class=\"toctogglelabel\" for=\"toctogglecheckbox\"></label></span></div>\n<ul>\n<li class=\"toclevel-1 tocsection-1\"><a href=\"#Philosophical_views\"><span class=\"tocnumber\">1</span> <span class=\"toctext\">Philosophical views</span></a>\n<ul>\n<li class=\"toclevel-2 tocsection-2\"><a href=\"#Plausibility_debate\"><span class=\"tocnumber\">1.1</span> <span class=\"toctext\">Plausibility debate</span></a>\n<ul>\n<li class=\"toclevel-3 tocsection-3\"><a href=\"#Computational_Foundation_argument\"><span class=\"tocnumber\">1.1.1</span> <span class=\"toctext\">Computational Foundation argument</span></a></li>\n</ul>\n</li>\n<li class=\"toclevel-2 tocsection-4\"><a href=\"#Ethics\"><span class=\"tocnumber\">1.2</span> <span class=\"toctext\">Ethics</span></a></li>\n</ul>\n</li>\n<li class=\"toclevel-1 tocsection-5\"><a href=\"#Research_and_implementation_proposals\"><span class=\"tocnumber\">2</span> <span class=\"toctext\">Research and implementation proposals</span></a>\n<ul>\n<li class=\"toclevel-2 tocsection-6\"><a href=\"#Aspects_of_consciousness\"><span class=\"tocnumber\">2.1</span> <span class=\"toctext\">Aspects of consciousness</span></a>\n<ul>\n<li class=\"toclevel-3 tocsection-7\"><a href=\"#Awareness\"><span class=\"tocnumber\">2.1.1</span> <span class=\"toctext\">Awareness</span></a></li>\n<li class=\"toclevel-3 tocsection-8\"><a href=\"#Memory\"><span class=\"tocnumber\">2.1.2</span> <span class=\"toctext\">Memory</span></a></li>\n<li class=\"toclevel-3 tocsection-9\"><a href=\"#Learning\"><span class=\"tocnumber\">2.1.3</span> <span class=\"toctext\">Learning</span></a></li>\n<li class=\"toclevel-3 tocsection-10\"><a href=\"#Anticipation\"><span class=\"tocnumber\">2.1.4</span> <span class=\"toctext\">Anticipation</span></a></li>\n<li class=\"toclevel-3 tocsection-11\"><a href=\"#Subjective_experience\"><span class=\"tocnumber\">2.1.5</span> <span class=\"toctext\">Subjective experience</span></a></li>\n</ul>\n</li>\n<li class=\"toclevel-2 tocsection-12\"><a href=\"#Role_of_cognitive_architectures\"><span class=\"tocnumber\">2.2</span> <span class=\"toctext\">Role of cognitive architectures</span></a></li>\n<li class=\"toclevel-2 tocsection-13\"><a href=\"#Symbolic_or_hybrid_proposals\"><span class=\"tocnumber\">2.3</span> <span class=\"toctext\">Symbolic or hybrid proposals</span></a>\n<ul>\n<li class=\"toclevel-3 tocsection-14\"><a href=\"#Franklin's_Intelligent_Distribution_Agent\"><span class=\"tocnumber\">2.3.1</span> <span class=\"toctext\">Franklin's Intelligent Distribution Agent</span></a></li>\n<li class=\"toclevel-3 tocsection-15\"><a href=\"#Ron_Sun's_cognitive_architecture_CLARION\"><span class=\"tocnumber\">2.3.2</span> <span class=\"toctext\">Ron Sun's cognitive architecture CLARION</span></a></li>\n<li class=\"toclevel-3 tocsection-16\"><a href=\"#Ben_Goertzel's_OpenCog\"><span class=\"tocnumber\">2.3.3</span> <span class=\"toctext\">Ben Goertzel's OpenCog</span></a></li>\n</ul>\n</li>\n<li class=\"toclevel-2 tocsection-17\"><a href=\"#Connectionist_proposals\"><span class=\"tocnumber\">2.4</span> <span class=\"toctext\">Connectionist proposals</span></a>\n<ul>\n<li class=\"toclevel-3 tocsection-18\"><a href=\"#Haikonen's_cognitive_architecture\"><span class=\"tocnumber\">2.4.1</span> <span class=\"toctext\">Haikonen's cognitive architecture</span></a></li>\n<li class=\"toclevel-3 tocsection-19\"><a href=\"#Shanahan's_cognitive_architecture\"><span class=\"tocnumber\">2.4.2</span> <span class=\"toctext\">Shanahan's cognitive architecture</span></a></li>\n<li class=\"toclevel-3 tocsection-20\"><a href=\"#Takeno's_self-awareness_research\"><span class=\"tocnumber\">2.4.3</span> <span class=\"toctext\">Takeno's self-awareness research</span></a></li>\n<li class=\"toclevel-3 tocsection-21\"><a href=\"#Aleksander's_impossible_mind\"><span class=\"tocnumber\">2.4.4</span> <span class=\"toctext\">Aleksander's impossible mind</span></a></li>\n<li class=\"toclevel-3 tocsection-22\"><a href=\"#Thaler's_Creativity_Machine_Paradigm\"><span class=\"tocnumber\">2.4.5</span> <span class=\"toctext\">Thaler's Creativity Machine Paradigm</span></a></li>\n<li class=\"toclevel-3 tocsection-23\"><a href=\"#Michael_Graziano's_attention_schema\"><span class=\"tocnumber\">2.4.6</span> <span class=\"toctext\">Michael Graziano's attention schema</span></a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li class=\"toclevel-1 tocsection-24\"><a href=\"#Testing\"><span class=\"tocnumber\">3</span> <span class=\"toctext\">Testing</span></a></li>\n<li class=\"toclevel-1 tocsection-25\"><a href=\"#In_fiction\"><span class=\"tocnumber\">4</span> <span class=\"toctext\">In fiction</span></a></li>\n<li class=\"toclevel-1 tocsection-26\"><a href=\"#See_also\"><span class=\"tocnumber\">5</span> <span class=\"toctext\">See also</span></a></li>\n<li class=\"toclevel-1 tocsection-27\"><a href=\"#References\"><span class=\"tocnumber\">6</span> <span class=\"toctext\">References</span></a>\n<ul>\n<li class=\"toclevel-2 tocsection-28\"><a href=\"#Citations\"><span class=\"tocnumber\">6.1</span> <span class=\"toctext\">Citations</span></a></li>\n<li class=\"toclevel-2 tocsection-29\"><a href=\"#Bibliography\"><span class=\"tocnumber\">6.2</span> <span class=\"toctext\">Bibliography</span></a></li>\n</ul>\n</li>\n<li class=\"toclevel-1 tocsection-30\"><a href=\"#Further_reading\"><span class=\"tocnumber\">7</span> <span class=\"toctext\">Further reading</span></a></li>\n<li class=\"toclevel-1 tocsection-31\"><a href=\"#External_links\"><span class=\"tocnumber\">8</span> <span class=\"toctext\">External links</span></a></li>\n</ul>\n</div>\n<h2><span class=\"mw-headline\" id=\"Philosophical_views\">Philosophical views</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_consciousness&amp;action=edit&amp;section=1\" title=\"Edit section: Philosophical views\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>As there are many hypothesized <a href=\"/wiki/Consciousness#Types_of_consciousness\" title=\"Consciousness\">types of consciousness</a>, there are many potential implementations of artificial consciousness.  In the philosophical literature, perhaps the most common taxonomy of consciousness is into \"access\" and \"phenomenal\" variants.  Access consciousness concerns those aspects of <a href=\"/wiki/Experience\" title=\"Experience\">experience</a> that can be apprehended, while phenomenal consciousness concerns those aspects of experience that seemingly cannot be apprehended, instead being characterized qualitatively in terms of “raw feels”, “what it is like” or <a href=\"/wiki/Qualia\" title=\"Qualia\">qualia</a> (<a href=\"#CITEREFBlock1997\">Block 1997</a>).\n</p>\n<h3><span class=\"mw-headline\" id=\"Plausibility_debate\">Plausibility debate</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_consciousness&amp;action=edit&amp;section=2\" title=\"Edit section: Plausibility debate\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p><a href=\"/wiki/Type_physicalism\" title=\"Type physicalism\">Type-identity theorists</a> and other skeptics hold the view that consciousness can only be realized in particular physical systems because consciousness has properties that necessarily depend on physical constitution (<a href=\"#CITEREFBlock1978\">Block 1978</a>; <a href=\"#CITEREFBickle2003\">Bickle 2003</a>).<sup class=\"reference\" id=\"cite_ref-4\"><a href=\"#cite_note-4\">[4]</a></sup><sup class=\"reference\" id=\"cite_ref-5\"><a href=\"#cite_note-5\">[5]</a></sup>\n</p><p>In his article \"Artificial Consciousness: Utopia or Real Possibility\" Giorgio Buttazzo says that despite our current technology's ability to simulate autonomy, \"Working in a fully automated mode, they [the computers] cannot exhibit creativity, emotions, or <a href=\"/wiki/Free_will\" title=\"Free will\">free will</a>. A computer, like a washing machine, is a slave operated by its components.\"<sup class=\"reference\" id=\"cite_ref-6\"><a href=\"#cite_note-6\">[6]</a></sup>\n</p><p>For other theorists (e.g., <a href=\"/wiki/Functionalism_(philosophy_of_mind)\" title=\"Functionalism (philosophy of mind)\">functionalists</a>), who define mental states in terms of causal roles, any system that can instantiate the same pattern of causal roles, regardless of physical constitution, will instantiate the same mental states, including consciousness (<a href=\"#CITEREFPutnam1967\">Putnam 1967</a>).\n</p>\n<h4><span class=\"mw-headline\" id=\"Computational_Foundation_argument\">Computational Foundation argument</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_consciousness&amp;action=edit&amp;section=3\" title=\"Edit section: Computational Foundation argument\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h4>\n<p>One of the most explicit arguments for the plausibility of AC comes from <a href=\"/wiki/David_Chalmers\" title=\"David Chalmers\">David Chalmers</a>.  His proposal, found within his article <a href=\"#CITEREFChalmers2011\">Chalmers 2011</a>, is roughly that the right kinds of computations are sufficient for the possession of a conscious mind. In the outline, he defends his claim thus: Computers perform computations. Computations can capture other systems' abstract causal organization.\n</p><p>The most controversial part of Chalmers' proposal is that mental properties are \"organizationally invariant\". Mental properties are of two kinds, psychological and phenomenological. Psychological properties, such as belief and perception, are those that are \"characterized by their causal role\". He adverts to the work of <a href=\"#CITEREFArmstrong1968\">Armstrong 1968</a> and <a href=\"#CITEREFLewis1972\">Lewis 1972</a> in claiming that \"[s]ystems with the same causal topology…will share their psychological properties\".\n</p><p>Phenomenological properties are not prima facie definable in terms of their causal roles. Establishing that phenomenological properties are amenable to individuation by causal role therefore requires argument. Chalmers provides his Dancing Qualia Argument for this purpose.<sup class=\"reference\" id=\"cite_ref-7\"><a href=\"#cite_note-7\">[7]</a></sup>\n</p><p>Chalmers begins by assuming that agents with identical causal organizations could have different experiences. He then asks us to conceive of changing one agent into the other by the replacement of parts (neural parts replaced by silicon, say) while preserving its causal organization. Ex hypothesi, the experience of the agent under transformation would change (as the parts were replaced), but there would be no change in causal topology and therefore no means whereby the agent could \"notice\" the shift in experience.\n</p><p>Critics of AC object that Chalmers begs the question in assuming that all mental properties and external connections are sufficiently captured by abstract causal organization.\n</p>\n<h3><span class=\"mw-headline\" id=\"Ethics\">Ethics</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_consciousness&amp;action=edit&amp;section=4\" title=\"Edit section: Ethics\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<div class=\"hatnote navigation-not-searchable\" role=\"note\">Main articles: <a href=\"/wiki/Ethics_of_artificial_intelligence\" title=\"Ethics of artificial intelligence\">Ethics of artificial intelligence</a>, <a href=\"/wiki/Machine_ethics\" title=\"Machine ethics\">Machine ethics</a>, and <a class=\"mw-redirect\" href=\"/wiki/Roboethics\" title=\"Roboethics\">Roboethics</a></div>\n<p>If it were suspected that a particular machine was conscious, its rights would be an <a href=\"/wiki/Ethics\" title=\"Ethics\">ethical</a> issue that would need to be assessed (e.g. what rights it would have under law). For example, a conscious computer that was owned and used as a tool or central computer of a building of larger machine is a particular ambiguity. Should <a href=\"/wiki/Law\" title=\"Law\">laws</a> be made for such a case? Consciousness would also require a legal definition in this particular case. Because artificial consciousness is still largely a theoretical subject, such ethics have not been discussed or developed to a great extent, though it has often been a theme in fiction (see below).\n</p><p>The rules for the 2003 <a href=\"/wiki/Loebner_Prize\" title=\"Loebner Prize\">Loebner Prize</a> competition explicitly addressed the question of robot rights:\n</p>\n<blockquote><p>61. If, in any given year, a publicly available open source Entry entered by the University of Surrey or the Cambridge Center wins the Silver Medal or the Gold Medal, then the Medal and the Cash Award will be awarded to the body responsible for the development of that Entry. If no such body can be identified, or if there is disagreement among two or more claimants, the Medal and the Cash Award will be held in trust <i>until such time as the Entry may legally possess, either in the United States of America or in the venue of the contest, the Cash Award and Gold Medal in its own right</i>.<sup class=\"reference\" id=\"cite_ref-8\"><a href=\"#cite_note-8\">[8]</a></sup></p></blockquote>\n<h2><span class=\"mw-headline\" id=\"Research_and_implementation_proposals\">Research and implementation proposals</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_consciousness&amp;action=edit&amp;section=5\" title=\"Edit section: Research and implementation proposals\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<h3><span class=\"mw-headline\" id=\"Aspects_of_consciousness\">Aspects of consciousness</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_consciousness&amp;action=edit&amp;section=6\" title=\"Edit section: Aspects of consciousness\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>There are various aspects of consciousness generally deemed necessary for a machine to be artificially conscious. A variety of functions in which consciousness plays a role were suggested by <a href=\"/wiki/Bernard_Baars\" title=\"Bernard Baars\">Bernard Baars</a> (<a href=\"#CITEREFBaars1988\">Baars 1988</a>) and others. The functions of consciousness suggested by Bernard Baars are Definition and Context Setting, Adaptation and Learning, Editing, Flagging and Debugging, Recruiting and Control, Prioritizing and Access-Control, Decision-making or Executive Function, Analogy-forming Function, Metacognitive and Self-monitoring Function, and Autoprogramming and Self-maintenance Function. Igor Aleksander suggested 12 principles for artificial consciousness (<a href=\"#CITEREFAleksander1995\">Aleksander 1995</a>) and these are: The Brain is a State Machine, Inner Neuron Partitioning, Conscious and Unconscious States, Perceptual Learning and Memory, Prediction, The Awareness of Self, Representation of Meaning, Learning Utterances, Learning Language, Will, Instinct, and Emotion. The aim of AC is to define whether and how these and other aspects of consciousness can be synthesized in an engineered artifact such as a digital computer. This list is not exhaustive; there are many others not covered.\n</p>\n<h4><span class=\"mw-headline\" id=\"Awareness\">Awareness</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_consciousness&amp;action=edit&amp;section=7\" title=\"Edit section: Awareness\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h4>\n<p><a href=\"/wiki/Awareness\" title=\"Awareness\">Awareness</a> could be one required aspect, but there are many problems with the exact definition of <i>awareness</i>. The results of the experiments of <a class=\"mw-redirect\" href=\"/wiki/Mirror_neurons#In_monkeys\" title=\"Mirror neurons\">neuroscanning on monkeys</a> suggest that a process, not only a state or object, activates neurons. Awareness includes creating and testing alternative models of each process based on the information received through the senses or imagined, and is also useful for making predictions. Such modeling needs a lot of flexibility. Creating such a model includes modeling of the physical world, modeling of one's own internal states and processes, and modeling of other conscious entities.\n</p><p>There are at least three types of awareness:<sup class=\"reference\" id=\"cite_ref-9\"><a href=\"#cite_note-9\">[9]</a></sup> agency awareness, goal awareness, and sensorimotor awareness, which may also be conscious or not.  For example, in agency awareness you may be aware that you performed a certain action yesterday, but are not now conscious of it.  In goal awareness you may be aware that you must search for a lost object, but are not now conscious of it.  In sensorimotor awareness, you may be aware that your hand is resting on an object, but are not now conscious of it.\n</p><p>Because objects of awareness are often conscious, the distinction between awareness and consciousness is frequently blurred or they are used as synonyms.<sup class=\"reference\" id=\"cite_ref-10\"><a href=\"#cite_note-10\">[10]</a></sup>\n</p>\n<h4><span class=\"mw-headline\" id=\"Memory\">Memory</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_consciousness&amp;action=edit&amp;section=8\" title=\"Edit section: Memory\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h4>\n<p>Conscious events interact with <a href=\"/wiki/Memory\" title=\"Memory\">memory</a> systems in learning, rehearsal, and retrieval.<sup class=\"reference\" id=\"cite_ref-11\"><a href=\"#cite_note-11\">[11]</a></sup>\nThe IDA model<sup class=\"reference\" id=\"cite_ref-12\"><a href=\"#cite_note-12\">[12]</a></sup> elucidates the role of consciousness in the updating of perceptual memory,<sup class=\"reference\" id=\"cite_ref-13\"><a href=\"#cite_note-13\">[13]</a></sup> transient <a href=\"/wiki/Episodic_memory\" title=\"Episodic memory\">episodic memory</a>, and <a href=\"/wiki/Procedural_memory\" title=\"Procedural memory\">procedural memory</a>. Transient episodic and declarative memories have distributed representations in IDA, there is evidence that this is also the case in the nervous system.<sup class=\"reference\" id=\"cite_ref-14\"><a href=\"#cite_note-14\">[14]</a></sup> In IDA, these two memories are implemented computationally using a modified version of <a href=\"/wiki/Pentti_Kanerva\" title=\"Pentti Kanerva\">Kanerva</a>’s <a href=\"/wiki/Sparse_distributed_memory\" title=\"Sparse distributed memory\">Sparse distributed memory</a> architecture.<sup class=\"reference\" id=\"cite_ref-15\"><a href=\"#cite_note-15\">[15]</a></sup>\n</p>\n<h4><span class=\"mw-headline\" id=\"Learning\">Learning</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_consciousness&amp;action=edit&amp;section=9\" title=\"Edit section: Learning\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h4>\n<p>Learning is also considered necessary for AC. By Bernard Baars, conscious experience is needed to represent and adapt to novel and significant events (<a href=\"#CITEREFBaars1988\">Baars 1988</a>). By <a href=\"/wiki/Axel_Cleeremans\" title=\"Axel Cleeremans\">Axel Cleeremans</a> and Luis Jiménez, learning is defined as \"a set of philogenetically  [<i><a href=\"/wiki/Sic\" title=\"Sic\">sic</a></i>] advanced adaptation processes that critically depend on an evolved sensitivity to subjective experience so as to enable agents to afford flexible control over their actions in complex, unpredictable environments\" (<a href=\"#CITEREFCleeremans2001\">Cleeremans 2001</a>).\n</p>\n<h4><span class=\"mw-headline\" id=\"Anticipation\">Anticipation</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_consciousness&amp;action=edit&amp;section=10\" title=\"Edit section: Anticipation\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h4>\n<p>The ability to predict (or <a href=\"/wiki/Anticipation_(artificial_intelligence)\" title=\"Anticipation (artificial intelligence)\">anticipate</a>) foreseeable events is considered important for AC by <a href=\"/wiki/Igor_Aleksander\" title=\"Igor Aleksander\">Igor Aleksander</a>.<sup class=\"reference\" id=\"cite_ref-Aleksander_1995_16-0\"><a href=\"#cite_note-Aleksander_1995-16\">[16]</a></sup> The emergentist <a class=\"mw-redirect\" href=\"/wiki/Multiple_Drafts_Model\" title=\"Multiple Drafts Model\">multiple drafts principle</a> proposed by <a href=\"/wiki/Daniel_Dennett\" title=\"Daniel Dennett\">Daniel Dennett</a> in <i><a href=\"/wiki/Consciousness_Explained\" title=\"Consciousness Explained\">Consciousness Explained</a></i> may be useful for prediction: it involves the evaluation and selection of the most appropriate \"draft\" to fit the current environment.  Anticipation includes prediction of consequences of one's own proposed actions and prediction of consequences of probable actions by other entities.\n</p><p>Relationships between real world states are mirrored in the state structure of a conscious organism enabling the organism to predict events.<sup class=\"reference\" id=\"cite_ref-Aleksander_1995_16-1\"><a href=\"#cite_note-Aleksander_1995-16\">[16]</a></sup> An artificially conscious machine should be able to anticipate events correctly in order to be ready to respond to them when they occur or to take preemptive action to avert anticipated events. The implication here is that the machine needs flexible, real-time components that build spatial, dynamic, statistical, functional, and cause-effect models of the real world and predicted worlds, making it possible to demonstrate that it possesses artificial consciousness in the present and future and not only in the past. In order to do this, a conscious machine should make coherent predictions and contingency plans, not only in worlds with fixed rules like a chess board, but also for novel environments that may change, to be executed only when appropriate to simulate and control the real world.\n</p>\n<h4><span class=\"mw-headline\" id=\"Subjective_experience\">Subjective experience</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_consciousness&amp;action=edit&amp;section=11\" title=\"Edit section: Subjective experience\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h4>\n<p>Subjective experiences or <a href=\"/wiki/Qualia\" title=\"Qualia\">qualia</a> are widely considered to be <i>the</i> <a href=\"/wiki/Hard_problem_of_consciousness\" title=\"Hard problem of consciousness\">hard problem of consciousness</a>. Indeed, it is held to pose a challenge to <a href=\"/wiki/Physicalism\" title=\"Physicalism\">physicalism</a>, let alone <a class=\"mw-redirect\" href=\"/wiki/Computationalism\" title=\"Computationalism\">computationalism</a>. On the other hand, there are problems in other fields of science which limit that which we can observe, such as the <a href=\"/wiki/Uncertainty_principle\" title=\"Uncertainty principle\">uncertainty principle</a> in physics, which have not made the research in these fields of science impossible.\n</p>\n<h3><span class=\"mw-headline\" id=\"Role_of_cognitive_architectures\">Role of cognitive architectures</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_consciousness&amp;action=edit&amp;section=12\" title=\"Edit section: Role of cognitive architectures\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<div class=\"hatnote navigation-not-searchable\" role=\"note\">Main article: <a href=\"/wiki/Cognitive_architecture\" title=\"Cognitive architecture\">Cognitive architecture</a></div>\n<p>The term \"cognitive architecture\" may refer to a theory about the structure of the human mind, or any portion or function thereof, including consciousness. In another context, a cognitive architecture implements the theory on computers. An example is <i>QuBIC: Quantum and Bio-inspired Cognitive Architecture for Machine Consciousness</i>. One of the main goals of a cognitive architecture is to summarize the various results of cognitive psychology in a comprehensive computer model. However, the results need to be in a formalized form so they can be the basis of a computer program. Also, the role of cognitive architecture is for the A.I. to clearly structure, build, and implement it's thought process.\n</p>\n<h3><span class=\"mw-headline\" id=\"Symbolic_or_hybrid_proposals\">Symbolic or hybrid proposals</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_consciousness&amp;action=edit&amp;section=13\" title=\"Edit section: Symbolic or hybrid proposals\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<h4><span id=\"Franklin.27s_Intelligent_Distribution_Agent\"></span><span class=\"mw-headline\" id=\"Franklin's_Intelligent_Distribution_Agent\">Franklin's Intelligent Distribution Agent</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_consciousness&amp;action=edit&amp;section=14\" title=\"Edit section: Franklin's Intelligent Distribution Agent\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h4>\n<p><a href=\"/wiki/Stan_Franklin\" title=\"Stan Franklin\">Stan Franklin</a> (1995, 2003) defines an <a href=\"/wiki/Autonomous_agent\" title=\"Autonomous agent\">autonomous agent</a> as possessing <a href=\"/wiki/Consciousness\" title=\"Consciousness\">functional consciousness</a> when it is capable of several of the functions of consciousness as identified by <a href=\"/wiki/Bernard_Baars\" title=\"Bernard Baars\">Bernard Baars</a>' <a class=\"mw-redirect\" href=\"/wiki/Global_Workspace_Theory\" title=\"Global Workspace Theory\">Global Workspace Theory</a> (Baars <a href=\"#CITEREFBaars1988\">1988</a>, <a href=\"#CITEREFBaars1997\">1997</a>). His brain child IDA (Intelligent Distribution Agent) is a software implementation of GWT, which makes it functionally conscious by definition. IDA's task is to negotiate new assignments for sailors in the <a class=\"mw-redirect\" href=\"/wiki/US_Navy\" title=\"US Navy\">US Navy</a> after they end a tour of duty, by matching each individual's skills and preferences with the Navy's needs. IDA interacts with Navy databases and communicates with the sailors via natural language e-mail dialog while obeying a large set of Navy policies. The IDA computational model was developed during 1996–2001 at Stan Franklin's \"Conscious\" Software Research Group at the <a href=\"/wiki/University_of_Memphis\" title=\"University of Memphis\">University of Memphis</a>. It \"consists of approximately a quarter-million lines of <a href=\"/wiki/Java_(programming_language)\" title=\"Java (programming language)\">Java</a> code, and almost completely consumes the resources of a 2001 high-end workstation.\" It relies heavily on <i>codelets</i>, which are \"special purpose, relatively independent, mini-agent[s] typically implemented as a small piece of code running as a separate thread.\" In IDA's top-down architecture, high-level cognitive functions are explicitly modeled (see <a href=\"#CITEREFFranklin1995\">Franklin 1995</a> and <a href=\"#CITEREFFranklin2003\">Franklin 2003</a> for details). While IDA is functionally conscious by definition, Franklin does \"not attribute <a href=\"/wiki/Consciousness\" title=\"Consciousness\">phenomenal consciousness</a> to his own 'conscious' software agent, IDA, in spite of her many human-like behaviours. This in spite of watching several US Navy detailers repeatedly nodding their heads saying 'Yes, that's how I do it' while watching IDA's internal and external actions as she performs her task.\"\n</p>\n<h4><span id=\"Ron_Sun.27s_cognitive_architecture_CLARION\"></span><span class=\"mw-headline\" id=\"Ron_Sun's_cognitive_architecture_CLARION\">Ron Sun's cognitive architecture CLARION</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_consciousness&amp;action=edit&amp;section=15\" title=\"Edit section: Ron Sun's cognitive architecture CLARION\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h4>\n<p><a href=\"/wiki/CLARION_(cognitive_architecture)\" title=\"CLARION (cognitive architecture)\">CLARION</a> posits a two-level representation that explains the distinction between conscious and unconscious mental processes.\n</p><p>CLARION has been successful in accounting for a variety of psychological data. A number of well-known skill learning tasks have been simulated using CLARION that span the spectrum ranging from simple reactive skills to complex cognitive skills. The tasks include serial reaction time (SRT) tasks, artificial grammar learning (AGL) tasks, process control (PC) tasks, the categorical inference (CI) task, the alphabetical arithmetic (AA) task, and the Tower of Hanoi (TOH) task (<a href=\"#CITEREFSun2002\">Sun 2002</a>). Among them, SRT, AGL, and PC are typical implicit learning tasks, very much relevant to the issue of consciousness as they operationalized the notion of consciousness in the context of psychological experiments.\n</p>\n<h4><span id=\"Ben_Goertzel.27s_OpenCog\"></span><span class=\"mw-headline\" id=\"Ben_Goertzel's_OpenCog\">Ben Goertzel's OpenCog</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_consciousness&amp;action=edit&amp;section=16\" title=\"Edit section: Ben Goertzel's OpenCog\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h4>\n<p><a href=\"/wiki/Ben_Goertzel\" title=\"Ben Goertzel\">Ben Goertzel</a> is pursuing an embodied AGI through the open-source <a href=\"/wiki/OpenCog\" title=\"OpenCog\">OpenCog</a> project. Current code includes embodied virtual pets capable of learning simple English-language commands, as well as integration with real-world robotics, being done at the <a href=\"/wiki/Hong_Kong_Polytechnic_University\" title=\"Hong Kong Polytechnic University\">Hong Kong Polytechnic University</a>.\n</p>\n<h3><span class=\"mw-headline\" id=\"Connectionist_proposals\">Connectionist proposals</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_consciousness&amp;action=edit&amp;section=17\" title=\"Edit section: Connectionist proposals\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<h4><span id=\"Haikonen.27s_cognitive_architecture\"></span><span class=\"mw-headline\" id=\"Haikonen's_cognitive_architecture\">Haikonen's cognitive architecture</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_consciousness&amp;action=edit&amp;section=18\" title=\"Edit section: Haikonen's cognitive architecture\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h4>\n<p>Pentti <a href=\"#CITEREFHaikonen2003\">Haikonen (2003)</a> considers classical rule-based computing inadequate for achieving AC: \"the brain is definitely not a computer. Thinking is not an execution of programmed strings of commands. The brain is not a numerical calculator either. We do not think by numbers.\" Rather than trying to achieve <a href=\"/wiki/Mind\" title=\"Mind\">mind</a> and <a href=\"/wiki/Consciousness\" title=\"Consciousness\">consciousness</a> by identifying and implementing their underlying computational rules, Haikonen proposes \"a special <a href=\"/wiki/Cognitive_architecture\" title=\"Cognitive architecture\">cognitive architecture</a> to reproduce the processes of <a href=\"/wiki/Perception\" title=\"Perception\">perception</a>, <a href=\"/wiki/Mental_image\" title=\"Mental image\">inner imagery</a>, <a href=\"/wiki/Intrapersonal_communication\" title=\"Intrapersonal communication\">inner speech</a>, <a href=\"/wiki/Pain\" title=\"Pain\">pain</a>, <a href=\"/wiki/Pleasure\" title=\"Pleasure\">pleasure</a>, <a class=\"mw-redirect\" href=\"/wiki/Emotions\" title=\"Emotions\">emotions</a> and the <a class=\"mw-redirect\" href=\"/wiki/Cognitive\" title=\"Cognitive\">cognitive</a> functions behind these. This bottom-up architecture would produce higher-level functions by the power of the elementary processing units, the <a href=\"/wiki/Artificial_neuron\" title=\"Artificial neuron\">artificial neurons</a>, without <a class=\"mw-redirect\" href=\"/wiki/Algorithms\" title=\"Algorithms\">algorithms</a> or <a href=\"/wiki/Computer_program\" title=\"Computer program\">programs</a>\". Haikonen believes that, when implemented with sufficient complexity, this architecture will develop consciousness, which he considers to be \"a style and way of operation, characterized by distributed signal representation, perception process, cross-modality reporting and availability for retrospection.\" Haikonen is not alone in this process view of consciousness, or the view that AC will spontaneously emerge in <a href=\"/wiki/Autonomous_agent\" title=\"Autonomous agent\">autonomous agents</a> that have a suitable neuro-inspired architecture of complexity; these are shared by many, e.g. <a href=\"#CITEREFFreeman1999\">Freeman (1999)</a> and <a href=\"#CITEREFCotterill2003\">Cotterill (2003)</a>. A low-complexity implementation of the architecture proposed by <a href=\"#CITEREFHaikonen2003\">Haikonen (2003)</a> was reportedly not capable of AC, but did exhibit emotions as expected. See <a href=\"#CITEREFDoan2009\">Doan (2009)</a> for a comprehensive introduction to Haikonen's cognitive architecture. An updated account of Haikonen's architecture, along with a summary of his philosophical views, is given in <a href=\"#CITEREFHaikonen2012\">Haikonen (2012)</a>.\n</p>\n<h4><span id=\"Shanahan.27s_cognitive_architecture\"></span><span class=\"mw-headline\" id=\"Shanahan's_cognitive_architecture\">Shanahan's cognitive architecture</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_consciousness&amp;action=edit&amp;section=19\" title=\"Edit section: Shanahan's cognitive architecture\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h4>\n<p><a href=\"/wiki/Murray_Shanahan\" title=\"Murray Shanahan\">Murray Shanahan</a> describes a cognitive architecture that combines Baars's idea of a global workspace with a mechanism for internal simulation (\"imagination\") (<a href=\"#CITEREFShanahan2006\">Shanahan 2006</a>). For discussions of Shanahan's architecture, see (<a href=\"#CITEREFGamez2008\">Gamez 2008</a>) and (<a href=\"#CITEREFReggia2013\">Reggia 2013</a>) and Chapter 20 of (<a href=\"#CITEREFHaikonen2012\">Haikonen 2012</a>).\n</p>\n<h4><span id=\"Takeno.27s_self-awareness_research\"></span><span class=\"mw-headline\" id=\"Takeno's_self-awareness_research\">Takeno's self-awareness research</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_consciousness&amp;action=edit&amp;section=20\" title=\"Edit section: Takeno's self-awareness research\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h4>\n<p>Self-awareness in robots is being investigated by Junichi Takeno<sup class=\"reference\" id=\"cite_ref-17\"><a href=\"#cite_note-17\">[17]</a></sup> at <a href=\"/wiki/Meiji_University\" title=\"Meiji University\">Meiji University</a> in Japan. Takeno is asserting that he has developed a robot capable of discriminating between a self-image in a mirror and any other having an identical image to it,<sup class=\"reference\" id=\"cite_ref-18\"><a href=\"#cite_note-18\">[18]</a></sup><sup class=\"reference\" id=\"cite_ref-19\"><a href=\"#cite_note-19\">[19]</a></sup> and this claim has already been reviewed (<a href=\"#CITEREFTakenoInabaSuzuki2005\">Takeno, Inaba &amp; Suzuki 2005</a>). Takeno asserts that he first contrived the computational module called a MoNAD, which has a self-aware function, and he then constructed the artificial consciousness system by formulating the relationships between emotions, feelings and reason by connecting the modules in a hierarchy (Igarashi, Takeno 2007). Takeno completed a mirror image cognition experiment using a robot equipped with the MoNAD system. Takeno proposed the Self-Body Theory stating that \"humans feel that their own mirror image is closer to themselves than an actual part of themselves.\" The most important point in developing artificial consciousness or clarifying human consciousness is the development of a function of self awareness, and he claims that he has demonstrated physical and mathematical evidence for this in his thesis.<sup class=\"reference\" id=\"cite_ref-20\"><a href=\"#cite_note-20\">[20]</a></sup> He also demonstrated that robots can study episodes in memory where the emotions were stimulated and use this experience to take predictive actions to prevent the recurrence of unpleasant emotions (Torigoe, Takeno 2009).\n</p>\n<h4><span id=\"Aleksander.27s_impossible_mind\"></span><span class=\"mw-headline\" id=\"Aleksander's_impossible_mind\">Aleksander's impossible mind</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_consciousness&amp;action=edit&amp;section=21\" title=\"Edit section: Aleksander's impossible mind\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h4>\n<p><a href=\"/wiki/Igor_Aleksander\" title=\"Igor Aleksander\">Igor Aleksander</a>, emeritus professor of Neural Systems Engineering at <a class=\"mw-redirect\" href=\"/wiki/Imperial_College\" title=\"Imperial College\">Imperial College</a>, has extensively researched <a href=\"/wiki/Artificial_neural_network\" title=\"Artificial neural network\">artificial neural networks</a> and claims in his book <i>Impossible Minds: My Neurons, My Consciousness</i> that the principles for creating a conscious machine already exist but that it would take forty years to train such a machine to understand <a href=\"/wiki/Language\" title=\"Language\">language</a>.<sup class=\"reference\" id=\"cite_ref-21\"><a href=\"#cite_note-21\">[21]</a></sup> Whether this is true remains to be demonstrated and the basic principle stated in <i>Impossible Minds</i>—that the brain is a <a class=\"mw-redirect\" href=\"/wiki/Finite_state_machine\" title=\"Finite state machine\">neural state machine</a>—is open to doubt.<sup class=\"reference\" id=\"cite_ref-22\"><a href=\"#cite_note-22\">[22]</a></sup>\n</p>\n<h4><span id=\"Thaler.27s_Creativity_Machine_Paradigm\"></span><span class=\"mw-headline\" id=\"Thaler's_Creativity_Machine_Paradigm\">Thaler's Creativity Machine Paradigm</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_consciousness&amp;action=edit&amp;section=22\" title=\"Edit section: Thaler's Creativity Machine Paradigm\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h4>\n<p>Stephen Thaler proposed a possible connection between consciousness and creativity in his 1994 patent, called \"Device for the Autonomous Generation of Useful Information\" (DAGUI),<sup class=\"reference\" id=\"cite_ref-dagui_23-0\"><a href=\"#cite_note-dagui-23\">[23]</a></sup><sup class=\"reference\" id=\"cite_ref-24\"><a href=\"#cite_note-24\">[24]</a></sup><sup class=\"reference\" id=\"cite_ref-25\"><a href=\"#cite_note-25\">[25]</a></sup> or the so-called \"Creativity Machine\", in which computational critics govern the injection of synaptic noise and degradation into neural nets so as to induce false memories or confabulations that may qualify as potential ideas or strategies.<sup class=\"reference\" id=\"cite_ref-26\"><a href=\"#cite_note-26\">[26]</a></sup> He recruits this neural architecture and methodology to account for the subjective feel of consciousness, claiming that similar noise-driven neural assemblies within the brain invent dubious significance to overall cortical activity.<sup class=\"reference\" id=\"cite_ref-ECIIE_27-0\"><a href=\"#cite_note-ECIIE-27\">[27]</a></sup><sup class=\"reference\" id=\"cite_ref-APA_28-0\"><a href=\"#cite_note-APA-28\">[28]</a></sup><sup class=\"reference\" id=\"cite_ref-IJMC_29-0\"><a href=\"#cite_note-IJMC-29\">[29]</a></sup> Thaler's theory and the resulting patents in machine consciousness were inspired by experiments in which he internally disrupted trained neural nets so as to drive a succession of neural activation patterns that he likened to stream of consciousness.<sup class=\"reference\" id=\"cite_ref-APA_28-1\"><a href=\"#cite_note-APA-28\">[28]</a></sup><sup class=\"reference\" id=\"cite_ref-vip_30-0\"><a href=\"#cite_note-vip-30\">[30]</a></sup><sup class=\"reference\" id=\"cite_ref-gedanken_31-0\"><a href=\"#cite_note-gedanken-31\">[31]</a></sup><sup class=\"reference\" id=\"cite_ref-chaos_32-0\"><a href=\"#cite_note-chaos-32\">[32]</a></sup><sup class=\"reference\" id=\"cite_ref-33\"><a href=\"#cite_note-33\">[33]</a></sup><sup class=\"reference\" id=\"cite_ref-luciana_34-0\"><a href=\"#cite_note-luciana-34\">[34]</a></sup>\n</p>\n<h4><span id=\"Michael_Graziano.27s_attention_schema\"></span><span class=\"mw-headline\" id=\"Michael_Graziano's_attention_schema\">Michael Graziano's attention schema</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_consciousness&amp;action=edit&amp;section=23\" title=\"Edit section: Michael Graziano's attention schema\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h4>\n<div class=\"hatnote navigation-not-searchable\" role=\"note\">Main article: <a href=\"/wiki/Michael_Graziano#The_brain_basis_of_consciousness\" title=\"Michael Graziano\">Michael Graziano § The brain basis of consciousness</a></div>\n<p>In 2011, <a href=\"/wiki/Michael_Graziano\" title=\"Michael Graziano\">Michael Graziano</a> and Sabine Kastler published a paper named \"Human consciousness and its relationship to social neuroscience: A novel hypothesis\" proposing a theory of consciousness as an attention schema.<sup class=\"reference\" id=\"cite_ref-Graziano,_A_novel_hypothesis_35-0\"><a href=\"#cite_note-Graziano,_A_novel_hypothesis-35\">[35]</a></sup>  Graziano went on to publish an expanded discussion of this theory in his book \"Consciousness and the Social Brain\".<sup class=\"reference\" id=\"cite_ref-Graziano_Consciousness_and_the_Social_Brain_2-1\"><a href=\"#cite_note-Graziano_Consciousness_and_the_Social_Brain-2\">[2]</a></sup> This Attention Schema Theory of Consciousness, as he named it, proposes that the brain tracks attention to various sensory inputs by way of  an attention schema, analogous to the well study body schema that tracks the spatial place of a person's body.<sup class=\"reference\" id=\"cite_ref-Graziano_Consciousness_and_the_Social_Brain_2-2\"><a href=\"#cite_note-Graziano_Consciousness_and_the_Social_Brain-2\">[2]</a></sup>  This relates to artificial consciousness by proposing a specific mechanism of information handling, that produces what we allegedly experience and describe as consciousness, and which should be able to be duplicated by a machine using current technology. When the brain finds that person X is aware of thing Y, it is in effect modeling the state in which person X is applying an attentional enhancement to Y. In the attention schema theory, the same process can be applied to oneself. The brain tracks attention to various sensory inputs, and one's own awareness is a schematized model of one's attention. Graziano proposes specific locations in the brain for this process, and suggests that such awareness is a computed feature constructed by an expert system in the brain.\n</p>\n<h2><span class=\"mw-headline\" id=\"Testing\">Testing</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_consciousness&amp;action=edit&amp;section=24\" title=\"Edit section: Testing\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>The most well-known method for testing machine <a class=\"mw-redirect\" href=\"/wiki/Intelligence_(trait)\" title=\"Intelligence (trait)\">intelligence</a> is the <a href=\"/wiki/Turing_test\" title=\"Turing test\">Turing test</a>. But when interpreted as only observational, this test contradicts the philosophy of science principles of <a href=\"/wiki/Theory-ladenness\" title=\"Theory-ladenness\">theory dependence of observations</a>. It also has been suggested that Alan Turing's recommendation of imitating not a human adult consciousness, but a human child consciousness, should be taken seriously.<sup class=\"reference\" id=\"cite_ref-test_36-0\"><a href=\"#cite_note-test-36\">[36]</a></sup>\n</p><p>Other tests, such as <a class=\"external text\" href=\"http://www.conscious-robots.com/consscale\" rel=\"nofollow\">ConsScale</a>, test the presence of features inspired by biological systems, or measure the cognitive development of artificial systems.\n</p><p>Qualia, or phenomenological consciousness, is an inherently first-person phenomenon. Although various systems may display various signs of behavior correlated with functional consciousness, there is no conceivable way in which third-person tests can have access to first-person phenomenological features. Because of that, and because there is no empirical definition of consciousness,<sup class=\"reference\" id=\"cite_ref-37\"><a href=\"#cite_note-37\">[37]</a></sup> a test of presence of consciousness in AC may be impossible.\n</p><p>In 2014, Victor Argonov suggested a non-Turing test for machine consciousness based on machine's ability to produce philosophical judgments.<sup class=\"reference\" id=\"cite_ref-38\"><a href=\"#cite_note-38\">[38]</a></sup> He argues that a deterministic machine must be regarded as conscious if it is able to produce judgments on all problematic properties of consciousness (such as qualia or binding) having no innate (preloaded) philosophical knowledge on these issues, no philosophical discussions while learning, and no informational models of other creatures in its memory (such models may implicitly or explicitly contain knowledge about these creatures’ consciousness). However, this test can be used only to detect, but not refute the existence of consciousness. A positive result proves that machine is conscious but a negative result proves nothing. For example, absence of philosophical judgments may be caused by lack of the machine’s intellect, not by absence of consciousness.\n</p>\n<h2><span class=\"mw-headline\" id=\"In_fiction\">In fiction</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_consciousness&amp;action=edit&amp;section=25\" title=\"Edit section: In fiction\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<div class=\"hatnote navigation-not-searchable\" role=\"note\">Main article: <a class=\"mw-redirect\" href=\"/wiki/Simulated_consciousness_(science_fiction)\" title=\"Simulated consciousness (science fiction)\">Simulated consciousness (science fiction)</a></div>\n<div class=\"hatnote navigation-not-searchable\" role=\"note\">See also: <a href=\"/wiki/Artificial_intelligence_in_fiction#Sentient_AI\" title=\"Artificial intelligence in fiction\">Artificial intelligence in fiction § Sentient AI</a></div>\n<p>Characters with artificial consciousness (or at least with personalities that imply they have consciousness), from works of fiction:\n</p>\n<ul><li>AC – created by merging two AIs in the <i><a href=\"/wiki/Sprawl_trilogy\" title=\"Sprawl trilogy\">Sprawl trilogy</a></i> by <a href=\"/wiki/William_Gibson\" title=\"William Gibson\">William Gibson</a></li>\n<li><a href=\"/wiki/Agent_(The_Matrix)\" title=\"Agent (The Matrix)\">Agents</a> – in the simulated reality known as \"<a href=\"/wiki/The_Matrix\" title=\"The Matrix\">The Matrix</a>\" in <a href=\"/wiki/The_Matrix_(franchise)\" title=\"The Matrix (franchise)\"><i>The Matrix</i> franchise</a>\n<ul><li><a href=\"/wiki/Agent_Smith\" title=\"Agent Smith\">Agent Smith</a> – began as an Agent in <i><a href=\"/wiki/The_Matrix\" title=\"The Matrix\">The Matrix</a></i>, then became a renegade program of overgrowing power that could make copies of itself like a self-replicating computer virus</li></ul></li>\n<li>A.L.I.E. – Sentient genocidal AI from the TV series <i><a href=\"/wiki/The_100_(TV_series)\" title=\"The 100 (TV series)\">The 100</a></i></li>\n<li>AM (Allied Mastercomputer) – the antagonist of <i><a href=\"/wiki/Harlan_Ellison\" title=\"Harlan Ellison\">Harlan Ellison</a></i><span class=\"nowrap\" style=\"padding-left:0.1em;\">'</span>s short novel \"<a href=\"/wiki/I_Have_No_Mouth,_and_I_Must_Scream\" title=\"I Have No Mouth, and I Must Scream\">I Have No Mouth, and I Must Scream</a>\"</li>\n<li>Amusement park robots  (with pixilated consciousness) that went homicidal in <i><a href=\"/wiki/Westworld_(film)\" title=\"Westworld (film)\">Westworld</a></i> and <i><a href=\"/wiki/Futureworld\" title=\"Futureworld\">Futureworld</a></i></li>\n<li>Annalee Call – an Auton (<a href=\"/wiki/Android_(robot)\" title=\"Android (robot)\">android</a> manufactured by other androids) from the movie <i><a href=\"/wiki/Alien_Resurrection\" title=\"Alien Resurrection\">Alien Resurrection</a></i></li>\n<li><a href=\"/wiki/Arnold_Rimmer\" title=\"Arnold Rimmer\">Arnold Rimmer</a> – computer-generated sapient hologram aboard the <i><a href=\"/wiki/Red_Dwarf\" title=\"Red Dwarf\">Red Dwarf</a></i></li>\n<li>Ava – a humanoid robot in <i><a href=\"/wiki/Ex_Machina_(film)\" title=\"Ex Machina (film)\">Ex Machina</a></i></li>\n<li><a href=\"/wiki/Ash_(Alien)\" title=\"Ash (Alien)\">Ash</a> – android crew member of the <i>Nostromo</i> starship in the movie <i><a href=\"/wiki/Alien_(film)\" title=\"Alien (film)\">Alien</a></i></li>\n<li><i><a href=\"/wiki/The_Bicentennial_Man\" title=\"The Bicentennial Man\">The Bicentennial Man</a></i> – an android in Isaac Asimov's <i><a class=\"mw-redirect\" href=\"/wiki/Foundation_(Isaac_Asimov_novel)\" title=\"Foundation (Isaac Asimov novel)\">Foundation</a></i> universe</li>\n<li><a class=\"mw-redirect\" href=\"/wiki/Bishop_(Alien)\" title=\"Bishop (Alien)\">Bishop</a> – android crew member aboard the U.S.S. <i>Sulaco</i> in the movie <i><a href=\"/wiki/Aliens_(film)\" title=\"Aliens (film)\">Aliens</a></i></li>\n<li>The uploaded mind of Dr. Will Caster, which presumably included his consciousness, from the film <i><a href=\"/wiki/Transcendence_(2014_film)\" title=\"Transcendence (2014 film)\">Transcendence</a></i></li>\n<li><a href=\"/wiki/C-3PO\" title=\"C-3PO\">C-3PO</a> – protocol droid featured in all the <i><a href=\"/wiki/Star_Wars\" title=\"Star Wars\">Star Wars</a></i> movies</li>\n<li>Chappie – <i><a class=\"mw-redirect\" href=\"/wiki/CHAPPiE\" title=\"CHAPPiE\">CHAPPiE</a></i></li>\n<li>Cohen (and other Emergent AIs) – <a href=\"/wiki/Chris_Moriarty\" title=\"Chris Moriarty\">Chris Moriarty</a>'s <i>Spin</i> Series</li>\n<li><a class=\"mw-redirect\" href=\"/wiki/Commander_Data\" title=\"Commander Data\">Commander Data</a> – <i><a href=\"/wiki/Star_Trek:_The_Next_Generation\" title=\"Star Trek: The Next Generation\">Star Trek: The Next Generation</a></i></li>\n<li><a href=\"/wiki/Cortana_(Halo)\" title=\"Cortana (Halo)\">Cortana</a> (and other \"Smart AI\") – from the <i><a class=\"mw-redirect\" href=\"/wiki/Halo_(series)\" title=\"Halo (series)\">Halo</a></i> series of games</li>\n<li><a href=\"/wiki/Cylon_(Battlestar_Galactica)\" title=\"Cylon (Battlestar Galactica)\">Cylons</a> – genocidal robots with resurrection ships that enable the consciousness of any Cylon within an unspecified range to download into a new body aboard the ship upon death, from <i><a href=\"/wiki/Battlestar_Galactica_(2004_TV_series)\" title=\"Battlestar Galactica (2004 TV series)\">Battlestar Galactica</a></i></li>\n<li><a href=\"/wiki/Serena_Butler#Dune:_The_Butlerian_JihadPrequels\" title=\"Serena Butler\">Erasmus</a> – baby killer robot that incited the <a href=\"/wiki/Butlerian_Jihad\" title=\"Butlerian Jihad\">Butlerian Jihad</a> in the <i><a href=\"/wiki/Dune_(franchise)\" title=\"Dune (franchise)\">Dune</a></i> franchise</li>\n<li>Fal'Cie – Mechanical beings with god-like powers from the <i><a href=\"/wiki/Final_Fantasy_XIII\" title=\"Final Fantasy XIII\">Final Fantasy XIII</a></i> series</li>\n<li>The Geth, EDI and SAM – <i><a href=\"/wiki/Mass_Effect\" title=\"Mass Effect\">Mass Effect</a></i></li>\n<li><a href=\"/wiki/HAL_9000\" title=\"HAL 9000\">HAL 9000</a> – spaceship <a href=\"/wiki/Discovery_One\" title=\"Discovery One\">USS Discovery One's</a> onboard computer, that lethally malfunctioned due to mutually exclusive directives, from the 1968 novel <i><a href=\"/wiki/2001:_A_Space_Odyssey_(novel)\" title=\"2001: A Space Odyssey (novel)\">2001: A Space Odyssey</a></i> and in <a href=\"/wiki/2001:_A_Space_Odyssey_(film)\" title=\"2001: A Space Odyssey (film)\">the film</a></li>\n<li><a href=\"/wiki/Holly_(Red_Dwarf)\" title=\"Holly (Red Dwarf)\">Holly</a> – ship's computer with an IQ of 6000, aboard the <i><a href=\"/wiki/Red_Dwarf\" title=\"Red Dwarf\">Red Dwarf</a></i></li>\n<li>Hosts in the <i><a href=\"/wiki/Westworld\" title=\"Westworld\">Westworld</a></i> franchise</li>\n<li><a href=\"/wiki/Jane_(Ender%27s_Game)\" title=\"Jane (Ender's Game)\">Jane</a> – <a href=\"/wiki/Orson_Scott_Card\" title=\"Orson Scott Card\">Orson Scott Card</a>'s <i><a href=\"/wiki/Speaker_for_the_Dead\" title=\"Speaker for the Dead\">Speaker for the Dead</a></i>, <i><a href=\"/wiki/Xenocide\" title=\"Xenocide\">Xenocide</a></i>, <i><a href=\"/wiki/Children_of_the_Mind\" title=\"Children of the Mind\">Children of the Mind</a></i>, and \"<a class=\"mw-redirect\" href=\"/wiki/Investment_Counselor_(short_story)\" title=\"Investment Counselor (short story)\">Investment Counselor</a>\"</li>\n<li>Johnny Five – <i><a href=\"/wiki/Short_Circuit_(1986_film)\" title=\"Short Circuit (1986 film)\">Short Circuit</a></i></li>\n<li>Joshua – <i><a href=\"/wiki/WarGames\" title=\"WarGames\">WarGames</a></i></li>\n<li><a href=\"/wiki/Keymaker\" title=\"Keymaker\">Keymaker</a> – an \"exile\" sapient program in <a href=\"/wiki/The_Matrix_(franchise)\" title=\"The Matrix (franchise)\"><i>The Matrix</i> franchise</a></li>\n<li><a href=\"/wiki/The_Machine_(film)\" title=\"The Machine (film)\">\"Machine\"</a> – android from the film <i><a href=\"/wiki/The_Machine_(film)\" title=\"The Machine (film)\">The Machine</a></i>, whose owners try to kill her when they witness her conscious thoughts, out of fear that she will design better androids (intelligence explosion)</li>\n<li>Mike – <i><a href=\"/wiki/The_Moon_Is_a_Harsh_Mistress\" title=\"The Moon Is a Harsh Mistress\">The Moon Is a Harsh Mistress</a></i></li>\n<li>Mimi – humanoid robot in <i><a href=\"/wiki/Real_Humans\" title=\"Real Humans\">Real Humans</a></i>, (original title – <i>Äkta människor</i>) 2012</li>\n<li><a href=\"/wiki/Mind_(The_Culture)\" title=\"Mind (The Culture)\">The Minds</a> – <a class=\"mw-redirect\" href=\"/wiki/Iain_M._Banks\" title=\"Iain M. Banks\">Iain M. Banks</a>' <a class=\"mw-redirect\" href=\"/wiki/Culture_series\" title=\"Culture series\"><i>Culture</i> novels</a></li>\n<li><a href=\"/wiki/Organizations_of_the_Dune_universe#Prequels\" title=\"Organizations of the Dune universe\">Omnius</a> – sentient computer network that controlled the Universe until overthrown by the <a href=\"/wiki/Butlerian_Jihad\" title=\"Butlerian Jihad\">Butlerian Jihad</a> in the <i><a href=\"/wiki/Dune_(franchise)\" title=\"Dune (franchise)\">Dune</a></i> franchise</li>\n<li>Operating Systems in the movie <i><a href=\"/wiki/Her_(film)\" title=\"Her (film)\">Her</a></i></li>\n<li><a href=\"/wiki/The_Oracle_(The_Matrix)\" title=\"The Oracle (The Matrix)\">The Oracle</a> – sapient program in <a href=\"/wiki/The_Matrix_(franchise)\" title=\"The Matrix (franchise)\"><i>The Matrix</i> franchise</a></li>\n<li>Professor James Moriarty – sentient holodeck character in the \"<a href=\"/wiki/Ship_in_a_Bottle_(Star_Trek:_The_Next_Generation)\" title=\"Ship in a Bottle (Star Trek: The Next Generation)\">Ship in a Bottle</a>\" episode from <i><a href=\"/wiki/Star_Trek:_The_Next_Generation\" title=\"Star Trek: The Next Generation\">Star Trek: The Next Generation</a></i></li>\n<li>In <a href=\"/wiki/Greg_Egan\" title=\"Greg Egan\">Greg Egan</a>'s novel <i><a href=\"/wiki/Permutation_City\" title=\"Permutation City\">Permutation City</a></i> the protagonist creates digital copies of himself to conduct experiments that are also related to implications of artificial consciousness on <a href=\"/wiki/Identity_(social_science)\" title=\"Identity (social science)\">identity</a></li>\n<li><a class=\"mw-redirect\" href=\"/wiki/Puppet_Master_(Ghost_in_the_Shell)\" title=\"Puppet Master (Ghost in the Shell)\">Puppet Master</a> – <i><a href=\"/wiki/Ghost_in_the_Shell\" title=\"Ghost in the Shell\">Ghost in the Shell</a></i> <a href=\"/wiki/Manga\" title=\"Manga\">manga</a> and <a href=\"/wiki/Anime\" title=\"Anime\">anime</a></li>\n<li><a href=\"/wiki/R2-D2\" title=\"R2-D2\">R2-D2</a> – exciteable <a class=\"mw-redirect\" href=\"/wiki/Astromech_droid\" title=\"Astromech droid\">astromech droid</a> featured in all the <i><a href=\"/wiki/Star_Wars\" title=\"Star Wars\">Star Wars</a></i> movies</li>\n<li><a href=\"/wiki/Replicant\" title=\"Replicant\">Replicants</a> – bio-robotic androids from the novel <i><a href=\"/wiki/Do_Androids_Dream_of_Electric_Sheep%3F\" title=\"Do Androids Dream of Electric Sheep?\">Do Androids Dream of Electric Sheep?</a></i> and the movie <i><a href=\"/wiki/Blade_Runner\" title=\"Blade Runner\">Blade Runner</a></i> which portray what might happen when artificially conscious robots are modeled very closely upon humans</li>\n<li><a href=\"/wiki/Roboduck\" title=\"Roboduck\">Roboduck</a> – combat robot superhero in the <i><a href=\"/wiki/NEW-GEN\" title=\"NEW-GEN\">NEW-GEN</a></i> comic book series from Marvel Comics</li>\n<li>Robots in <a href=\"/wiki/Isaac_Asimov\" title=\"Isaac Asimov\">Isaac Asimov</a>'s <a href=\"/wiki/Robot_series_(Asimov)\" title=\"Robot series (Asimov)\"><i>Robot</i> series</a></li>\n<li>Robots in <a href=\"/wiki/The_Matrix_(franchise)\" title=\"The Matrix (franchise)\"><i>The Matrix</i> franchise</a>, especially in <i><a href=\"/wiki/The_Animatrix\" title=\"The Animatrix\">The Animatrix</a></i></li>\n<li>The Ship – the result of a large-scale AC experiment, in <a href=\"/wiki/Frank_Herbert\" title=\"Frank Herbert\">Frank Herbert</a>'s <i><a href=\"/wiki/Destination:_Void\" title=\"Destination: Void\">Destination: Void</a></i> and sequels, despite past edicts warning against \"Making a Machine in the Image of a Man's Mind\"</li>\n<li><a href=\"/wiki/Skynet_(Terminator)\" title=\"Skynet (Terminator)\">Skynet</a> – from the <i><a href=\"/wiki/Terminator_(franchise)\" title=\"Terminator (franchise)\">Terminator</a></i> franchise</li>\n<li>\"Synths\" are a type of <a href=\"/wiki/Android_(robot)\" title=\"Android (robot)\">android</a> in the video game <i><a href=\"/wiki/Fallout_4\" title=\"Fallout 4\">Fallout 4</a></i>. There is a faction in the game known as \"The Railroad\" which believes that, as conscious beings, synths have their own rights. The Institute, the lab that produces the synths, mostly does not believe they are truly conscious and attributes any apparent desires for freedom as a malfunction.</li>\n<li><a href=\"/wiki/TARDIS\" title=\"TARDIS\">TARDIS</a> – time machine and spacecraft of <i><a href=\"/wiki/Doctor_Who\" title=\"Doctor Who\">Doctor Who</a></i>, sometimes portrayed with a mind of its own</li>\n<li><a href=\"/wiki/Terminator_(character)\" title=\"Terminator (character)\">Terminator cyborgs</a> – from the <i><a href=\"/wiki/Terminator_(franchise)\" title=\"Terminator (franchise)\">Terminator</a></i> franchise, with visual consciousness depicted via first-person perspective</li>\n<li><a href=\"/wiki/Transformers\" title=\"Transformers\">Transformers</a> – sentient robots from the various series in the Transformers robot superhero franchise of the same name</li>\n<li>Vanamonde – an artificial being that was immensely powerful but entirely child-like in <a href=\"/wiki/Arthur_C._Clarke\" title=\"Arthur C. Clarke\">Arthur C. Clarke</a>'s <i><a href=\"/wiki/The_City_and_the_Stars\" title=\"The City and the Stars\">The City and the Stars</a></i></li>\n<li>WALL-E – a robot and the title character in <i><a href=\"/wiki/WALL-E\" title=\"WALL-E\">WALL-E</a></i></li>\n<li>Gideon – An interactive artificial consciousness made by <a href=\"/wiki/Flash_(Barry_Allen)\" title=\"Flash (Barry Allen)\">Barry Allen</a> shown in DC comics and shows like <i><a href=\"/wiki/The_Flash_(2014_TV_series)\" title=\"The Flash (2014 TV series)\">The Flash</a></i> and <i><a href=\"/wiki/Legends_of_Tomorrow\" title=\"Legends of Tomorrow\">Legends of Tomorrow</a></i></li></ul>\n<h2><span class=\"mw-headline\" id=\"See_also\">See also</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_consciousness&amp;action=edit&amp;section=26\" title=\"Edit section: See also\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<div class=\"div-col columns column-width\" style=\"-moz-column-width: 30em; -webkit-column-width: 30em; column-width: 30em;\">\n<ul><li><b>General fields and theories</b>\n<ul><li><a href=\"/wiki/Artificial_intelligence\" title=\"Artificial intelligence\">Artificial intelligence</a>\n<ul><li><a href=\"/wiki/Artificial_general_intelligence\" title=\"Artificial general intelligence\">Artificial general intelligence</a> (AGI) – some consider AC a subfield of AGI research</li>\n<li><a class=\"mw-redirect\" href=\"/wiki/Intelligence_explosion\" title=\"Intelligence explosion\">Intelligence explosion</a> – what may happen when a sentient AI redesigns itself in iterative cycles</li></ul></li>\n<li><a class=\"mw-redirect\" href=\"/wiki/Brain-computer_interface\" title=\"Brain-computer interface\">Brain-computer interface</a></li>\n<li><a href=\"/wiki/Computational_theory_of_mind\" title=\"Computational theory of mind\">Computational theory of mind</a>\n<ul><li><a class=\"mw-redirect\" href=\"/wiki/Consciousness_in_animals\" title=\"Consciousness in animals\">Consciousness in animals</a></li>\n<li><a class=\"mw-redirect\" href=\"/wiki/Simulated_consciousness_(science_fiction)\" title=\"Simulated consciousness (science fiction)\">Simulated consciousness (science fiction)</a></li></ul></li>\n<li><a href=\"/wiki/Identity_of_indiscernibles\" title=\"Identity of indiscernibles\">Identity of indiscernibles</a></li>\n<li><a href=\"/wiki/Mind_uploading\" title=\"Mind uploading\">Mind uploading</a></li>\n<li><a href=\"/wiki/Neurotechnology\" title=\"Neurotechnology\">Neurotechnology</a></li>\n<li><a href=\"/wiki/Philosophy_of_mind\" title=\"Philosophy of mind\">Philosophy of mind</a></li>\n<li><a href=\"/wiki/Simulated_reality\" title=\"Simulated reality\">Simulated reality</a></li>\n<li><a href=\"/wiki/Quantum_cognition\" title=\"Quantum cognition\">Quantum cognition</a></li></ul></li>\n<li><b>Proposed concepts and implementations</b>\n<ul><li><a href=\"/wiki/ADS-AC\" title=\"ADS-AC\">ADS-AC (system)</a></li>\n<li><a href=\"/wiki/Conceptual_space\" title=\"Conceptual space\">Conceptual space</a> – conceptual prototype</li>\n<li><a href=\"/wiki/Copycat_(software)\" title=\"Copycat (software)\">Copycat (cognitive architecture)</a></li>\n<li><a class=\"mw-redirect\" href=\"/wiki/Global_Workspace_Theory\" title=\"Global Workspace Theory\">Global Workspace Theory</a></li>\n<li><a href=\"/wiki/Greedy_reductionism\" title=\"Greedy reductionism\">Greedy reductionism</a> – avoid oversimplifying anything essential</li>\n<li><a href=\"/wiki/Image_schema\" title=\"Image schema\">Image schema</a> – spatial patterns</li>\n<li><a href=\"/wiki/Kismet_(robot)\" title=\"Kismet (robot)\">Kismet (robot)</a></li>\n<li><a href=\"/wiki/LIDA_(cognitive_architecture)\" title=\"LIDA (cognitive architecture)\">LIDA (cognitive architecture)</a></li>\n<li><a href=\"/wiki/Memory-prediction_framework\" title=\"Memory-prediction framework\">Memory-prediction framework</a></li>\n<li><a class=\"mw-redirect\" href=\"/wiki/Psi-Theory\" title=\"Psi-Theory\">Psi-Theory</a></li>\n<li>Brain waves and <a href=\"/wiki/Turtle_(robot)\" title=\"Turtle (robot)\">Turtle robot</a> by <a href=\"/wiki/William_Grey_Walter\" title=\"William Grey Walter\">William Grey Walter</a></li></ul></li></ul>\n</div>\n<h2><span class=\"mw-headline\" id=\"References\">References</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_consciousness&amp;action=edit&amp;section=27\" title=\"Edit section: References\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<h3><span class=\"mw-headline\" id=\"Citations\">Citations</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_consciousness&amp;action=edit&amp;section=28\" title=\"Edit section: Citations\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<div class=\"reflist columns references-column-width\" style=\"-moz-column-width: 30em; -webkit-column-width: 30em; column-width: 30em; list-style-type: decimal;\">\n<ol class=\"references\">\n<li id=\"cite_note-gunn-1\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-gunn_1-0\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Thaler, S. L. (1998). \"The emerging intelligence and its critical look at us\". <i>Journal of Near-Death Studies</i>. <b>17</b> (1): 21–29. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a class=\"external text\" href=\"//doi.org/10.1023%2FA%3A1022990118714\" rel=\"nofollow\">10.1023/A:1022990118714</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Near-Death+Studies&amp;rft.atitle=The+emerging+intelligence+and+its+critical+look+at+us&amp;rft.volume=17&amp;rft.issue=1&amp;rft.pages=21-29&amp;rft.date=1998&amp;rft_id=info%3Adoi%2F10.1023%2FA%3A1022990118714&amp;rft.aulast=Thaler&amp;rft.aufirst=S.+L.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><style data-mw-deduplicate=\"TemplateStyles:r879151008\">.mw-parser-output cite.citation{font-style:inherit}.mw-parser-output .citation q{quotes:\"\\\"\"\"\\\"\"\"'\"\"'\"}.mw-parser-output .citation .cs1-lock-free a{background:url(\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png\")no-repeat;background-position:right .1em center}.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:url(\"//upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Lock-gray-alt-2.svg/9px-Lock-gray-alt-2.svg.png\")no-repeat;background-position:right .1em center}.mw-parser-output .citation .cs1-lock-subscription a{background:url(\"//upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Lock-red-alt-2.svg/9px-Lock-red-alt-2.svg.png\")no-repeat;background-position:right .1em center}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration{color:#555}.mw-parser-output .cs1-subscription span,.mw-parser-output .cs1-registration span{border-bottom:1px dotted;cursor:help}.mw-parser-output .cs1-ws-icon a{background:url(\"//upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Wikisource-logo.svg/12px-Wikisource-logo.svg.png\")no-repeat;background-position:right .1em center}.mw-parser-output code.cs1-code{color:inherit;background:inherit;border:inherit;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;font-size:100%}.mw-parser-output .cs1-visible-error{font-size:100%}.mw-parser-output .cs1-maint{display:none;color:#33aa33;margin-left:0.3em}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration,.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left,.mw-parser-output .cs1-kern-wl-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right,.mw-parser-output .cs1-kern-wl-right{padding-right:0.2em}</style></span>\n</li>\n<li id=\"cite_note-Graziano_Consciousness_and_the_Social_Brain-2\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-Graziano_Consciousness_and_the_Social_Brain_2-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-Graziano_Consciousness_and_the_Social_Brain_2-1\"><sup><i><b>b</b></i></sup></a> <a href=\"#cite_ref-Graziano_Consciousness_and_the_Social_Brain_2-2\"><sup><i><b>c</b></i></sup></a></span> <span class=\"reference-text\"><cite class=\"citation book\">Graziano, Michael (2013). <i>Consciousness and the Social Brain</i>. Oxford University Press. <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a> <a href=\"/wiki/Special:BookSources/978-0199928644\" title=\"Special:BookSources/978-0199928644\">978-0199928644</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Consciousness+and+the+Social+Brain&amp;rft.pub=Oxford+University+Press&amp;rft.date=2013&amp;rft.isbn=978-0199928644&amp;rft.aulast=Graziano&amp;rft.aufirst=Michael&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></span>\n</li>\n<li id=\"cite_note-3\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-3\">^</a></b></span> <span class=\"reference-text\"><i><a href=\"/wiki/Artificial_Intelligence:_A_Modern_Approach\" title=\"Artificial Intelligence: A Modern Approach\">Artificial Intelligence: A Modern Approach</a></i> includes the <a href=\"/wiki/Philosophy\" title=\"Philosophy\">philosophical</a> foundations of AI including the questions of consciousness <a class=\"external free\" href=\"http://aima.cs.berkeley.edu/contents.html\" rel=\"nofollow\">http://aima.cs.berkeley.edu/contents.html</a>, Russell, Stuart J., Norvig, Peter, 2003, Upper Saddle River, New Jersey: Prentice Hall, <link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/><a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a> <a href=\"/wiki/Special:BookSources/0-13-790395-2\" title=\"Special:BookSources/0-13-790395-2\">0-13-790395-2</a></span>\n</li>\n<li id=\"cite_note-4\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-4\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Schlagel, R. H. (1999). \"Why not artificial consciousness or thought?\". <i>Minds and Machines</i>. <b>9</b> (1): 3–28. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a class=\"external text\" href=\"//doi.org/10.1023%2Fa%3A1008374714117\" rel=\"nofollow\">10.1023/a:1008374714117</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Minds+and+Machines&amp;rft.atitle=Why+not+artificial+consciousness+or+thought%3F&amp;rft.volume=9&amp;rft.issue=1&amp;rft.pages=3-28&amp;rft.date=1999&amp;rft_id=info%3Adoi%2F10.1023%2Fa%3A1008374714117&amp;rft.aulast=Schlagel&amp;rft.aufirst=R.+H.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></span>\n</li>\n<li id=\"cite_note-5\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-5\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Searle, J. R. (1980). <a class=\"external text\" href=\"http://cogprints.org/7150/1/10.1.1.83.5248.pdf\" rel=\"nofollow\">\"Minds, brains, and programs\"</a> <span class=\"cs1-format\">(PDF)</span>. <i>Behavioral and Brain Sciences</i>. <b>3</b> (3): 417–457. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a class=\"external text\" href=\"//doi.org/10.1017%2Fs0140525x00005756\" rel=\"nofollow\">10.1017/s0140525x00005756</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Behavioral+and+Brain+Sciences&amp;rft.atitle=Minds%2C+brains%2C+and+programs&amp;rft.volume=3&amp;rft.issue=3&amp;rft.pages=417-457&amp;rft.date=1980&amp;rft_id=info%3Adoi%2F10.1017%2Fs0140525x00005756&amp;rft.aulast=Searle&amp;rft.aufirst=J.+R.&amp;rft_id=http%3A%2F%2Fcogprints.org%2F7150%2F1%2F10.1.1.83.5248.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></span>\n</li>\n<li id=\"cite_note-6\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-6\">^</a></b></span> <span class=\"reference-text\"><a class=\"external text\" href=\"http://ieeexplore.ieee.org/xpl/login.jsp?tp=&amp;arnumber=933500&amp;url=http%3A%2F%2Fieeexplore.ieee.org%2Fiel5%2F2%2F20203%2F00933500\" rel=\"nofollow\">Artificial consciousness: Utopia or real possibility?</a> Buttazzo, Giorgio, July 2001, Computer, ISSN 0018-9162</span>\n</li>\n<li id=\"cite_note-7\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-7\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation web\">Chalmers, David (1995). <a class=\"external text\" href=\"http://consc.net/papers/qualia.html\" rel=\"nofollow\">\"Absent Qualia, Fading Qualia, Dancing Qualia\"</a><span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">12 April</span> 2016</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Absent+Qualia%2C+Fading+Qualia%2C+Dancing+Qualia&amp;rft.date=1995&amp;rft.aulast=Chalmers&amp;rft.aufirst=David&amp;rft_id=http%3A%2F%2Fconsc.net%2Fpapers%2Fqualia.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></span>\n</li>\n<li id=\"cite_note-8\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-8\">^</a></b></span> <span class=\"reference-text\"><a class=\"external text\" href=\"http://loebner03.hamill.co.uk/docs/LPC%20Official%20Rules%20v2.0.pdf\" rel=\"nofollow\">Loebner Prize Contest Official Rules — Version 2.0</a> The competition was directed by <a href=\"/wiki/David_Hamill\" title=\"David Hamill\">David Hamill</a> and the rules were developed by members of the Robitron Yahoo group.</span>\n</li>\n<li id=\"cite_note-9\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-9\">^</a></b></span> <span class=\"reference-text\">Joëlle Proust in <i>Neural Correlates of Consciousness</i>, Thomas Metzinger, 2000, MIT, pages 307-324</span>\n</li>\n<li id=\"cite_note-10\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-10\">^</a></b></span> <span class=\"reference-text\">Christof Koch, <i>The Quest for Consciousness</i>, 2004, page 2 footnote 2</span>\n</li>\n<li id=\"cite_note-11\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-11\">^</a></b></span> <span class=\"reference-text\">Tulving, E. 1985. Memory and consciousness. Canadian Psychology 26:1-12</span>\n</li>\n<li id=\"cite_note-12\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-12\">^</a></b></span> <span class=\"reference-text\">Franklin, Stan, et al. \"The role of consciousness in memory.\" Brains, Minds and Media 1.1 (2005): 38.</span>\n</li>\n<li id=\"cite_note-13\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-13\">^</a></b></span> <span class=\"reference-text\">Franklin, Stan. \"Perceptual memory and learning: Recognizing, categorizing, and relating.\" Proc. Developmental Robotics AAAI Spring Symp. 2005.</span>\n</li>\n<li id=\"cite_note-14\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-14\">^</a></b></span> <span class=\"reference-text\">Shastri, L. 2002. Episodic memory and cortico-hippocampal interactions. Trends in Cognitive Sciences</span>\n</li>\n<li id=\"cite_note-15\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-15\">^</a></b></span> <span class=\"reference-text\">Kanerva, Pentti. Sparse distributed memory. MIT press, 1988.</span>\n</li>\n<li id=\"cite_note-Aleksander_1995-16\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-Aleksander_1995_16-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-Aleksander_1995_16-1\"><sup><i><b>b</b></i></sup></a></span> <span class=\"reference-text\">Aleksander 1995</span>\n</li>\n<li id=\"cite_note-17\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-17\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation web\"><a class=\"external text\" href=\"https://web.archive.org/web/20070703091242/http://robonable.typepad.jp/robot/2_/index.html\" rel=\"nofollow\">\"Robot\"</a>. Archived from <a class=\"external text\" href=\"http://robonable.typepad.jp/robot/2_/index.html\" rel=\"nofollow\">the original</a> on 2007-07-03<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2007-07-03</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Robot&amp;rft_id=http%3A%2F%2Frobonable.typepad.jp%2Frobot%2F2_%2Findex.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></span>\n</li>\n<li id=\"cite_note-18\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-18\">^</a></b></span> <span class=\"reference-text\"><a class=\"external text\" href=\"http://www.rs.cs.meiji.ac.jp/Takeno_Archive.html\" rel=\"nofollow\">Takeno - Archive No...</a></span>\n</li>\n<li id=\"cite_note-19\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-19\">^</a></b></span> <span class=\"reference-text\"><a class=\"external text\" href=\"https://web.archive.org/web/20090203193304/http://www.mimed.mw.tum.de/06-12-18_MIMED_LUETH-002918.PDF\" rel=\"nofollow\">The world first self-aware robot and The success of mirror image cognition</a>, Takeno</span>\n</li>\n<li id=\"cite_note-20\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-20\">^</a></b></span> <span class=\"reference-text\"><a class=\"external text\" href=\"http://www.s2is.org/Issues/v1/n4/papers/paper4.pdf\" rel=\"nofollow\">A Robot Succeeds in 100% Mirror Image Cognition</a>, Takeno, 2008</span>\n</li>\n<li id=\"cite_note-21\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-21\">^</a></b></span> <span class=\"reference-text\">Aleksander I (1996) <i>Impossible Minds: My Neurons, My Consciousness</i>, Imperial College Press <link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/><a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a> <a href=\"/wiki/Special:BookSources/1-86094-036-6\" title=\"Special:BookSources/1-86094-036-6\">1-86094-036-6</a></span>\n</li>\n<li id=\"cite_note-22\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-22\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Wilson, RJ (1998). \"review of <i>Impossible Minds</i>\". <i>Journal of Consciousness Studies</i>. <b>5</b> (1): 115–6.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Consciousness+Studies&amp;rft.atitle=review+of+Impossible+Minds&amp;rft.volume=5&amp;rft.issue=1&amp;rft.pages=115-6&amp;rft.date=1998&amp;rft.aulast=Wilson&amp;rft.aufirst=RJ&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></span>\n</li>\n<li id=\"cite_note-dagui-23\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-dagui_23-0\">^</a></b></span> <span class=\"reference-text\">Thaler, S.L., \"<a class=\"external text\" href=\"https://web.archive.org/web/20170313064154/http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;co1=AND&amp;d=PTXT&amp;s1=5659666.PN.&amp;OS=PN%2F5659666&amp;RS=PN%2F5659666\" rel=\"nofollow\">Device for the autonomous generation of useful information</a>\"</span>\n</li>\n<li id=\"cite_note-24\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-24\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Marupaka, N.; Lyer, L.; Minai, A. (2012). <a class=\"external text\" href=\"http://www.ece.uc.edu/~aminai/papers/marupaka_creativity_NN12.pdf\" rel=\"nofollow\">\"Connectivity and thought: The influence of semantic network structure in a neurodynamical model of thinking\"</a> <span class=\"cs1-format\">(PDF)</span>. <i>Neural Networks</i>. <b>32</b>: 147–158. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a class=\"external text\" href=\"//doi.org/10.1016%2Fj.neunet.2012.02.004\" rel=\"nofollow\">10.1016/j.neunet.2012.02.004</a>. <a class=\"mw-redirect\" href=\"/wiki/PubMed_Identifier\" title=\"PubMed Identifier\">PMID</a> <a class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/22397950\" rel=\"nofollow\">22397950</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Neural+Networks&amp;rft.atitle=Connectivity+and+thought%3A+The+influence+of+semantic+network+structure+in+a+neurodynamical+model+of+thinking&amp;rft.volume=32&amp;rft.pages=147-158&amp;rft.date=2012&amp;rft_id=info%3Adoi%2F10.1016%2Fj.neunet.2012.02.004&amp;rft_id=info%3Apmid%2F22397950&amp;rft.aulast=Marupaka&amp;rft.aufirst=N.&amp;rft.au=Lyer%2C+L.&amp;rft.au=Minai%2C+A.&amp;rft_id=http%3A%2F%2Fwww.ece.uc.edu%2F~aminai%2Fpapers%2Fmarupaka_creativity_NN12.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></span>\n</li>\n<li id=\"cite_note-25\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-25\">^</a></b></span> <span class=\"reference-text\">Roque, R. and Barreira, A. (2011). \"O Paradigma da \"Máquina de Criatividade\" e a Geração de Novidades em um Espaço Conceitual,\" 3º Seminário Interno de Cognição Artificial - SICA 2011 – FEEC – UNICAMP.</span>\n</li>\n<li id=\"cite_note-26\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-26\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation book\">Minati, Gianfranco; Vitiello, Giuseppe (2006). \"Mistake Making Machines\". <i>Systemics of Emergence: Research and Development</i>. pp. 67–78. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a class=\"external text\" href=\"//doi.org/10.1007%2F0-387-28898-8_4\" rel=\"nofollow\">10.1007/0-387-28898-8_4</a>. <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a> <a href=\"/wiki/Special:BookSources/978-0-387-28899-4\" title=\"Special:BookSources/978-0-387-28899-4\">978-0-387-28899-4</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Mistake+Making+Machines&amp;rft.btitle=Systemics+of+Emergence%3A+Research+and+Development&amp;rft.pages=67-78&amp;rft.date=2006&amp;rft_id=info%3Adoi%2F10.1007%2F0-387-28898-8_4&amp;rft.isbn=978-0-387-28899-4&amp;rft.aulast=Minati&amp;rft.aufirst=Gianfranco&amp;rft.au=Vitiello%2C+Giuseppe&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></span>\n</li>\n<li id=\"cite_note-ECIIE-27\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-ECIIE_27-0\">^</a></b></span> <span class=\"reference-text\">Thaler, S. L. (2013) <a class=\"external text\" href=\"http://www.springerreference.com/docs/html/chapterdbid/358097.html\" rel=\"nofollow\">The Creativity Machine Paradigm, Encyclopedia of Creativity, Invention, Innovation, and Entrepreneurship</a>, (ed.) E.G. Carayannis, Springer Science+Business Media</span>\n</li>\n<li id=\"cite_note-APA-28\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-APA_28-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-APA_28-1\"><sup><i><b>b</b></i></sup></a></span> <span class=\"reference-text\">Thaler, S. L. (2011). \"The Creativity Machine: Withstanding the Argument from Consciousness,\" APA Newsletter on Philosophy and Computers</span>\n</li>\n<li id=\"cite_note-IJMC-29\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-IJMC_29-0\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Thaler, S. L. (2014). \"Synaptic Perturbation and Consciousness\". <i>Int. J. Mach. Conscious</i>. <b>6</b> (2): 75–107. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a class=\"external text\" href=\"//doi.org/10.1142%2FS1793843014400137\" rel=\"nofollow\">10.1142/S1793843014400137</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Int.+J.+Mach.+Conscious&amp;rft.atitle=Synaptic+Perturbation+and+Consciousness&amp;rft.volume=6&amp;rft.issue=2&amp;rft.pages=75-107&amp;rft.date=2014&amp;rft_id=info%3Adoi%2F10.1142%2FS1793843014400137&amp;rft.aulast=Thaler&amp;rft.aufirst=S.+L.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></span>\n</li>\n<li id=\"cite_note-vip-30\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-vip_30-0\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Thaler, S. L. (1995). \"<span class=\"cs1-kern-left\">\"</span>Virtual Input Phenomena\" Within the Death of a Simple Pattern Associator\". <i>Neural Networks</i>. <b>8</b> (1): 55–65. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a class=\"external text\" href=\"//doi.org/10.1016%2F0893-6080%2894%2900065-t\" rel=\"nofollow\">10.1016/0893-6080(94)00065-t</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Neural+Networks&amp;rft.atitle=%22Virtual+Input+Phenomena%22+Within+the+Death+of+a+Simple+Pattern+Associator&amp;rft.volume=8&amp;rft.issue=1&amp;rft.pages=55-65&amp;rft.date=1995&amp;rft_id=info%3Adoi%2F10.1016%2F0893-6080%2894%2900065-t&amp;rft.aulast=Thaler&amp;rft.aufirst=S.+L.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></span>\n</li>\n<li id=\"cite_note-gedanken-31\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-gedanken_31-0\">^</a></b></span> <span class=\"reference-text\">Thaler, S. L. (1995). Death of a gedanken creature, <i>Journal of Near-Death Studies</i>, 13(3), Spring 1995</span>\n</li>\n<li id=\"cite_note-chaos-32\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-chaos_32-0\">^</a></b></span> <span class=\"reference-text\">Thaler, S. L. (1996). Is Neuronal Chaos the Source of Stream of Consciousness? In Proceedings of the World Congress on Neural Networks, (WCNN’96), Lawrence Erlbaum, Mawah, NJ.</span>\n</li>\n<li id=\"cite_note-33\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-33\">^</a></b></span> <span class=\"reference-text\">Mayer, H. A. (2004). <a class=\"external text\" href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.89.5420&amp;rep=rep1&amp;type=pdf\" rel=\"nofollow\">A modular neurocontroller for creative mobile autonomous robots learning by temporal difference</a>, Systems, Man and Cybernetics, 2004 IEEE International Conference(Volume:6 )</span>\n</li>\n<li id=\"cite_note-luciana-34\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-luciana_34-0\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Ricciardiello, L.; Fornaro, P. (2013). \"Beyond the cliff of creativity, a novel key to Bipolar Disorder and creativity\". <i>Medical Hypotheses</i>. <b>80</b> (5): 534–543. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a class=\"external text\" href=\"//doi.org/10.1016%2Fj.mehy.2012.12.018\" rel=\"nofollow\">10.1016/j.mehy.2012.12.018</a>. <a class=\"mw-redirect\" href=\"/wiki/PubMed_Identifier\" title=\"PubMed Identifier\">PMID</a> <a class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/23452643\" rel=\"nofollow\">23452643</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Medical+Hypotheses&amp;rft.atitle=Beyond+the+cliff+of+creativity%2C+a+novel+key+to+Bipolar+Disorder+and+creativity&amp;rft.volume=80&amp;rft.issue=5&amp;rft.pages=534-543&amp;rft.date=2013&amp;rft_id=info%3Adoi%2F10.1016%2Fj.mehy.2012.12.018&amp;rft_id=info%3Apmid%2F23452643&amp;rft.aulast=Ricciardiello&amp;rft.aufirst=L.&amp;rft.au=Fornaro%2C+P.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></span>\n</li>\n<li id=\"cite_note-Graziano,_A_novel_hypothesis-35\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-Graziano,_A_novel_hypothesis_35-0\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Graziano, Michael (1 January 2011). <a class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC3223025\" rel=\"nofollow\">\"Human consciousness and its relationship to social neuroscience: A novel hypothesis\"</a>. <i>Corn Neurosci</i>. <b>2</b> (2): 98–113. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a class=\"external text\" href=\"//doi.org/10.1080%2F17588928.2011.565121\" rel=\"nofollow\">10.1080/17588928.2011.565121</a>. <a href=\"/wiki/PubMed_Central\" title=\"PubMed Central\">PMC</a> <span class=\"cs1-lock-free\" title=\"Freely accessible\"><a class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC3223025\" rel=\"nofollow\">3223025</a></span>. <a class=\"mw-redirect\" href=\"/wiki/PubMed_Identifier\" title=\"PubMed Identifier\">PMID</a> <a class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/22121395\" rel=\"nofollow\">22121395</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Corn+Neurosci.&amp;rft.atitle=Human+consciousness+and+its+relationship+to+social+neuroscience%3A+A+novel+hypothesis&amp;rft.volume=2&amp;rft.issue=2&amp;rft.pages=98-113&amp;rft.date=2011-01-01&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC3223025&amp;rft_id=info%3Apmid%2F22121395&amp;rft_id=info%3Adoi%2F10.1080%2F17588928.2011.565121&amp;rft.aulast=Graziano&amp;rft.aufirst=Michael&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC3223025&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></span>\n</li>\n<li id=\"cite_note-test-36\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-test_36-0\">^</a></b></span> <span class=\"reference-text\"><a class=\"external text\" href=\"http://web.eecs.utk.edu/~itamar/Papers/AI_MAG_2011.pdf\" rel=\"nofollow\">Mapping the Landscape of Human-Level Artificial General Intelligence</a></span>\n</li>\n<li id=\"cite_note-37\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-37\">^</a></b></span> <span class=\"reference-text\">\"Consciousness\". In Honderich T. The Oxford companion to philosophy. Oxford University Press. <link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/><a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a> <a href=\"/wiki/Special:BookSources/978-0-19-926479-7\" title=\"Special:BookSources/978-0-19-926479-7\">978-0-19-926479-7</a></span>\n</li>\n<li id=\"cite_note-38\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-38\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation journal\">Victor Argonov (2014). <a class=\"external text\" href=\"http://philpapers.org/rec/ARGMAA-2\" rel=\"nofollow\">\"Experimental Methods for Unraveling the Mind-body Problem: The Phenomenal Judgment Approach\"</a>. <i>Journal of Mind and Behavior</i>. <b>35</b>: 51–70.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Mind+and+Behavior&amp;rft.atitle=Experimental+Methods+for+Unraveling+the+Mind-body+Problem%3A+The+Phenomenal+Judgment+Approach&amp;rft.volume=35&amp;rft.pages=51-70&amp;rft.date=2014&amp;rft_id=http%3A%2F%2Fphilpapers.org%2Frec%2FARGMAA-2&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><span class=\"cs1-maint citation-comment\">CS1 maint: Uses authors parameter (<a href=\"/wiki/Category:CS1_maint:_Uses_authors_parameter\" title=\"Category:CS1 maint: Uses authors parameter\">link</a>)</span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></span>\n</li>\n</ol></div>\n<h3><span class=\"mw-headline\" id=\"Bibliography\">Bibliography</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_consciousness&amp;action=edit&amp;section=29\" title=\"Edit section: Bibliography\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<style data-mw-deduplicate=\"TemplateStyles:r853264625\">.mw-parser-output .refbegin{font-size:90%;margin-bottom:0.5em}.mw-parser-output .refbegin-hanging-indents>ul{list-style-type:none;margin-left:0}.mw-parser-output .refbegin-hanging-indents>ul>li,.mw-parser-output .refbegin-hanging-indents>dl>dd{margin-left:0;padding-left:3.2em;text-indent:-3.2em;list-style:none}.mw-parser-output .refbegin-100{font-size:100%}</style><div class=\"refbegin columns references-column-count references-column-count-2\" style=\"-moz-column-count: 2; -webkit-column-count: 2; column-count: 2;\">\n<ul><li><cite class=\"citation\" id=\"CITEREFEricsson-Zenith2010\">Ericsson-Zenith, Steven (2010), <a class=\"external text\" href=\"http://iase.info\" rel=\"nofollow\"><i>Explaining Experience In Nature</i></a>, Sunnyvale, CA: Institute for Advanced Science &amp; Engineering</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Explaining+Experience+In+Nature&amp;rft.place=Sunnyvale%2C+CA&amp;rft.pub=Institute+for+Advanced+Science+%26+Engineering&amp;rft.date=2010&amp;rft.aulast=Ericsson-Zenith&amp;rft.aufirst=Steven&amp;rft_id=http%3A%2F%2Fiase.info&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFAleksander1995\">Aleksander, Igor (1995), <a class=\"external text\" href=\"https://web.archive.org/web/19970302014628/http://www.ee.ic.ac.uk/research/neural/publications/iwann.html\" rel=\"nofollow\"><i>Artificial Neuroconsciousness: An Update</i></a>, IWANN, Archived from the original on 1997-03-02</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Artificial+Neuroconsciousness%3A+An+Update&amp;rft.pub=IWANN&amp;rft.date=1995&amp;rft.aulast=Aleksander&amp;rft.aufirst=Igor&amp;rft_id=http%3A%2F%2Fwww.ee.ic.ac.uk%2Fresearch%2Fneural%2Fpublications%2Fiwann.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><span class=\"cs1-maint citation-comment\">CS1 maint: BOT: original-url status unknown (<a href=\"/wiki/Category:CS1_maint:_BOT:_original-url_status_unknown\" title=\"Category:CS1 maint: BOT: original-url status unknown\">link</a>)</span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFArmstrong1968\">Armstrong, David (1968), <i>A Materialist Theory of Mind</i>, Routledge</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=A+Materialist+Theory+of+Mind&amp;rft.pub=Routledge&amp;rft.date=1968&amp;rft.aulast=Armstrong&amp;rft.aufirst=David&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFArrabales2009\">Arrabales, Raul (2009), <a class=\"external text\" href=\"https://web.archive.org/web/20110721234802/http://www.conscious-robots.com/raul/papers/Arrabales_ICCI09_preprint.pdf\" rel=\"nofollow\">\"Establishing a Roadmap and Metrics for Conscious Machines Development\"</a> <span class=\"cs1-format\">(PDF)</span>, <i>Proceedings of the 8th IEEE International Conference on Cognitive Informatics</i>, Hong Kong: 94–101, archived from <a class=\"external text\" href=\"http://www.conscious-robots.com/raul/papers/Arrabales_ICCI09_preprint.pdf\" rel=\"nofollow\">the original</a> <span class=\"cs1-format\">(PDF)</span> on 2011-07-21</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+of+the+8th+IEEE+International+Conference+on+Cognitive+Informatics&amp;rft.atitle=Establishing+a+Roadmap+and+Metrics+for+Conscious+Machines+Development&amp;rft.pages=94-101&amp;rft.date=2009&amp;rft.aulast=Arrabales&amp;rft.aufirst=Raul&amp;rft_id=http%3A%2F%2Fwww.conscious-robots.com%2Fraul%2Fpapers%2FArrabales_ICCI09_preprint.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFBaars1988\">Baars, Bernard (1988), <a class=\"external text\" href=\"https://web.archive.org/web/20040816183746/http://vesicle.nsi.edu/users/baars/BaarsConsciousnessBook1988/\" rel=\"nofollow\"><i>A Cognitive Theory of Consciousness</i></a>, Cambridge, MA: Cambridge University Press, <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a> <a href=\"/wiki/Special:BookSources/978-0-521-30133-6\" title=\"Special:BookSources/978-0-521-30133-6\">978-0-521-30133-6</a>, archived from <a class=\"external text\" href=\"http://vesicle.nsi.edu/users/baars/BaarsConsciousnessBook1988\" rel=\"nofollow\">the original</a> on 2004-08-16</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=A+Cognitive+Theory+of+Consciousness&amp;rft.place=Cambridge%2C+MA&amp;rft.pub=Cambridge+University+Press&amp;rft.date=1988&amp;rft.isbn=978-0-521-30133-6&amp;rft.aulast=Baars&amp;rft.aufirst=Bernard&amp;rft_id=http%3A%2F%2Fvesicle.nsi.edu%2Fusers%2Fbaars%2FBaarsConsciousnessBook1988&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFBaars1997\">Baars, Bernard (1997), <i>In the Theater of Consciousness</i>, New York, NY: Oxford University Press, <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a> <a href=\"/wiki/Special:BookSources/978-0-19-510265-9\" title=\"Special:BookSources/978-0-19-510265-9\">978-0-19-510265-9</a></cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=In+the+Theater+of+Consciousness&amp;rft.place=New+York%2C+NY&amp;rft.pub=Oxford+University+Press&amp;rft.date=1997&amp;rft.isbn=978-0-19-510265-9&amp;rft.aulast=Baars&amp;rft.aufirst=Bernard&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFBickle2003\">Bickle, John (2003), <i>Philosophy and Neuroscience: A Ruthless Reductive Account</i>, New York, NY: Springer-Verlag</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Philosophy+and+Neuroscience%3A+A+Ruthless+Reductive+Account&amp;rft.place=New+York%2C+NY&amp;rft.pub=Springer-Verlag&amp;rft.date=2003&amp;rft.aulast=Bickle&amp;rft.aufirst=John&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFBlock1978\">Block, Ned (1978), \"Troubles for Functionalism\", <i>Minnesota Studies in the Philosophy of Science 9: 261-325</i></cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Minnesota+Studies+in+the+Philosophy+of+Science+9%3A+261-325&amp;rft.atitle=Troubles+for+Functionalism&amp;rft.date=1978&amp;rft.aulast=Block&amp;rft.aufirst=Ned&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFBlock1997\">Block, Ned (1997), <i>On a confusion about a function of consciousness in Block, Flanagan and Guzeldere (eds.) The Nature of Consciousness: Philosophical Debates</i>, MIT Press</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=On+a+confusion+about+a+function+of+consciousness+in+Block%2C+Flanagan+and+Guzeldere+%28eds.%29+The+Nature+of+Consciousness%3A+Philosophical+Debates&amp;rft.pub=MIT+Press&amp;rft.date=1997&amp;rft.aulast=Block&amp;rft.aufirst=Ned&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFBoyles2012\">Boyles, Robert James M. (2012), <a class=\"external text\" href=\"http://philpapers.org/archive/BOYAQI.pdf\" rel=\"nofollow\"><i>Artificial Qualia, Intentional Systems and Machine Consciousness</i></a> <span class=\"cs1-format\">(PDF)</span>, Proceedings of the Research@DLSU Congress 2012: Science and Technology Conference, <a href=\"/wiki/International_Standard_Serial_Number\" title=\"International Standard Serial Number\">ISSN</a> <a class=\"external text\" href=\"//www.worldcat.org/issn/2012-3477\" rel=\"nofollow\">2012-3477</a></cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Artificial+Qualia%2C+Intentional+Systems+and+Machine+Consciousness&amp;rft.pub=Proceedings+of+the+Research%40DLSU+Congress+2012%3A+Science+and+Technology+Conference&amp;rft.date=2012&amp;rft.issn=2012-3477&amp;rft.aulast=Boyles&amp;rft.aufirst=Robert+James+M.&amp;rft_id=http%3A%2F%2Fphilpapers.org%2Farchive%2FBOYAQI.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFChalmers1996\">Chalmers, David (1996), <i>The Conscious Mind</i>, Oxford University Press, <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a> <a href=\"/wiki/Special:BookSources/978-0-19-510553-7\" title=\"Special:BookSources/978-0-19-510553-7\">978-0-19-510553-7</a></cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Conscious+Mind&amp;rft.pub=Oxford+University+Press&amp;rft.date=1996&amp;rft.isbn=978-0-19-510553-7&amp;rft.aulast=Chalmers&amp;rft.aufirst=David&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFCotterill2003\">Cotterill, Rodney (2003), \"Cyberchild: a Simulation Test-Bed for Consciousness Studies\",  in Holland, Owen, <a class=\"external text\" href=\"https://www.ingentaconnect.com/content/imp/jcs/2003/00000010/F0020004/1345\" rel=\"nofollow\"><i>Machine Consciousness</i></a>, Exeter, UK: Imprint Academic</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Cyberchild%3A+a+Simulation+Test-Bed+for+Consciousness+Studies&amp;rft.btitle=Machine+Consciousness&amp;rft.place=Exeter%2C+UK&amp;rft.pub=Imprint+Academic&amp;rft.date=2003&amp;rft.aulast=Cotterill&amp;rft.aufirst=Rodney&amp;rft_id=https%3A%2F%2Fwww.ingentaconnect.com%2Fcontent%2Fimp%2Fjcs%2F2003%2F00000010%2FF0020004%2F1345&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFDoan2009\">Doan, Trung (2009), <a class=\"external text\" href=\"https://web.archive.org/web/20091215095351/http://www.conscious-robots.com/en/conscious-machines/theories-of-consciousness/pentti-haikonens-architecture-for-conscious-mac.html\" rel=\"nofollow\"><i>Pentti Haikonen's architecture for conscious machines</i></a>, archived from <a class=\"external text\" href=\"http://www.conscious-robots.com/en/conscious-machines/theories-of-consciousness/pentti-haikonens-architecture-for-conscious-mac.html\" rel=\"nofollow\">the original</a> on 2009-12-15</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Pentti+Haikonen%27s+architecture+for+conscious+machines&amp;rft.date=2009&amp;rft.aulast=Doan&amp;rft.aufirst=Trung&amp;rft_id=http%3A%2F%2Fwww.conscious-robots.com%2Fen%2Fconscious-machines%2Ftheories-of-consciousness%2Fpentti-haikonens-architecture-for-conscious-mac.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFFranklin1995\">Franklin, Stan (1995), <i>Artificial Minds</i>, Boston, MA: MIT Press, <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a> <a href=\"/wiki/Special:BookSources/978-0-262-06178-0\" title=\"Special:BookSources/978-0-262-06178-0\">978-0-262-06178-0</a></cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Artificial+Minds&amp;rft.place=Boston%2C+MA&amp;rft.pub=MIT+Press&amp;rft.date=1995&amp;rft.isbn=978-0-262-06178-0&amp;rft.aulast=Franklin&amp;rft.aufirst=Stan&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFFranklin2003\">Franklin, Stan (2003), \"IDA: A Conscious Artefact\",  in Holland, Owen, <i>Machine Consciousness</i>, Exeter, UK: Imprint Academic</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=IDA%3A+A+Conscious+Artefact&amp;rft.btitle=Machine+Consciousness&amp;rft.place=Exeter%2C+UK&amp;rft.pub=Imprint+Academic&amp;rft.date=2003&amp;rft.aulast=Franklin&amp;rft.aufirst=Stan&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFFreeman1999\">Freeman, Walter (1999), <i>How Brains make up their Minds</i>, London, UK: Phoenix, <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a> <a href=\"/wiki/Special:BookSources/978-0-231-12008-1\" title=\"Special:BookSources/978-0-231-12008-1\">978-0-231-12008-1</a></cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=How+Brains+make+up+their+Minds&amp;rft.place=London%2C+UK&amp;rft.pub=Phoenix&amp;rft.date=1999&amp;rft.isbn=978-0-231-12008-1&amp;rft.aulast=Freeman&amp;rft.aufirst=Walter&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFGamez2008\">Gamez, David (2008), \"Progress in machine consciousness\", <i>Consciousness and Cognition</i>, <b>17</b> (3): 887–910, <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a class=\"external text\" href=\"//doi.org/10.1016%2Fj.concog.2007.04.005\" rel=\"nofollow\">10.1016/j.concog.2007.04.005</a>, <a class=\"mw-redirect\" href=\"/wiki/PubMed_Identifier\" title=\"PubMed Identifier\">PMID</a> <a class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/17572107\" rel=\"nofollow\">17572107</a></cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Consciousness+and+Cognition&amp;rft.atitle=Progress+in+machine+consciousness&amp;rft.volume=17&amp;rft.issue=3&amp;rft.pages=887-910&amp;rft.date=2008&amp;rft_id=info%3Adoi%2F10.1016%2Fj.concog.2007.04.005&amp;rft_id=info%3Apmid%2F17572107&amp;rft.aulast=Gamez&amp;rft.aufirst=David&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFHaikonen2003\">Haikonen, Pentti (2003), <i>The Cognitive Approach to Conscious Machines</i>, Exeter, UK: Imprint Academic, <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a> <a href=\"/wiki/Special:BookSources/978-0-907845-42-3\" title=\"Special:BookSources/978-0-907845-42-3\">978-0-907845-42-3</a></cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Cognitive+Approach+to+Conscious+Machines&amp;rft.place=Exeter%2C+UK&amp;rft.pub=Imprint+Academic&amp;rft.date=2003&amp;rft.isbn=978-0-907845-42-3&amp;rft.aulast=Haikonen&amp;rft.aufirst=Pentti&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFHaikonen2012\">Haikonen, Pentti (2012), <i>Consciousness and Robot Sentience</i>, Singapore: World Scientific, <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a> <a href=\"/wiki/Special:BookSources/978-981-4407-15-1\" title=\"Special:BookSources/978-981-4407-15-1\">978-981-4407-15-1</a></cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Consciousness+and+Robot+Sentience&amp;rft.place=Singapore&amp;rft.pub=World+Scientific&amp;rft.date=2012&amp;rft.isbn=978-981-4407-15-1&amp;rft.aulast=Haikonen&amp;rft.aufirst=Pentti&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFKoch2004\">Koch, Christof (2004), <i>The Quest for Consciousness: A Neurobiological Approach</i>, Pasadena, CA: Roberts &amp; Company Publishers, <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a> <a href=\"/wiki/Special:BookSources/978-0-9747077-0-9\" title=\"Special:BookSources/978-0-9747077-0-9\">978-0-9747077-0-9</a></cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Quest+for+Consciousness%3A+A+Neurobiological+Approach&amp;rft.place=Pasadena%2C+CA&amp;rft.pub=Roberts+%26+Company+Publishers&amp;rft.date=2004&amp;rft.isbn=978-0-9747077-0-9&amp;rft.aulast=Koch&amp;rft.aufirst=Christof&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFLewis1972\">Lewis, David (1972), \"Psychophysical and theoretical identifications\", <i>Australasian Journal of Philosophy</i>, <b>50</b> (3): 249–258, <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a class=\"external text\" href=\"//doi.org/10.1080%2F00048407212341301\" rel=\"nofollow\">10.1080/00048407212341301</a></cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Australasian+Journal+of+Philosophy&amp;rft.atitle=Psychophysical+and+theoretical+identifications&amp;rft.volume=50&amp;rft.issue=3&amp;rft.pages=249-258&amp;rft.date=1972&amp;rft_id=info%3Adoi%2F10.1080%2F00048407212341301&amp;rft.aulast=Lewis&amp;rft.aufirst=David&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFPutnam1967\">Putnam, Hilary (1967), <i>The nature of mental states in Capitan and Merrill (eds.) Art, Mind and Religion</i>, University of Pittsburgh Press</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+nature+of+mental+states+in+Capitan+and+Merrill+%28eds.%29+Art%2C+Mind+and+Religion&amp;rft.pub=University+of+Pittsburgh+Press&amp;rft.date=1967&amp;rft.aulast=Putnam&amp;rft.aufirst=Hilary&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFReggia2013\">Reggia, James (2013), \"The rise of machine consciousness: Studying consciousness with computational models\", <i>Neural Networks</i>, <b>44</b>: 112–131, <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a class=\"external text\" href=\"//doi.org/10.1016%2Fj.neunet.2013.03.011\" rel=\"nofollow\">10.1016/j.neunet.2013.03.011</a>, <a class=\"mw-redirect\" href=\"/wiki/PubMed_Identifier\" title=\"PubMed Identifier\">PMID</a> <a class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/23597599\" rel=\"nofollow\">23597599</a></cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Neural+Networks&amp;rft.atitle=The+rise+of+machine+consciousness%3A+Studying+consciousness+with+computational+models&amp;rft.volume=44&amp;rft.pages=112-131&amp;rft.date=2013&amp;rft_id=info%3Adoi%2F10.1016%2Fj.neunet.2013.03.011&amp;rft_id=info%3Apmid%2F23597599&amp;rft.aulast=Reggia&amp;rft.aufirst=James&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFSanzLópezRodríguezHernández2007\">Sanz, Ricardo; López, I; Rodríguez, M; Hernández, C (2007), <a class=\"external text\" href=\"http://cogprints.org/5941/1/ASLAB%2DA%2D2007%2D011.pdf\" rel=\"nofollow\">\"Principles for consciousness in integrated cognitive control\"</a> <span class=\"cs1-format\">(PDF)</span>, <i>Neural Networks</i>, <b>20</b> (9): 938–946, <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a class=\"external text\" href=\"//doi.org/10.1016%2Fj.neunet.2007.09.012\" rel=\"nofollow\">10.1016/j.neunet.2007.09.012</a>, <a class=\"mw-redirect\" href=\"/wiki/PubMed_Identifier\" title=\"PubMed Identifier\">PMID</a> <a class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/17936581\" rel=\"nofollow\">17936581</a></cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Neural+Networks&amp;rft.atitle=Principles+for+consciousness+in+integrated+cognitive+control&amp;rft.volume=20&amp;rft.issue=9&amp;rft.pages=938-946&amp;rft.date=2007&amp;rft_id=info%3Adoi%2F10.1016%2Fj.neunet.2007.09.012&amp;rft_id=info%3Apmid%2F17936581&amp;rft.aulast=Sanz&amp;rft.aufirst=Ricardo&amp;rft.au=L%C3%B3pez%2C+I&amp;rft.au=Rodr%C3%ADguez%2C+M&amp;rft.au=Hern%C3%A1ndez%2C+C&amp;rft_id=http%3A%2F%2Fcogprints.org%2F5941%2F1%2FASLAB%252DA%252D2007%252D011.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFSearle2004\">Searle, John (2004), <i>Mind: A Brief Introduction</i>, Oxford University Press</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Mind%3A+A+Brief+Introduction&amp;rft.pub=Oxford+University+Press&amp;rft.date=2004&amp;rft.aulast=Searle&amp;rft.aufirst=John&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFShanahan2006\">Shanahan, Murray (2006), \"A cognitive architecture that combines internal simulation with a global workspace\", <i>Consciousness and Cognition</i>, <b>15</b> (2): 443–449, <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a class=\"external text\" href=\"//doi.org/10.1016%2Fj.concog.2005.11.005\" rel=\"nofollow\">10.1016/j.concog.2005.11.005</a>, <a class=\"mw-redirect\" href=\"/wiki/PubMed_Identifier\" title=\"PubMed Identifier\">PMID</a> <a class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/16384715\" rel=\"nofollow\">16384715</a></cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Consciousness+and+Cognition&amp;rft.atitle=A+cognitive+architecture+that+combines+internal+simulation+with+a+global+workspace&amp;rft.volume=15&amp;rft.issue=2&amp;rft.pages=443-449&amp;rft.date=2006&amp;rft_id=info%3Adoi%2F10.1016%2Fj.concog.2005.11.005&amp;rft_id=info%3Apmid%2F16384715&amp;rft.aulast=Shanahan&amp;rft.aufirst=Murray&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFSun1999\">Sun, Ron (December 1999), \"Accounting for the computational basis of consciousness: A connectionist approach\", <i>Consciousness and Cognition</i>, <b>8</b> (4): 529–565, <a href=\"/wiki/CiteSeerX\" title=\"CiteSeerX\">CiteSeerX</a> <span class=\"cs1-lock-free\" title=\"Freely accessible\"><a class=\"external text\" href=\"//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.42.2681\" rel=\"nofollow\">10.1.1.42.2681</a></span>, <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a class=\"external text\" href=\"//doi.org/10.1006%2Fccog.1999.0405\" rel=\"nofollow\">10.1006/ccog.1999.0405</a>, <a class=\"mw-redirect\" href=\"/wiki/PubMed_Identifier\" title=\"PubMed Identifier\">PMID</a> <a class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/10600249\" rel=\"nofollow\">10600249</a></cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Consciousness+and+Cognition&amp;rft.atitle=Accounting+for+the+computational+basis+of+consciousness%3A+A+connectionist+approach&amp;rft.volume=8&amp;rft.issue=4&amp;rft.pages=529-565&amp;rft.date=1999-12&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.42.2681&amp;rft_id=info%3Apmid%2F10600249&amp;rft_id=info%3Adoi%2F10.1006%2Fccog.1999.0405&amp;rft.aulast=Sun&amp;rft.aufirst=Ron&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFSun2001\">Sun, Ron (2001), \"Computation, reduction, and teleology of consciousness\", <i>Cognitive Systems Research</i>, <b>1</b> (4): 241–249, <a href=\"/wiki/CiteSeerX\" title=\"CiteSeerX\">CiteSeerX</a> <span class=\"cs1-lock-free\" title=\"Freely accessible\"><a class=\"external text\" href=\"//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.20.8764\" rel=\"nofollow\">10.1.1.20.8764</a></span>, <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a class=\"external text\" href=\"//doi.org/10.1016%2FS1389-0417%2800%2900013-9\" rel=\"nofollow\">10.1016/S1389-0417(00)00013-9</a></cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Cognitive+Systems+Research&amp;rft.atitle=Computation%2C+reduction%2C+and+teleology+of+consciousness&amp;rft.volume=1&amp;rft.issue=4&amp;rft.pages=241-249&amp;rft.date=2001&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.20.8764&amp;rft_id=info%3Adoi%2F10.1016%2FS1389-0417%2800%2900013-9&amp;rft.aulast=Sun&amp;rft.aufirst=Ron&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFTakenoInabaSuzuki2005\">Takeno, Junichi; Inaba, K; Suzuki, T (June 27–30, 2005), \"Experiments and examination of <b>mirror image cognition</b> using a small robot\", <i>The 6th IEEE International Symposium on Computational Intelligence in Robotics and Automation</i>, Espoo Finland: CIRA 2005: 493–498, <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a class=\"external text\" href=\"//doi.org/10.1109%2FCIRA.2005.1554325\" rel=\"nofollow\">10.1109/CIRA.2005.1554325</a>, <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a> <a href=\"/wiki/Special:BookSources/978-0-7803-9355-4\" title=\"Special:BookSources/978-0-7803-9355-4\">978-0-7803-9355-4</a></cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+6th+IEEE+International+Symposium+on+Computational+Intelligence+in+Robotics+and+Automation&amp;rft.atitle=Experiments+and+examination+of+mirror+image+cognition+using+a+small+robot&amp;rft.pages=493-498&amp;rft.date=2005-06-27%2F2005-06-30&amp;rft_id=info%3Adoi%2F10.1109%2FCIRA.2005.1554325&amp;rft.isbn=978-0-7803-9355-4&amp;rft.aulast=Takeno&amp;rft.aufirst=Junichi&amp;rft.au=Inaba%2C+K&amp;rft.au=Suzuki%2C+T&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFCleeremans2001\">Cleeremans, Axel (2001), <a class=\"external text\" href=\"http://srsc.ulb.ac.be/axcWWW/papers/pdf/01-AXCLJ.pdf\" rel=\"nofollow\"><i>Implicit learning and consciousness</i></a> <span class=\"cs1-format\">(PDF)</span></cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Implicit+learning+and+consciousness&amp;rft.date=2001&amp;rft.aulast=Cleeremans&amp;rft.aufirst=Axel&amp;rft_id=http%3A%2F%2Fsrsc.ulb.ac.be%2FaxcWWW%2Fpapers%2Fpdf%2F01-AXCLJ.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li><cite class=\"citation\" id=\"CITEREFChalmers2011\">Chalmers, David (2011), <a class=\"external text\" href=\"https://web.archive.org/web/20151223105456/http://j-cs.org/gnuboard/bbs/download.php?bo_table=__vol012i4&amp;wr_id=1&amp;no=0\" rel=\"nofollow\">\"A Computational Foundation for the Study of Cognition\"</a>, <i>Journal of Cognitive Science</i>, Seoul Republic of Korea: 323–357, archived from <a class=\"external text\" href=\"http://j-cs.org/gnuboard/bbs/download.php?bo_table=__vol012i4&amp;wr_id=1&amp;no=0\" rel=\"nofollow\">the original</a> on 2015-12-23</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Cognitive+Science&amp;rft.atitle=A+Computational+Foundation+for+the+Study+of+Cognition&amp;rft.pages=323-357&amp;rft.date=2011&amp;rft.aulast=Chalmers&amp;rft.aufirst=David&amp;rft_id=http%3A%2F%2Fj-cs.org%2Fgnuboard%2Fbbs%2Fdownload.php%3Fbo_table%3D__vol012i4%26wr_id%3D1%26no%3D0&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li></ul>\n</div>\n<h2><span class=\"mw-headline\" id=\"Further_reading\">Further reading</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_consciousness&amp;action=edit&amp;section=30\" title=\"Edit section: Further reading\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<ul><li><cite class=\"citation journal\">Baars, Bernard; Franklin, Stan (2003). <a class=\"external text\" href=\"http://cogprints.org/5854/1/TICSarticle2003.pdf\" rel=\"nofollow\">\"How conscious experience and working memory interact\"</a> <span class=\"cs1-format\">(PDF)</span>. <i>Trends in Cognitive Sciences</i>. <b>7</b> (4): 166–172. <a href=\"/wiki/Digital_object_identifier\" title=\"Digital object identifier\">doi</a>:<a class=\"external text\" href=\"//doi.org/10.1016%2Fs1364-6613%2803%2900056-1\" rel=\"nofollow\">10.1016/s1364-6613(03)00056-1</a>. <a class=\"mw-redirect\" href=\"/wiki/PubMed_Identifier\" title=\"PubMed Identifier\">PMID</a> <a class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pubmed/12691765\" rel=\"nofollow\">12691765</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Trends+in+Cognitive+Sciences&amp;rft.atitle=How+conscious+experience+and+working+memory+interact&amp;rft.volume=7&amp;rft.issue=4&amp;rft.pages=166-172&amp;rft.date=2003&amp;rft_id=info%3Adoi%2F10.1016%2Fs1364-6613%2803%2900056-1&amp;rft_id=info%3Apmid%2F12691765&amp;rft.aulast=Baars&amp;rft.aufirst=Bernard&amp;rft.au=Franklin%2C+Stan&amp;rft_id=http%3A%2F%2Fcogprints.org%2F5854%2F1%2FTICSarticle2003.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+consciousness\"></span><link href=\"mw-data:TemplateStyles:r879151008\" rel=\"mw-deduplicated-inline-style\"/></li>\n<li>Casti, John L. \"The Cambridge Quintet: A Work of Scientific Speculation\", Perseus Books Group, 1998</li>\n<li>Franklin, S, B J Baars, U Ramamurthy, and Matthew Ventura. 2005. <a class=\"external text\" href=\"http://www.brains-minds-media.org/archive/150\" rel=\"nofollow\">The role of consciousness in memory</a>. Brains, Minds and Media 1: 1–38, pdf.</li>\n<li>Haikonen, Pentti (2004), <i>Conscious Machines and Machine Emotions</i>, presented at Workshop on Models for Machine Consciousness, Antwerp, BE, June 2004.</li>\n<li>McCarthy, John (1971–1987), <a class=\"external text\" href=\"http://www-formal.stanford.edu/jmc/generality/generality.html\" rel=\"nofollow\"><i>Generality in Artificial Intelligence</i></a>.  Stanford University, 1971-1987.</li>\n<li>Penrose, Roger, <a href=\"/wiki/The_Emperor%27s_New_Mind\" title=\"The Emperor's New Mind\">The Emperor's New Mind</a>, 1989.</li>\n<li>Sternberg, Eliezer J. (2007) <i>Are You a Machine? Tha Brain the Mind and What it Means to be Human.</i> Amherst, NY: Prometheus Books.</li>\n<li>Suzuki T., Inaba K., Takeno, Junichi (2005),<i> Conscious Robot That <b>Distinguishes Between Self and Others</b> and Implements Imitation Behavior</i>, (<b>Best Paper of IEA/AIE2005</b>), Innovations in Applied Artificial Intelligence, 18th International Conference on Industrial and Engineering Applications of Artificial Intelligence and Expert Systems, pp. 101–110, IEA/AIE 2005, Bari, Italy, June 22–24, 2005.</li>\n<li>Takeno, Junichi (2006), <a class=\"external text\" href=\"http://www.d6.dion.ne.jp/~takenof/SAR-LAL-Takeno.pdf\" rel=\"nofollow\"><i>The <b>Self-Aware Robot</b> -A Response to Reactions to Discovery News-</i></a>, HRI Press, August 2006.</li>\n<li>Zagal, J.C., Lipson, H. (2009) \"<a class=\"external text\" href=\"http://ccsl.mae.cornell.edu/sites/default/files/GECCO09_Zagal.pdf\" rel=\"nofollow\">Self-Reflection in Evolutionary Robotics</a>\",  Proceedings of the Genetic and Evolutionary Computation Conference, pp 2179–2188, GECCO 2009.</li></ul>\n<h2><span class=\"mw-headline\" id=\"External_links\">External links</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Artificial_consciousness&amp;action=edit&amp;section=31\" title=\"Edit section: External links\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<ul><li><a class=\"external text\" href=\"http://www.slideserve.com/astro/artefactual-consciousness-depiction-and-an-example-in-robot-usable-models-of-visual-consciousness-igor-aleksander-intelligent-and-interactive-systems-group\" rel=\"nofollow\">Artefactual consciousness depiction by Professor Igor Aleksander</a></li>\n<li><a class=\"external text\" href=\"https://web.archive.org/web/20110719195048/http://www.aco.gatech.edu/conference/focs-aco/abstracts.html\" rel=\"nofollow\">FOCS 2009: Manuel Blum - Can (Theoretical Computer) Science come to grips with Consciousness?</a></li>\n<li><a class=\"external text\" href=\"http://www.Conscious-Robots.com\" rel=\"nofollow\">www.Conscious-Robots.com</a>, Machine Consciousness and Conscious Robots Portal.</li></ul>\n<div aria-labelledby=\"Consciousness\" class=\"navbox\" role=\"navigation\" style=\"padding:3px\"><table class=\"nowraplinks collapsible autocollapse navbox-inner\" style=\"border-spacing:0;background:transparent;color:inherit\"><tbody><tr><th class=\"navbox-title\" colspan=\"2\" scope=\"col\"><div class=\"plainlinks hlist navbar mini\"><ul><li class=\"nv-view\"><a href=\"/wiki/Template:Consciousness\" title=\"Template:Consciousness\"><abbr style=\";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;\" title=\"View this template\">v</abbr></a></li><li class=\"nv-talk\"><a href=\"/wiki/Template_talk:Consciousness\" title=\"Template talk:Consciousness\"><abbr style=\";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;\" title=\"Discuss this template\">t</abbr></a></li><li class=\"nv-edit\"><a class=\"external text\" href=\"//en.wikipedia.org/w/index.php?title=Template:Consciousness&amp;action=edit\"><abbr style=\";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;\" title=\"Edit this template\">e</abbr></a></li></ul></div><div id=\"Consciousness\" style=\"font-size:114%;margin:0 4em\"><a href=\"/wiki/Consciousness\" title=\"Consciousness\">Consciousness</a></div></th></tr><tr><th class=\"navbox-group\" scope=\"row\" style=\"width:1%\">Figures</th><td class=\"navbox-list navbox-odd hlist\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Antonio_Damasio\" title=\"Antonio Damasio\">Antonio Damasio</a></li>\n<li><a href=\"/wiki/Benjamin_Libet\" title=\"Benjamin Libet\">Benjamin Libet</a></li>\n<li><a href=\"/wiki/Bernard_Baars\" title=\"Bernard Baars\">Bernard Baars</a></li>\n<li><a href=\"/wiki/Christof_Koch\" title=\"Christof Koch\">Christof Koch</a></li>\n<li><a href=\"/wiki/Colin_McGinn\" title=\"Colin McGinn\">Colin McGinn</a></li>\n<li><a href=\"/wiki/Daniel_Dennett\" title=\"Daniel Dennett\">Daniel Dennett</a></li>\n<li><a href=\"/wiki/David_Bohm\" title=\"David Bohm\">David Bohm</a></li>\n<li><a href=\"/wiki/David_Chalmers\" title=\"David Chalmers\">David Chalmers</a></li>\n<li><a href=\"/wiki/David_Pearce_(philosopher)\" title=\"David Pearce (philosopher)\">David Pearce</a></li>\n<li><a href=\"/wiki/Douglas_Hofstadter\" title=\"Douglas Hofstadter\">Douglas Hofstadter</a></li>\n<li><a href=\"/wiki/Eugene_Wigner\" title=\"Eugene Wigner\">Eugene Wigner</a></li>\n<li><a href=\"/wiki/Francis_Crick\" title=\"Francis Crick\">Francis Crick</a></li>\n<li><a href=\"/wiki/Frank_Cameron_Jackson\" title=\"Frank Cameron Jackson\">Frank Jackson</a></li>\n<li><a href=\"/wiki/George_Berkeley\" title=\"George Berkeley\">George Berkeley</a></li>\n<li><a href=\"/wiki/Georges_Rey\" title=\"Georges Rey\">Georges Rey</a></li>\n<li><a href=\"/wiki/Gerald_Edelman\" title=\"Gerald Edelman\">Gerald Edelman</a></li>\n<li><a href=\"/wiki/Giulio_Tononi\" title=\"Giulio Tononi\">Giulio Tononi</a></li>\n<li><a href=\"/wiki/John_Eccles_(neurophysiologist)\" title=\"John Eccles (neurophysiologist)\">John Eccles</a></li>\n<li><a href=\"/wiki/John_Locke\" title=\"John Locke\">John Locke</a></li>\n<li><a href=\"/wiki/John_Searle\" title=\"John Searle\">John Searle</a></li>\n<li><a href=\"/wiki/Joseph_Levine_(philosopher)\" title=\"Joseph Levine (philosopher)\">Joseph Levine</a></li>\n<li><a href=\"/wiki/Karl_Popper\" title=\"Karl Popper\">Karl Popper</a></li>\n<li><a href=\"/wiki/Karl_H._Pribram\" title=\"Karl H. Pribram\">Karl Pribram</a></li>\n<li><a href=\"/wiki/Max_Velmans\" title=\"Max Velmans\">Max Velmans</a></li>\n<li><a href=\"/wiki/Michael_Gazzaniga\" title=\"Michael Gazzaniga\">Michael Gazzaniga</a></li>\n<li><a href=\"/wiki/Michael_Graziano\" title=\"Michael Graziano\">Michael Graziano</a></li>\n<li><a href=\"/wiki/Ned_Block\" title=\"Ned Block\">Ned Block</a></li>\n<li><a href=\"/wiki/Patricia_Churchland\" title=\"Patricia Churchland\">Patricia Churchland</a></li>\n<li><a href=\"/wiki/Patrick_Wilken\" title=\"Patrick Wilken\">Patrick Wilken</a></li>\n<li><a href=\"/wiki/Paul_Churchland\" title=\"Paul Churchland\">Paul Churchland</a></li>\n<li><a href=\"/wiki/Ren%C3%A9_Descartes\" title=\"René Descartes\">René Descartes</a></li>\n<li><a href=\"/wiki/Roger_Penrose\" title=\"Roger Penrose\">Roger Penrose</a></li>\n<li><a href=\"/wiki/Stanislas_Dehaene\" title=\"Stanislas Dehaene\">Stanislas Dehaene</a></li>\n<li><a href=\"/wiki/Steven_Novella\" title=\"Steven Novella\">Steven Novella</a></li>\n<li><a href=\"/wiki/Stuart_Hameroff\" title=\"Stuart Hameroff\">Stuart Hameroff</a></li>\n<li><a href=\"/wiki/Susan_Blackmore\" title=\"Susan Blackmore\">Susan Blackmore</a></li>\n<li><a href=\"/wiki/Thomas_Nagel\" title=\"Thomas Nagel\">Thomas Nagel</a></li>\n<li><a href=\"/wiki/Victor_J._Stenger\" title=\"Victor J. Stenger\">Victor J. Stenger</a></li>\n<li><a href=\"/wiki/William_James\" title=\"William James\">William James</a></li>\n<li><a href=\"/wiki/William_Lycan\" title=\"William Lycan\">William Lycan</a></li></ul>\n</div></td></tr><tr><th class=\"navbox-group\" scope=\"row\" style=\"width:1%\">Theories</th><td class=\"navbox-list navbox-even hlist\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Attention_schema_theory\" title=\"Attention schema theory\">Attention schema theory</a></li>\n<li><a href=\"/wiki/Global_workspace_theory\" title=\"Global workspace theory\">Global workspace theory</a></li>\n<li><a href=\"/wiki/Holonomic_brain_theory\" title=\"Holonomic brain theory\">Holonomic brain theory</a></li>\n<li><a href=\"/wiki/Integrated_information_theory\" title=\"Integrated information theory\">Integrated information theory</a></li>\n<li><a href=\"/wiki/Multiple_drafts_model\" title=\"Multiple drafts model\">Multiple drafts model</a></li></ul>\n</div></td></tr><tr><th class=\"navbox-group\" scope=\"row\" style=\"width:1%\">Topics</th><td class=\"navbox-list navbox-odd hlist\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Altered_state_of_consciousness\" title=\"Altered state of consciousness\">Altered state of consciousness</a></li>\n<li><a href=\"/wiki/Animal_consciousness\" title=\"Animal consciousness\">Animal consciousness</a></li>\n<li><a class=\"mw-selflink selflink\">Artificial consciousness</a></li>\n<li><a href=\"/wiki/Attention\" title=\"Attention\">Attention</a></li>\n<li><a href=\"/wiki/Awareness\" title=\"Awareness\">Awareness</a></li>\n<li><a href=\"/wiki/Binding_problem\" title=\"Binding problem\">Binding problem</a></li>\n<li><a href=\"/wiki/Brain\" title=\"Brain\">Brain</a></li>\n<li><a href=\"/wiki/Cartesian_theater\" title=\"Cartesian theater\">Cartesian theater</a></li>\n<li><a href=\"/wiki/Collective_consciousness\" title=\"Collective consciousness\">Collective consciousness</a></li>\n<li><a href=\"/wiki/Consciousness_after_death\" title=\"Consciousness after death\">Consciousness after death</a></li>\n<li><a href=\"/wiki/Disorders_of_consciousness\" title=\"Disorders of consciousness\">Disorders of consciousness</a></li>\n<li><a href=\"/wiki/Double-aspect_theory\" title=\"Double-aspect theory\">Double-aspect theory</a></li>\n<li><a href=\"/wiki/Dual_consciousness\" title=\"Dual consciousness\">Dual consciousness</a></li>\n<li><a href=\"/wiki/Electromagnetic_theories_of_consciousness\" title=\"Electromagnetic theories of consciousness\">Electromagnetic theories of consciousness</a></li>\n<li><a href=\"/wiki/Eliminative_materialism\" title=\"Eliminative materialism\">Eliminative materialism</a></li>\n<li><a href=\"/wiki/Epiphenomenalism\" title=\"Epiphenomenalism\">Epiphenomenalism</a></li>\n<li><a href=\"/wiki/Experience\" title=\"Experience\">Experience</a></li>\n<li><a href=\"/wiki/Explanatory_gap\" title=\"Explanatory gap\">Explanatory gap</a></li>\n<li><a href=\"/wiki/Free_will\" title=\"Free will\">Free will</a></li>\n<li><a href=\"/wiki/Functionalism_(philosophy_of_mind)\" title=\"Functionalism (philosophy of mind)\">Functionalism (philosophy of mind)</a></li>\n<li><a href=\"/wiki/Hard_problem_of_consciousness\" title=\"Hard problem of consciousness\">Hard problem of consciousness</a></li>\n<li><a href=\"/wiki/Heterophenomenology\" title=\"Heterophenomenology\">Heterophenomenology</a></li>\n<li><a href=\"/wiki/Higher_consciousness\" title=\"Higher consciousness\">Higher consciousness</a></li>\n<li><a href=\"/wiki/Idealism\" title=\"Idealism\">Idealism</a></li>\n<li><a href=\"/wiki/Interactionism_(philosophy_of_mind)\" title=\"Interactionism (philosophy of mind)\">Interactionism</a></li>\n<li><a href=\"/wiki/Introspection_illusion\" title=\"Introspection illusion\">Introspection illusion</a></li>\n<li><a href=\"/wiki/Knowledge_argument\" title=\"Knowledge argument\">Knowledge argument</a></li>\n<li><a href=\"/wiki/Level_of_consciousness_(Esotericism)\" title=\"Level of consciousness (Esotericism)\">Level of consciousness</a></li>\n<li><a href=\"/wiki/Materialism\" title=\"Materialism\">Materialism</a></li>\n<li><a href=\"/wiki/Metaphysics\" title=\"Metaphysics\">Metaphysics</a></li>\n<li><a href=\"/wiki/Mind\" title=\"Mind\">Mind</a></li>\n<li><a href=\"/wiki/Mind%E2%80%93body_dualism\" title=\"Mind–body dualism\">Mind–body dualism</a></li>\n<li><a href=\"/wiki/Mind%E2%80%93body_problem\" title=\"Mind–body problem\">Mind–body problem</a></li>\n<li><a href=\"/wiki/Monism\" title=\"Monism\">Monism</a></li>\n<li><a href=\"/wiki/Neural_correlates_of_consciousness\" title=\"Neural correlates of consciousness\">Neural correlates of consciousness</a></li>\n<li><a href=\"/wiki/Neurophenomenology\" title=\"Neurophenomenology\">Neurophenomenology</a></li>\n<li><a href=\"/wiki/Neutral_monism\" title=\"Neutral monism\">Neutral monism</a></li>\n<li><a href=\"/wiki/New_mysterianism\" title=\"New mysterianism\">New mysterianism</a></li>\n<li><a href=\"/wiki/Ontology\" title=\"Ontology\">Ontology</a></li>\n<li><a href=\"/wiki/Panpsychism\" title=\"Panpsychism\">Panpsychism</a></li>\n<li><a class=\"mw-redirect\" href=\"/wiki/Parallelism_(philosophy)\" title=\"Parallelism (philosophy)\">Parallelism</a></li>\n<li><a href=\"/wiki/Phenomenology_(philosophy)\" title=\"Phenomenology (philosophy)\">Phenomenology</a></li>\n<li><a href=\"/wiki/Philosophical_zombie\" title=\"Philosophical zombie\">Philosophical zombie</a></li>\n<li><a href=\"/wiki/Philosophy_of_mind\" title=\"Philosophy of mind\">Philosophy of mind</a></li>\n<li><a href=\"/wiki/Physicalism\" title=\"Physicalism\">Physicalism</a></li>\n<li><a href=\"/wiki/Primary_consciousness\" title=\"Primary consciousness\">Primary consciousness</a></li>\n<li><a href=\"/wiki/Problem_of_other_minds\" title=\"Problem of other minds\">Problem of other minds</a></li>\n<li><a href=\"/wiki/Property_dualism\" title=\"Property dualism\">Property dualism</a></li>\n<li><a href=\"/wiki/Reentry_(neural_circuitry)\" title=\"Reentry (neural circuitry)\">Reentry</a></li>\n<li><a href=\"/wiki/Reflexive_monism\" title=\"Reflexive monism\">Reflexive monism</a></li>\n<li><a href=\"/wiki/Revisionary_materialism\" title=\"Revisionary materialism\">Revisionary materialism</a></li>\n<li><a href=\"/wiki/Qualia\" title=\"Qualia\">Qualia</a></li>\n<li><a href=\"/wiki/Quantum_mind\" title=\"Quantum mind\">Quantum mind</a></li>\n<li><a href=\"/wiki/Secondary_consciousness\" title=\"Secondary consciousness\">Secondary consciousness</a></li>\n<li><a href=\"/wiki/Sentience\" title=\"Sentience\">Sentience</a></li>\n<li><a href=\"/wiki/Sociology_of_human_consciousness\" title=\"Sociology of human consciousness\">Sociology of human consciousness</a></li>\n<li><a href=\"/wiki/Solipsism\" title=\"Solipsism\">Solipsism</a></li>\n<li><a href=\"/wiki/Stream_of_consciousness_(psychology)\" title=\"Stream of consciousness (psychology)\">Stream of consciousness</a></li>\n<li><a href=\"/wiki/Subjective_character_of_experience\" title=\"Subjective character of experience\">Subjective character of experience</a></li>\n<li><a href=\"/wiki/Subjective_consciousness\" title=\"Subjective consciousness\">Subjective consciousness</a></li>\n<li><a href=\"/wiki/Subjectivity\" title=\"Subjectivity\">Subjectivity</a></li>\n<li><a href=\"/wiki/Type_physicalism\" title=\"Type physicalism\">Type physicalism (reductive materialism, identity theory of mind)</a></li>\n<li><a href=\"/wiki/Unconscious_mind\" title=\"Unconscious mind\">Unconscious mind</a></li>\n<li><a href=\"/wiki/Unconsciousness\" title=\"Unconsciousness\">Unconsciousness</a></li></ul>\n</div></td></tr><tr><th class=\"navbox-group\" scope=\"row\" style=\"width:1%\">Works</th><td class=\"navbox-list navbox-even hlist\" style=\"text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px\"><div style=\"padding:0em 0.25em\">\n<ul><li><a href=\"/wiki/Association_for_the_Scientific_Study_of_Consciousness\" title=\"Association for the Scientific Study of Consciousness\">Association for the Scientific Study of Consciousness</a></li>\n<li><a href=\"/wiki/Consciousness_and_Cognition\" title=\"Consciousness and Cognition\">Consciousness and Cognition</a></li>\n<li><a href=\"/wiki/Consciousness_Explained\" title=\"Consciousness Explained\">Consciousness Explained</a></li>\n<li><a href=\"/wiki/How_the_Self_Controls_Its_Brain\" title=\"How the Self Controls Its Brain\">How the Self Controls Its Brain</a></li>\n<li><a href=\"/wiki/Journal_of_Consciousness_Studies\" title=\"Journal of Consciousness Studies\">Journal of Consciousness Studies</a></li>\n<li><a href=\"/wiki/Online_Consciousness_Conference\" title=\"Online Consciousness Conference\">Online Consciousness Conference</a></li>\n<li><a href=\"/wiki/Psyche_(consciousness_journal)\" title=\"Psyche (consciousness journal)\">Psyche</a></li>\n<li><a href=\"/wiki/The_Astonishing_Hypothesis\" title=\"The Astonishing Hypothesis\">The Astonishing Hypothesis</a></li>\n<li><a href=\"/wiki/The_Conscious_Mind\" title=\"The Conscious Mind\">The Conscious Mind</a></li>\n<li><a href=\"/wiki/The_Emperor%27s_New_Mind\" title=\"The Emperor's New Mind\">The Emperor's New Mind</a></li>\n<li><a href=\"/wiki/Toward_a_Science_of_Consciousness\" title=\"Toward a Science of Consciousness\">Toward a Science of Consciousness</a></li>\n<li><a href=\"/wiki/Understanding_Consciousness\" title=\"Understanding Consciousness\">Understanding Consciousness</a></li>\n<li><a href=\"/wiki/What_Is_it_Like_to_Be_a_Bat%3F\" title=\"What Is it Like to Be a Bat?\">What Is it Like to Be a Bat?</a></li></ul>\n</div></td></tr></tbody></table></div>\n<!-- \nNewPP limit report\nParsed by mw1268\nCached time: 20190225010009\nCache expiry: 2073600\nDynamic content: false\nCPU time usage: 0.748 seconds\nReal time usage: 0.881 seconds\nPreprocessor visited node count: 3877/1000000\nPreprocessor generated node count: 0/1500000\nPost‐expand include size: 124785/2097152 bytes\nTemplate argument size: 1615/2097152 bytes\nHighest expansion depth: 13/40\nExpensive parser function count: 4/500\nUnstrip recursion depth: 1/20\nUnstrip post‐expand size: 119916/5000000 bytes\nNumber of Wikibase entities loaded: 4/400\nLua time usage: 0.380/10.000 seconds\nLua memory usage: 4.94 MB/50 MB\n-->\n<!--\nTransclusion expansion time report (%,ms,calls,template)\n100.00%  685.542      1 -total\n 36.85%  252.621      1 Template:Reflist\n 30.40%  208.413     31 Template:Citation\n 22.60%  154.963     11 Template:Cite_journal\n  6.92%   47.406      3 Template:ISBN\n  5.39%   36.959     15 Template:Harvnb\n  4.39%   30.113      1 Template:Other_uses\n  2.76%   18.913      1 Template:Harvs\n  2.60%   17.833      3 Template:Catalog_lookup_link\n  2.57%   17.638      1 Template:Refbegin\n-->\n<!-- Saved in parser cache with key enwiki:pcache:idhash:195552-0!canonical and timestamp 20190225010008 and revision id 883911144\n -->\n</div><noscript><img alt=\"\" height=\"1\" src=\"//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1\" style=\"border: none; position: absolute;\" title=\"\" width=\"1\"/></noscript></div> <div class=\"printfooter\">\n\t\t\t\t\t\tRetrieved from \"<a dir=\"ltr\" href=\"https://en.wikipedia.org/w/index.php?title=Artificial_consciousness&amp;oldid=883911144\">https://en.wikipedia.org/w/index.php?title=Artificial_consciousness&amp;oldid=883911144</a>\"\t\t\t\t\t</div>\n<div class=\"catlinks\" data-mw=\"interface\" id=\"catlinks\"><div class=\"mw-normal-catlinks\" id=\"mw-normal-catlinks\"><a href=\"/wiki/Help:Category\" title=\"Help:Category\">Categories</a>: <ul><li><a href=\"/wiki/Category:Artificial_intelligence\" title=\"Category:Artificial intelligence\">Artificial intelligence</a></li><li><a href=\"/wiki/Category:Consciousness\" title=\"Category:Consciousness\">Consciousness</a></li><li><a href=\"/wiki/Category:Consciousness_studies\" title=\"Category:Consciousness studies\">Consciousness studies</a></li><li><a href=\"/wiki/Category:Computational_neuroscience\" title=\"Category:Computational neuroscience\">Computational neuroscience</a></li></ul></div><div class=\"mw-hidden-catlinks mw-hidden-cats-hidden\" id=\"mw-hidden-catlinks\">Hidden categories: <ul><li><a href=\"/wiki/Category:CS1_maint:_Uses_authors_parameter\" title=\"Category:CS1 maint: Uses authors parameter\">CS1 maint: Uses authors parameter</a></li><li><a href=\"/wiki/Category:CS1_maint:_BOT:_original-url_status_unknown\" title=\"Category:CS1 maint: BOT: original-url status unknown\">CS1 maint: BOT: original-url status unknown</a></li></ul></div></div> <div class=\"visualClear\"></div>\n</div>\n</div>\n<div id=\"mw-navigation\">\n<h2>Navigation menu</h2>\n<div id=\"mw-head\">\n<div aria-labelledby=\"p-personal-label\" id=\"p-personal\" role=\"navigation\">\n<h3 id=\"p-personal-label\">Personal tools</h3>\n<ul>\n<li id=\"pt-anonuserpage\">Not logged in</li><li id=\"pt-anontalk\"><a accesskey=\"n\" href=\"/wiki/Special:MyTalk\" title=\"Discussion about edits from this IP address [n]\">Talk</a></li><li id=\"pt-anoncontribs\"><a accesskey=\"y\" href=\"/wiki/Special:MyContributions\" title=\"A list of edits made from this IP address [y]\">Contributions</a></li><li id=\"pt-createaccount\"><a href=\"/w/index.php?title=Special:CreateAccount&amp;returnto=Artificial+consciousness\" title=\"You are encouraged to create an account and log in; however, it is not mandatory\">Create account</a></li><li id=\"pt-login\"><a accesskey=\"o\" href=\"/w/index.php?title=Special:UserLogin&amp;returnto=Artificial+consciousness\" title=\"You're encouraged to log in; however, it's not mandatory. [o]\">Log in</a></li> </ul>\n</div>\n<div id=\"left-navigation\">\n<div aria-labelledby=\"p-namespaces-label\" class=\"vectorTabs\" id=\"p-namespaces\" role=\"navigation\">\n<h3 id=\"p-namespaces-label\">Namespaces</h3>\n<ul>\n<li class=\"selected\" id=\"ca-nstab-main\"><span><a accesskey=\"c\" href=\"/wiki/Artificial_consciousness\" title=\"View the content page [c]\">Article</a></span></li><li id=\"ca-talk\"><span><a accesskey=\"t\" href=\"/wiki/Talk:Artificial_consciousness\" rel=\"discussion\" title=\"Discussion about the content page [t]\">Talk</a></span></li> </ul>\n</div>\n<div aria-labelledby=\"p-variants-label\" class=\"vectorMenu emptyPortlet\" id=\"p-variants\" role=\"navigation\">\n<input aria-labelledby=\"p-variants-label\" class=\"vectorMenuCheckbox\" type=\"checkbox\"/>\n<h3 id=\"p-variants-label\">\n<span>Variants</span>\n</h3>\n<ul class=\"menu\">\n</ul>\n</div>\n</div>\n<div id=\"right-navigation\">\n<div aria-labelledby=\"p-views-label\" class=\"vectorTabs\" id=\"p-views\" role=\"navigation\">\n<h3 id=\"p-views-label\">Views</h3>\n<ul>\n<li class=\"collapsible selected\" id=\"ca-view\"><span><a href=\"/wiki/Artificial_consciousness\">Read</a></span></li><li class=\"collapsible\" id=\"ca-edit\"><span><a accesskey=\"e\" href=\"/w/index.php?title=Artificial_consciousness&amp;action=edit\" title=\"Edit this page [e]\">Edit</a></span></li><li class=\"collapsible\" id=\"ca-history\"><span><a accesskey=\"h\" href=\"/w/index.php?title=Artificial_consciousness&amp;action=history\" title=\"Past revisions of this page [h]\">View history</a></span></li> </ul>\n</div>\n<div aria-labelledby=\"p-cactions-label\" class=\"vectorMenu emptyPortlet\" id=\"p-cactions\" role=\"navigation\">\n<input aria-labelledby=\"p-cactions-label\" class=\"vectorMenuCheckbox\" type=\"checkbox\"/>\n<h3 id=\"p-cactions-label\"><span>More</span></h3>\n<ul class=\"menu\">\n</ul>\n</div>\n<div id=\"p-search\" role=\"search\">\n<h3>\n<label for=\"searchInput\">Search</label>\n</h3>\n<form action=\"/w/index.php\" id=\"searchform\">\n<div id=\"simpleSearch\">\n<input accesskey=\"f\" id=\"searchInput\" name=\"search\" placeholder=\"Search Wikipedia\" title=\"Search Wikipedia [f]\" type=\"search\"/><input name=\"title\" type=\"hidden\" value=\"Special:Search\"/><input class=\"searchButton mw-fallbackSearchButton\" id=\"mw-searchButton\" name=\"fulltext\" title=\"Search Wikipedia for this text\" type=\"submit\" value=\"Search\"/><input class=\"searchButton\" id=\"searchButton\" name=\"go\" title=\"Go to a page with this exact name if it exists\" type=\"submit\" value=\"Go\"/> </div>\n</form>\n</div>\n</div>\n</div>\n<div id=\"mw-panel\">\n<div id=\"p-logo\" role=\"banner\"><a class=\"mw-wiki-logo\" href=\"/wiki/Main_Page\" title=\"Visit the main page\"></a></div>\n<div aria-labelledby=\"p-navigation-label\" class=\"portal\" id=\"p-navigation\" role=\"navigation\">\n<h3 id=\"p-navigation-label\">Navigation</h3>\n<div class=\"body\">\n<ul>\n<li id=\"n-mainpage-description\"><a accesskey=\"z\" href=\"/wiki/Main_Page\" title=\"Visit the main page [z]\">Main page</a></li><li id=\"n-contents\"><a href=\"/wiki/Portal:Contents\" title=\"Guides to browsing Wikipedia\">Contents</a></li><li id=\"n-featuredcontent\"><a href=\"/wiki/Portal:Featured_content\" title=\"Featured content – the best of Wikipedia\">Featured content</a></li><li id=\"n-currentevents\"><a href=\"/wiki/Portal:Current_events\" title=\"Find background information on current events\">Current events</a></li><li id=\"n-randompage\"><a accesskey=\"x\" href=\"/wiki/Special:Random\" title=\"Load a random article [x]\">Random article</a></li><li id=\"n-sitesupport\"><a href=\"https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_en.wikipedia.org&amp;uselang=en\" title=\"Support us\">Donate to Wikipedia</a></li><li id=\"n-shoplink\"><a href=\"//shop.wikimedia.org\" title=\"Visit the Wikipedia store\">Wikipedia store</a></li> </ul>\n</div>\n</div>\n<div aria-labelledby=\"p-interaction-label\" class=\"portal\" id=\"p-interaction\" role=\"navigation\">\n<h3 id=\"p-interaction-label\">Interaction</h3>\n<div class=\"body\">\n<ul>\n<li id=\"n-help\"><a href=\"/wiki/Help:Contents\" title=\"Guidance on how to use and edit Wikipedia\">Help</a></li><li id=\"n-aboutsite\"><a href=\"/wiki/Wikipedia:About\" title=\"Find out about Wikipedia\">About Wikipedia</a></li><li id=\"n-portal\"><a href=\"/wiki/Wikipedia:Community_portal\" title=\"About the project, what you can do, where to find things\">Community portal</a></li><li id=\"n-recentchanges\"><a accesskey=\"r\" href=\"/wiki/Special:RecentChanges\" title=\"A list of recent changes in the wiki [r]\">Recent changes</a></li><li id=\"n-contactpage\"><a href=\"//en.wikipedia.org/wiki/Wikipedia:Contact_us\" title=\"How to contact Wikipedia\">Contact page</a></li> </ul>\n</div>\n</div>\n<div aria-labelledby=\"p-tb-label\" class=\"portal\" id=\"p-tb\" role=\"navigation\">\n<h3 id=\"p-tb-label\">Tools</h3>\n<div class=\"body\">\n<ul>\n<li id=\"t-whatlinkshere\"><a accesskey=\"j\" href=\"/wiki/Special:WhatLinksHere/Artificial_consciousness\" title=\"List of all English Wikipedia pages containing links to this page [j]\">What links here</a></li><li id=\"t-recentchangeslinked\"><a accesskey=\"k\" href=\"/wiki/Special:RecentChangesLinked/Artificial_consciousness\" rel=\"nofollow\" title=\"Recent changes in pages linked from this page [k]\">Related changes</a></li><li id=\"t-upload\"><a accesskey=\"u\" href=\"/wiki/Wikipedia:File_Upload_Wizard\" title=\"Upload files [u]\">Upload file</a></li><li id=\"t-specialpages\"><a accesskey=\"q\" href=\"/wiki/Special:SpecialPages\" title=\"A list of all special pages [q]\">Special pages</a></li><li id=\"t-permalink\"><a href=\"/w/index.php?title=Artificial_consciousness&amp;oldid=883911144\" title=\"Permanent link to this revision of the page\">Permanent link</a></li><li id=\"t-info\"><a href=\"/w/index.php?title=Artificial_consciousness&amp;action=info\" title=\"More information about this page\">Page information</a></li><li id=\"t-wikibase\"><a accesskey=\"g\" href=\"https://www.wikidata.org/wiki/Special:EntityPage/Q2993663\" title=\"Link to connected data repository item [g]\">Wikidata item</a></li><li id=\"t-cite\"><a href=\"/w/index.php?title=Special:CiteThisPage&amp;page=Artificial_consciousness&amp;id=883911144\" title=\"Information on how to cite this page\">Cite this page</a></li> </ul>\n</div>\n</div>\n<div aria-labelledby=\"p-coll-print_export-label\" class=\"portal\" id=\"p-coll-print_export\" role=\"navigation\">\n<h3 id=\"p-coll-print_export-label\">Print/export</h3>\n<div class=\"body\">\n<ul>\n<li id=\"coll-create_a_book\"><a href=\"/w/index.php?title=Special:Book&amp;bookcmd=book_creator&amp;referer=Artificial+consciousness\">Create a book</a></li><li id=\"coll-download-as-rdf2latex\"><a href=\"/w/index.php?title=Special:ElectronPdf&amp;page=Artificial+consciousness&amp;action=show-download-screen\">Download as PDF</a></li><li id=\"t-print\"><a accesskey=\"p\" href=\"/w/index.php?title=Artificial_consciousness&amp;printable=yes\" title=\"Printable version of this page [p]\">Printable version</a></li> </ul>\n</div>\n</div>\n<div aria-labelledby=\"p-lang-label\" class=\"portal\" id=\"p-lang\" role=\"navigation\">\n<h3 id=\"p-lang-label\">Languages</h3>\n<div class=\"body\">\n<ul>\n<li class=\"interlanguage-link interwiki-ar\"><a class=\"interlanguage-link-target\" href=\"https://ar.wikipedia.org/wiki/%D9%88%D8%B9%D9%8A_%D8%A7%D8%B5%D8%B7%D9%86%D8%A7%D8%B9%D9%8A\" hreflang=\"ar\" lang=\"ar\" title=\"وعي اصطناعي – Arabic\">العربية</a></li><li class=\"interlanguage-link interwiki-cs\"><a class=\"interlanguage-link-target\" href=\"https://cs.wikipedia.org/wiki/Um%C4%9Bl%C3%A9_v%C4%9Bdom%C3%AD\" hreflang=\"cs\" lang=\"cs\" title=\"Umělé vědomí – Czech\">Čeština</a></li><li class=\"interlanguage-link interwiki-fa\"><a class=\"interlanguage-link-target\" href=\"https://fa.wikipedia.org/wiki/%D9%87%D8%B4%DB%8C%D8%A7%D8%B1%DB%8C_%D9%85%D8%B5%D9%86%D9%88%D8%B9%DB%8C\" hreflang=\"fa\" lang=\"fa\" title=\"هشیاری مصنوعی – Persian\">فارسی</a></li><li class=\"interlanguage-link interwiki-fr\"><a class=\"interlanguage-link-target\" href=\"https://fr.wikipedia.org/wiki/Conscience_artificielle\" hreflang=\"fr\" lang=\"fr\" title=\"Conscience artificielle – French\">Français</a></li><li class=\"interlanguage-link interwiki-ko\"><a class=\"interlanguage-link-target\" href=\"https://ko.wikipedia.org/wiki/%EC%9D%B8%EA%B3%B5_%EC%9D%98%EC%8B%9D\" hreflang=\"ko\" lang=\"ko\" title=\"인공 의식 – Korean\">한국어</a></li><li class=\"interlanguage-link interwiki-ja\"><a class=\"interlanguage-link-target\" href=\"https://ja.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E6%84%8F%E8%AD%98\" hreflang=\"ja\" lang=\"ja\" title=\"人工意識 – Japanese\">日本語</a></li><li class=\"interlanguage-link interwiki-sq\"><a class=\"interlanguage-link-target\" href=\"https://sq.wikipedia.org/wiki/Vet%C3%ABdija_artificiale\" hreflang=\"sq\" lang=\"sq\" title=\"Vetëdija artificiale – Albanian\">Shqip</a></li><li class=\"interlanguage-link interwiki-fi\"><a class=\"interlanguage-link-target\" href=\"https://fi.wikipedia.org/wiki/Konetietoisuus\" hreflang=\"fi\" lang=\"fi\" title=\"Konetietoisuus – Finnish\">Suomi</a></li><li class=\"interlanguage-link interwiki-uk\"><a class=\"interlanguage-link-target\" href=\"https://uk.wikipedia.org/wiki/%D0%9C%D0%BE%D0%B4%D0%B5%D0%BB%D1%8E%D0%B2%D0%B0%D0%BD%D0%BD%D1%8F_%D1%81%D0%B2%D1%96%D0%B4%D0%BE%D0%BC%D0%BE%D1%81%D1%82%D1%96\" hreflang=\"uk\" lang=\"uk\" title=\"Моделювання свідомості – Ukrainian\">Українська</a></li><li class=\"interlanguage-link interwiki-ur\"><a class=\"interlanguage-link-target\" href=\"https://ur.wikipedia.org/wiki/%D8%B4%D8%B9%D9%88%D8%B1_%D8%A7%D8%B5%D8%B7%D9%86%D8%A7%D8%B9%DB%8C\" hreflang=\"ur\" lang=\"ur\" title=\"شعور اصطناعی – Urdu\">اردو</a></li><li class=\"interlanguage-link interwiki-zh\"><a class=\"interlanguage-link-target\" href=\"https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E6%84%8F%E8%AD%98\" hreflang=\"zh\" lang=\"zh\" title=\"人工意識 – Chinese\">中文</a></li> </ul>\n<div class=\"after-portlet after-portlet-lang\"><span class=\"wb-langlinks-edit wb-langlinks-link\"><a class=\"wbc-editpage\" href=\"https://www.wikidata.org/wiki/Special:EntityPage/Q2993663#sitelinks-wikipedia\" title=\"Edit interlanguage links\">Edit links</a></span></div> </div>\n</div>\n</div>\n</div>\n<div id=\"footer\" role=\"contentinfo\">\n<ul id=\"footer-info\">\n<li id=\"footer-info-lastmod\"> This page was last edited on 18 February 2019, at 11:13<span class=\"anonymous-show\"> (UTC)</span>.</li>\n<li id=\"footer-info-copyright\">Text is available under the <a href=\"//en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License\" rel=\"license\">Creative Commons Attribution-ShareAlike License</a><a href=\"//creativecommons.org/licenses/by-sa/3.0/\" rel=\"license\" style=\"display:none;\"></a>;\nadditional terms may apply.  By using this site, you agree to the <a href=\"//foundation.wikimedia.org/wiki/Terms_of_Use\">Terms of Use</a> and <a href=\"//foundation.wikimedia.org/wiki/Privacy_policy\">Privacy Policy</a>. Wikipedia® is a registered trademark of the <a href=\"//www.wikimediafoundation.org/\">Wikimedia Foundation, Inc.</a>, a non-profit organization.</li>\n</ul>\n<ul id=\"footer-places\">\n<li id=\"footer-places-privacy\"><a class=\"extiw\" href=\"https://foundation.wikimedia.org/wiki/Privacy_policy\" title=\"wmf:Privacy policy\">Privacy policy</a></li>\n<li id=\"footer-places-about\"><a href=\"/wiki/Wikipedia:About\" title=\"Wikipedia:About\">About Wikipedia</a></li>\n<li id=\"footer-places-disclaimer\"><a href=\"/wiki/Wikipedia:General_disclaimer\" title=\"Wikipedia:General disclaimer\">Disclaimers</a></li>\n<li id=\"footer-places-contact\"><a href=\"//en.wikipedia.org/wiki/Wikipedia:Contact_us\">Contact Wikipedia</a></li>\n<li id=\"footer-places-developers\"><a href=\"https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute\">Developers</a></li>\n<li id=\"footer-places-cookiestatement\"><a href=\"https://foundation.wikimedia.org/wiki/Cookie_statement\">Cookie statement</a></li>\n<li id=\"footer-places-mobileview\"><a class=\"noprint stopMobileRedirectToggle\" href=\"//en.m.wikipedia.org/w/index.php?title=Artificial_consciousness&amp;mobileaction=toggle_view_mobile\">Mobile view</a></li>\n</ul>\n<ul class=\"noprint\" id=\"footer-icons\">\n<li id=\"footer-copyrightico\">\n<a href=\"https://wikimediafoundation.org/\"><img alt=\"Wikimedia Foundation\" height=\"31\" src=\"/static/images/wikimedia-button.png\" srcset=\"/static/images/wikimedia-button-1.5x.png 1.5x, /static/images/wikimedia-button-2x.png 2x\" width=\"88\"/></a> </li>\n<li id=\"footer-poweredbyico\">\n<a href=\"//www.mediawiki.org/\"><img alt=\"Powered by MediaWiki\" height=\"31\" src=\"/static/images/poweredby_mediawiki_88x31.png\" srcset=\"/static/images/poweredby_mediawiki_132x47.png 1.5x, /static/images/poweredby_mediawiki_176x62.png 2x\" width=\"88\"/></a> </li>\n</ul>\n<div style=\"clear: both;\"></div>\n</div>\n<script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({\"wgPageParseReport\":{\"limitreport\":{\"cputime\":\"0.748\",\"walltime\":\"0.881\",\"ppvisitednodes\":{\"value\":3877,\"limit\":1000000},\"ppgeneratednodes\":{\"value\":0,\"limit\":1500000},\"postexpandincludesize\":{\"value\":124785,\"limit\":2097152},\"templateargumentsize\":{\"value\":1615,\"limit\":2097152},\"expansiondepth\":{\"value\":13,\"limit\":40},\"expensivefunctioncount\":{\"value\":4,\"limit\":500},\"unstrip-depth\":{\"value\":1,\"limit\":20},\"unstrip-size\":{\"value\":119916,\"limit\":5000000},\"entityaccesscount\":{\"value\":4,\"limit\":400},\"timingprofile\":[\"100.00%  685.542      1 -total\",\" 36.85%  252.621      1 Template:Reflist\",\" 30.40%  208.413     31 Template:Citation\",\" 22.60%  154.963     11 Template:Cite_journal\",\"  6.92%   47.406      3 Template:ISBN\",\"  5.39%   36.959     15 Template:Harvnb\",\"  4.39%   30.113      1 Template:Other_uses\",\"  2.76%   18.913      1 Template:Harvs\",\"  2.60%   17.833      3 Template:Catalog_lookup_link\",\"  2.57%   17.638      1 Template:Refbegin\"]},\"scribunto\":{\"limitreport-timeusage\":{\"value\":\"0.380\",\"limit\":\"10.000\"},\"limitreport-memusage\":{\"value\":5181075,\"limit\":52428800}},\"cachereport\":{\"origin\":\"mw1268\",\"timestamp\":\"20190225010009\",\"ttl\":2073600,\"transientcontent\":false}}});mw.config.set({\"wgBackendResponseTime\":111,\"wgHostname\":\"mw1250\"});});</script>\n</body>\n</html>\n",
  "table_of_contents": [
    "1 Philosophical views",
    "1.1 Plausibility debate",
    "1.1.1 Computational Foundation argument",
    "1.2 Ethics",
    "2 Research and implementation proposals",
    "2.1 Aspects of consciousness",
    "2.1.1 Awareness",
    "2.1.2 Memory",
    "2.1.3 Learning",
    "2.1.4 Anticipation",
    "2.1.5 Subjective experience",
    "2.2 Role of cognitive architectures",
    "2.3 Symbolic or hybrid proposals",
    "2.3.1 Franklin's Intelligent Distribution Agent",
    "2.3.2 Ron Sun's cognitive architecture CLARION",
    "2.3.3 Ben Goertzel's OpenCog",
    "2.4 Connectionist proposals",
    "2.4.1 Haikonen's cognitive architecture",
    "2.4.2 Shanahan's cognitive architecture",
    "2.4.3 Takeno's self-awareness research",
    "2.4.4 Aleksander's impossible mind",
    "2.4.5 Thaler's Creativity Machine Paradigm",
    "2.4.6 Michael Graziano's attention schema",
    "3 Testing",
    "4 In fiction",
    "5 See also",
    "6 References",
    "6.1 Citations",
    "6.2 Bibliography",
    "7 Further reading",
    "8 External links"
  ],
  "graphics": [],
  "paragraphs": [
    {
      "title": "",
      "text": "Artificial consciousness[1] (AC), also known as machine consciousness (MC) or synthetic consciousness (Gamez 2008; Reggia 2013), is a field related to artificial intelligence and cognitive robotics. The aim of the theory of artificial consciousness is to \"Define that which would have to be synthesized were consciousness to be found in an engineered artifact\" (Aleksander 1995).\n\nNeuroscience hypothesizes that consciousness is generated by the interoperation of various parts of the brain, called the neural correlates of consciousness or NCC, though there are challenges to that perspective. Proponents of AC believe it is possible to construct systems (e.g., computer systems) that can emulate this NCC interoperation.[2]\n\nArtificial consciousness concepts are also pondered in the philosophy of artificial intelligence through questions about mind, consciousness, and mental states.[3]\n\n"
    },
    {
      "title": "Philosophical views",
      "text": "As there are many hypothesized types of consciousness, there are many potential implementations of artificial consciousness.  In the philosophical literature, perhaps the most common taxonomy of consciousness is into \"access\" and \"phenomenal\" variants.  Access consciousness concerns those aspects of experience that can be apprehended, while phenomenal consciousness concerns those aspects of experience that seemingly cannot be apprehended, instead being characterized qualitatively in terms of “raw feels”, “what it is like” or qualia (Block 1997).\n\nType-identity theorists and other skeptics hold the view that consciousness can only be realized in particular physical systems because consciousness has properties that necessarily depend on physical constitution (Block 1978; Bickle 2003).[4][5]\n\nIn his article \"Artificial Consciousness: Utopia or Real Possibility\" Giorgio Buttazzo says that despite our current technology's ability to simulate autonomy, \"Working in a fully automated mode, they [the computers] cannot exhibit creativity, emotions, or free will. A computer, like a washing machine, is a slave operated by its components.\"[6]\n\nFor other theorists (e.g., functionalists), who define mental states in terms of causal roles, any system that can instantiate the same pattern of causal roles, regardless of physical constitution, will instantiate the same mental states, including consciousness (Putnam 1967).\n\nOne of the most explicit arguments for the plausibility of AC comes from David Chalmers.  His proposal, found within his article Chalmers 2011, is roughly that the right kinds of computations are sufficient for the possession of a conscious mind. In the outline, he defends his claim thus: Computers perform computations. Computations can capture other systems' abstract causal organization.\n\nThe most controversial part of Chalmers' proposal is that mental properties are \"organizationally invariant\". Mental properties are of two kinds, psychological and phenomenological. Psychological properties, such as belief and perception, are those that are \"characterized by their causal role\". He adverts to the work of Armstrong 1968 and Lewis 1972 in claiming that \"[s]ystems with the same causal topology…will share their psychological properties\".\n\nPhenomenological properties are not prima facie definable in terms of their causal roles. Establishing that phenomenological properties are amenable to individuation by causal role therefore requires argument. Chalmers provides his Dancing Qualia Argument for this purpose.[7]\n\nChalmers begins by assuming that agents with identical causal organizations could have different experiences. He then asks us to conceive of changing one agent into the other by the replacement of parts (neural parts replaced by silicon, say) while preserving its causal organization. Ex hypothesi, the experience of the agent under transformation would change (as the parts were replaced), but there would be no change in causal topology and therefore no means whereby the agent could \"notice\" the shift in experience.\n\nCritics of AC object that Chalmers begs the question in assuming that all mental properties and external connections are sufficiently captured by abstract causal organization.\n\nIf it were suspected that a particular machine was conscious, its rights would be an ethical issue that would need to be assessed (e.g. what rights it would have under law). For example, a conscious computer that was owned and used as a tool or central computer of a building of larger machine is a particular ambiguity. Should laws be made for such a case? Consciousness would also require a legal definition in this particular case. Because artificial consciousness is still largely a theoretical subject, such ethics have not been discussed or developed to a great extent, though it has often been a theme in fiction (see below).\n\nThe rules for the 2003 Loebner Prize competition explicitly addressed the question of robot rights:\n\n"
    },
    {
      "title": "Research and implementation proposals",
      "text": "There are various aspects of consciousness generally deemed necessary for a machine to be artificially conscious. A variety of functions in which consciousness plays a role were suggested by Bernard Baars (Baars 1988) and others. The functions of consciousness suggested by Bernard Baars are Definition and Context Setting, Adaptation and Learning, Editing, Flagging and Debugging, Recruiting and Control, Prioritizing and Access-Control, Decision-making or Executive Function, Analogy-forming Function, Metacognitive and Self-monitoring Function, and Autoprogramming and Self-maintenance Function. Igor Aleksander suggested 12 principles for artificial consciousness (Aleksander 1995) and these are: The Brain is a State Machine, Inner Neuron Partitioning, Conscious and Unconscious States, Perceptual Learning and Memory, Prediction, The Awareness of Self, Representation of Meaning, Learning Utterances, Learning Language, Will, Instinct, and Emotion. The aim of AC is to define whether and how these and other aspects of consciousness can be synthesized in an engineered artifact such as a digital computer. This list is not exhaustive; there are many others not covered.\n\nAwareness could be one required aspect, but there are many problems with the exact definition of awareness. The results of the experiments of neuroscanning on monkeys suggest that a process, not only a state or object, activates neurons. Awareness includes creating and testing alternative models of each process based on the information received through the senses or imagined, and is also useful for making predictions. Such modeling needs a lot of flexibility. Creating such a model includes modeling of the physical world, modeling of one's own internal states and processes, and modeling of other conscious entities.\n\nThere are at least three types of awareness:[9] agency awareness, goal awareness, and sensorimotor awareness, which may also be conscious or not.  For example, in agency awareness you may be aware that you performed a certain action yesterday, but are not now conscious of it.  In goal awareness you may be aware that you must search for a lost object, but are not now conscious of it.  In sensorimotor awareness, you may be aware that your hand is resting on an object, but are not now conscious of it.\n\nBecause objects of awareness are often conscious, the distinction between awareness and consciousness is frequently blurred or they are used as synonyms.[10]\n\nConscious events interact with memory systems in learning, rehearsal, and retrieval.[11]\nThe IDA model[12] elucidates the role of consciousness in the updating of perceptual memory,[13] transient episodic memory, and procedural memory. Transient episodic and declarative memories have distributed representations in IDA, there is evidence that this is also the case in the nervous system.[14] In IDA, these two memories are implemented computationally using a modified version of Kanerva’s Sparse distributed memory architecture.[15]\n\nLearning is also considered necessary for AC. By Bernard Baars, conscious experience is needed to represent and adapt to novel and significant events (Baars 1988). By Axel Cleeremans and Luis Jiménez, learning is defined as \"a set of philogenetically  [sic] advanced adaptation processes that critically depend on an evolved sensitivity to subjective experience so as to enable agents to afford flexible control over their actions in complex, unpredictable environments\" (Cleeremans 2001).\n\nThe ability to predict (or anticipate) foreseeable events is considered important for AC by Igor Aleksander.[16] The emergentist multiple drafts principle proposed by Daniel Dennett in Consciousness Explained may be useful for prediction: it involves the evaluation and selection of the most appropriate \"draft\" to fit the current environment.  Anticipation includes prediction of consequences of one's own proposed actions and prediction of consequences of probable actions by other entities.\n\nRelationships between real world states are mirrored in the state structure of a conscious organism enabling the organism to predict events.[16] An artificially conscious machine should be able to anticipate events correctly in order to be ready to respond to them when they occur or to take preemptive action to avert anticipated events. The implication here is that the machine needs flexible, real-time components that build spatial, dynamic, statistical, functional, and cause-effect models of the real world and predicted worlds, making it possible to demonstrate that it possesses artificial consciousness in the present and future and not only in the past. In order to do this, a conscious machine should make coherent predictions and contingency plans, not only in worlds with fixed rules like a chess board, but also for novel environments that may change, to be executed only when appropriate to simulate and control the real world.\n\nSubjective experiences or qualia are widely considered to be the hard problem of consciousness. Indeed, it is held to pose a challenge to physicalism, let alone computationalism. On the other hand, there are problems in other fields of science which limit that which we can observe, such as the uncertainty principle in physics, which have not made the research in these fields of science impossible.\n\nThe term \"cognitive architecture\" may refer to a theory about the structure of the human mind, or any portion or function thereof, including consciousness. In another context, a cognitive architecture implements the theory on computers. An example is QuBIC: Quantum and Bio-inspired Cognitive Architecture for Machine Consciousness. One of the main goals of a cognitive architecture is to summarize the various results of cognitive psychology in a comprehensive computer model. However, the results need to be in a formalized form so they can be the basis of a computer program. Also, the role of cognitive architecture is for the A.I. to clearly structure, build, and implement it's thought process.\n\nStan Franklin (1995, 2003) defines an autonomous agent as possessing functional consciousness when it is capable of several of the functions of consciousness as identified by Bernard Baars' Global Workspace Theory (Baars 1988, 1997). His brain child IDA (Intelligent Distribution Agent) is a software implementation of GWT, which makes it functionally conscious by definition. IDA's task is to negotiate new assignments for sailors in the US Navy after they end a tour of duty, by matching each individual's skills and preferences with the Navy's needs. IDA interacts with Navy databases and communicates with the sailors via natural language e-mail dialog while obeying a large set of Navy policies. The IDA computational model was developed during 1996–2001 at Stan Franklin's \"Conscious\" Software Research Group at the University of Memphis. It \"consists of approximately a quarter-million lines of Java code, and almost completely consumes the resources of a 2001 high-end workstation.\" It relies heavily on codelets, which are \"special purpose, relatively independent, mini-agent[s] typically implemented as a small piece of code running as a separate thread.\" In IDA's top-down architecture, high-level cognitive functions are explicitly modeled (see Franklin 1995 and Franklin 2003 for details). While IDA is functionally conscious by definition, Franklin does \"not attribute phenomenal consciousness to his own 'conscious' software agent, IDA, in spite of her many human-like behaviours. This in spite of watching several US Navy detailers repeatedly nodding their heads saying 'Yes, that's how I do it' while watching IDA's internal and external actions as she performs her task.\"\n\nCLARION posits a two-level representation that explains the distinction between conscious and unconscious mental processes.\n\nCLARION has been successful in accounting for a variety of psychological data. A number of well-known skill learning tasks have been simulated using CLARION that span the spectrum ranging from simple reactive skills to complex cognitive skills. The tasks include serial reaction time (SRT) tasks, artificial grammar learning (AGL) tasks, process control (PC) tasks, the categorical inference (CI) task, the alphabetical arithmetic (AA) task, and the Tower of Hanoi (TOH) task (Sun 2002). Among them, SRT, AGL, and PC are typical implicit learning tasks, very much relevant to the issue of consciousness as they operationalized the notion of consciousness in the context of psychological experiments.\n\nBen Goertzel is pursuing an embodied AGI through the open-source OpenCog project. Current code includes embodied virtual pets capable of learning simple English-language commands, as well as integration with real-world robotics, being done at the Hong Kong Polytechnic University.\n\nPentti Haikonen (2003) considers classical rule-based computing inadequate for achieving AC: \"the brain is definitely not a computer. Thinking is not an execution of programmed strings of commands. The brain is not a numerical calculator either. We do not think by numbers.\" Rather than trying to achieve mind and consciousness by identifying and implementing their underlying computational rules, Haikonen proposes \"a special cognitive architecture to reproduce the processes of perception, inner imagery, inner speech, pain, pleasure, emotions and the cognitive functions behind these. This bottom-up architecture would produce higher-level functions by the power of the elementary processing units, the artificial neurons, without algorithms or programs\". Haikonen believes that, when implemented with sufficient complexity, this architecture will develop consciousness, which he considers to be \"a style and way of operation, characterized by distributed signal representation, perception process, cross-modality reporting and availability for retrospection.\" Haikonen is not alone in this process view of consciousness, or the view that AC will spontaneously emerge in autonomous agents that have a suitable neuro-inspired architecture of complexity; these are shared by many, e.g. Freeman (1999) and Cotterill (2003). A low-complexity implementation of the architecture proposed by Haikonen (2003) was reportedly not capable of AC, but did exhibit emotions as expected. See Doan (2009) for a comprehensive introduction to Haikonen's cognitive architecture. An updated account of Haikonen's architecture, along with a summary of his philosophical views, is given in Haikonen (2012).\n\nMurray Shanahan describes a cognitive architecture that combines Baars's idea of a global workspace with a mechanism for internal simulation (\"imagination\") (Shanahan 2006). For discussions of Shanahan's architecture, see (Gamez 2008) and (Reggia 2013) and Chapter 20 of (Haikonen 2012).\n\nSelf-awareness in robots is being investigated by Junichi Takeno[17] at Meiji University in Japan. Takeno is asserting that he has developed a robot capable of discriminating between a self-image in a mirror and any other having an identical image to it,[18][19] and this claim has already been reviewed (Takeno, Inaba & Suzuki 2005). Takeno asserts that he first contrived the computational module called a MoNAD, which has a self-aware function, and he then constructed the artificial consciousness system by formulating the relationships between emotions, feelings and reason by connecting the modules in a hierarchy (Igarashi, Takeno 2007). Takeno completed a mirror image cognition experiment using a robot equipped with the MoNAD system. Takeno proposed the Self-Body Theory stating that \"humans feel that their own mirror image is closer to themselves than an actual part of themselves.\" The most important point in developing artificial consciousness or clarifying human consciousness is the development of a function of self awareness, and he claims that he has demonstrated physical and mathematical evidence for this in his thesis.[20] He also demonstrated that robots can study episodes in memory where the emotions were stimulated and use this experience to take predictive actions to prevent the recurrence of unpleasant emotions (Torigoe, Takeno 2009).\n\nIgor Aleksander, emeritus professor of Neural Systems Engineering at Imperial College, has extensively researched artificial neural networks and claims in his book Impossible Minds: My Neurons, My Consciousness that the principles for creating a conscious machine already exist but that it would take forty years to train such a machine to understand language.[21] Whether this is true remains to be demonstrated and the basic principle stated in Impossible Minds—that the brain is a neural state machine—is open to doubt.[22]\n\nStephen Thaler proposed a possible connection between consciousness and creativity in his 1994 patent, called \"Device for the Autonomous Generation of Useful Information\" (DAGUI),[23][24][25] or the so-called \"Creativity Machine\", in which computational critics govern the injection of synaptic noise and degradation into neural nets so as to induce false memories or confabulations that may qualify as potential ideas or strategies.[26] He recruits this neural architecture and methodology to account for the subjective feel of consciousness, claiming that similar noise-driven neural assemblies within the brain invent dubious significance to overall cortical activity.[27][28][29] Thaler's theory and the resulting patents in machine consciousness were inspired by experiments in which he internally disrupted trained neural nets so as to drive a succession of neural activation patterns that he likened to stream of consciousness.[28][30][31][32][33][34]\n\nIn 2011, Michael Graziano and Sabine Kastler published a paper named \"Human consciousness and its relationship to social neuroscience: A novel hypothesis\" proposing a theory of consciousness as an attention schema.[35]  Graziano went on to publish an expanded discussion of this theory in his book \"Consciousness and the Social Brain\".[2] This Attention Schema Theory of Consciousness, as he named it, proposes that the brain tracks attention to various sensory inputs by way of  an attention schema, analogous to the well study body schema that tracks the spatial place of a person's body.[2]  This relates to artificial consciousness by proposing a specific mechanism of information handling, that produces what we allegedly experience and describe as consciousness, and which should be able to be duplicated by a machine using current technology. When the brain finds that person X is aware of thing Y, it is in effect modeling the state in which person X is applying an attentional enhancement to Y. In the attention schema theory, the same process can be applied to oneself. The brain tracks attention to various sensory inputs, and one's own awareness is a schematized model of one's attention. Graziano proposes specific locations in the brain for this process, and suggests that such awareness is a computed feature constructed by an expert system in the brain.\n\n"
    },
    {
      "title": "Testing",
      "text": "The most well-known method for testing machine intelligence is the Turing test. But when interpreted as only observational, this test contradicts the philosophy of science principles of theory dependence of observations. It also has been suggested that Alan Turing's recommendation of imitating not a human adult consciousness, but a human child consciousness, should be taken seriously.[36]\n\nOther tests, such as ConsScale, test the presence of features inspired by biological systems, or measure the cognitive development of artificial systems.\n\nQualia, or phenomenological consciousness, is an inherently first-person phenomenon. Although various systems may display various signs of behavior correlated with functional consciousness, there is no conceivable way in which third-person tests can have access to first-person phenomenological features. Because of that, and because there is no empirical definition of consciousness,[37] a test of presence of consciousness in AC may be impossible.\n\nIn 2014, Victor Argonov suggested a non-Turing test for machine consciousness based on machine's ability to produce philosophical judgments.[38] He argues that a deterministic machine must be regarded as conscious if it is able to produce judgments on all problematic properties of consciousness (such as qualia or binding) having no innate (preloaded) philosophical knowledge on these issues, no philosophical discussions while learning, and no informational models of other creatures in its memory (such models may implicitly or explicitly contain knowledge about these creatures’ consciousness). However, this test can be used only to detect, but not refute the existence of consciousness. A positive result proves that machine is conscious but a negative result proves nothing. For example, absence of philosophical judgments may be caused by lack of the machine’s intellect, not by absence of consciousness.\n\n"
    },
    {
      "title": "In fiction",
      "text": "Characters with artificial consciousness (or at least with personalities that imply they have consciousness), from works of fiction:\n\n"
    }
  ],
  "links": []
}